import { x as requireValid, y as requireSemver, z as requireSatisfies, A as requireValid$1, B as requireClean, g as getDefaultExportFromCjs } from '../shared/taze.CWW-GbSg.mjs';
import require$$0 from 'path';
import require$$0$1 from 'url';
import require$$2$1 from 'stream';
import require$$1$2 from 'os';
import { r as requireLib$d, a as requireLib$e } from '../shared/taze.DCXPW1kL.mjs';
import require$$2$2 from 'node:path';
import require$$1$3 from 'node:os';
import require$$5 from 'node:fs/promises';
import require$$0$2 from 'node:url';
import require$$5$1 from 'node:module';
import { r as requireCommonjs$4, a as requireCommonjs$5, b as requirePromiseRetry } from '../shared/taze.BE9fBO3V.mjs';
import require$$0$3 from 'fs';
import require$$4 from 'node:fs';
import require$$0$5 from 'child_process';
import require$$0$4 from 'fs/promises';
import require$$1$4 from 'node:path/win32';
import process$1 from 'node:process';

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var commonjs$3 = {};

var hasRequiredCommonjs$3;

function requireCommonjs$3 () {
	if (hasRequiredCommonjs$3) return commonjs$3;
	hasRequiredCommonjs$3 = 1;
	Object.defineProperty(commonjs$3, "__esModule", { value: true });
	commonjs$3.walkUp = void 0;
	const path_1 = require$$0;
	const walkUp = function* (path) {
	    for (path = (0, path_1.resolve)(path); path;) {
	        yield path;
	        const pp = (0, path_1.dirname)(path);
	        if (pp === path) {
	            break;
	        }
	        else {
	            path = pp;
	        }
	    }
	};
	commonjs$3.walkUp = walkUp;
	
	return commonjs$3;
}

var ini;
var hasRequiredIni;

function requireIni () {
	if (hasRequiredIni) return ini;
	hasRequiredIni = 1;
	const { hasOwnProperty } = Object.prototype;

	const encode = (obj, opt = {}) => {
	  if (typeof opt === 'string') {
	    opt = { section: opt };
	  }
	  opt.align = opt.align === true;
	  opt.newline = opt.newline === true;
	  opt.sort = opt.sort === true;
	  opt.whitespace = opt.whitespace === true || opt.align === true;
	  // The `typeof` check is required because accessing the `process` directly fails on browsers.
	  /* istanbul ignore next */
	  opt.platform = opt.platform || (typeof process !== 'undefined' && process.platform);
	  opt.bracketedArray = opt.bracketedArray !== false;

	  /* istanbul ignore next */
	  const eol = opt.platform === 'win32' ? '\r\n' : '\n';
	  const separator = opt.whitespace ? ' = ' : '=';
	  const children = [];

	  const keys = opt.sort ? Object.keys(obj).sort() : Object.keys(obj);

	  let padToChars = 0;
	  // If aligning on the separator, then padToChars is determined as follows:
	  // 1. Get the keys
	  // 2. Exclude keys pointing to objects unless the value is null or an array
	  // 3. Add `[]` to array keys
	  // 4. Ensure non empty set of keys
	  // 5. Reduce the set to the longest `safe` key
	  // 6. Get the `safe` length
	  if (opt.align) {
	    padToChars = safe(
	      (
	        keys
	          .filter(k => obj[k] === null || Array.isArray(obj[k]) || typeof obj[k] !== 'object')
	          .map(k => Array.isArray(obj[k]) ? `${k}[]` : k)
	      )
	        .concat([''])
	        .reduce((a, b) => safe(a).length >= safe(b).length ? a : b)
	    ).length;
	  }

	  let out = '';
	  const arraySuffix = opt.bracketedArray ? '[]' : '';

	  for (const k of keys) {
	    const val = obj[k];
	    if (val && Array.isArray(val)) {
	      for (const item of val) {
	        out += safe(`${k}${arraySuffix}`).padEnd(padToChars, ' ') + separator + safe(item) + eol;
	      }
	    } else if (val && typeof val === 'object') {
	      children.push(k);
	    } else {
	      out += safe(k).padEnd(padToChars, ' ') + separator + safe(val) + eol;
	    }
	  }

	  if (opt.section && out.length) {
	    out = '[' + safe(opt.section) + ']' + (opt.newline ? eol + eol : eol) + out;
	  }

	  for (const k of children) {
	    const nk = splitSections(k, '.').join('\\.');
	    const section = (opt.section ? opt.section + '.' : '') + nk;
	    const child = encode(obj[k], {
	      ...opt,
	      section,
	    });
	    if (out.length && child.length) {
	      out += eol;
	    }

	    out += child;
	  }

	  return out
	};

	function splitSections (str, separator) {
	  var lastMatchIndex = 0;
	  var lastSeparatorIndex = 0;
	  var nextIndex = 0;
	  var sections = [];

	  do {
	    nextIndex = str.indexOf(separator, lastMatchIndex);

	    if (nextIndex !== -1) {
	      lastMatchIndex = nextIndex + separator.length;

	      if (nextIndex > 0 && str[nextIndex - 1] === '\\') {
	        continue
	      }

	      sections.push(str.slice(lastSeparatorIndex, nextIndex));
	      lastSeparatorIndex = nextIndex + separator.length;
	    }
	  } while (nextIndex !== -1)

	  sections.push(str.slice(lastSeparatorIndex));

	  return sections
	}

	const decode = (str, opt = {}) => {
	  opt.bracketedArray = opt.bracketedArray !== false;
	  const out = Object.create(null);
	  let p = out;
	  let section = null;
	  //          section          |key      = value
	  const re = /^\[([^\]]*)\]\s*$|^([^=]+)(=(.*))?$/i;
	  const lines = str.split(/[\r\n]+/g);
	  const duplicates = {};

	  for (const line of lines) {
	    if (!line || line.match(/^\s*[;#]/) || line.match(/^\s*$/)) {
	      continue
	    }
	    const match = line.match(re);
	    if (!match) {
	      continue
	    }
	    if (match[1] !== undefined) {
	      section = unsafe(match[1]);
	      if (section === '__proto__') {
	        // not allowed
	        // keep parsing the section, but don't attach it.
	        p = Object.create(null);
	        continue
	      }
	      p = out[section] = out[section] || Object.create(null);
	      continue
	    }
	    const keyRaw = unsafe(match[2]);
	    let isArray;
	    if (opt.bracketedArray) {
	      isArray = keyRaw.length > 2 && keyRaw.slice(-2) === '[]';
	    } else {
	      duplicates[keyRaw] = (duplicates?.[keyRaw] || 0) + 1;
	      isArray = duplicates[keyRaw] > 1;
	    }
	    const key = isArray && keyRaw.endsWith('[]')
	      ? keyRaw.slice(0, -2) : keyRaw;

	    if (key === '__proto__') {
	      continue
	    }
	    const valueRaw = match[3] ? unsafe(match[4]) : true;
	    const value = valueRaw === 'true' ||
	      valueRaw === 'false' ||
	      valueRaw === 'null' ? JSON.parse(valueRaw)
	      : valueRaw;

	    // Convert keys with '[]' suffix to an array
	    if (isArray) {
	      if (!hasOwnProperty.call(p, key)) {
	        p[key] = [];
	      } else if (!Array.isArray(p[key])) {
	        p[key] = [p[key]];
	      }
	    }

	    // safeguard against resetting a previously defined
	    // array by accidentally forgetting the brackets
	    if (Array.isArray(p[key])) {
	      p[key].push(value);
	    } else {
	      p[key] = value;
	    }
	  }

	  // {a:{y:1},"a.b":{x:2}} --> {a:{y:1,b:{x:2}}}
	  // use a filter to return the keys that have to be deleted.
	  const remove = [];
	  for (const k of Object.keys(out)) {
	    if (!hasOwnProperty.call(out, k) ||
	      typeof out[k] !== 'object' ||
	      Array.isArray(out[k])) {
	      continue
	    }

	    // see if the parent section is also an object.
	    // if so, add it to that, and mark this one for deletion
	    const parts = splitSections(k, '.');
	    p = out;
	    const l = parts.pop();
	    const nl = l.replace(/\\\./g, '.');
	    for (const part of parts) {
	      if (part === '__proto__') {
	        continue
	      }
	      if (!hasOwnProperty.call(p, part) || typeof p[part] !== 'object') {
	        p[part] = Object.create(null);
	      }
	      p = p[part];
	    }
	    if (p === out && nl === l) {
	      continue
	    }

	    p[nl] = out[k];
	    remove.push(k);
	  }
	  for (const del of remove) {
	    delete out[del];
	  }

	  return out
	};

	const isQuoted = val => {
	  return (val.startsWith('"') && val.endsWith('"')) ||
	    (val.startsWith("'") && val.endsWith("'"))
	};

	const safe = val => {
	  if (
	    typeof val !== 'string' ||
	    val.match(/[=\r\n]/) ||
	    val.match(/^\[/) ||
	    (val.length > 1 && isQuoted(val)) ||
	    val !== val.trim()
	  ) {
	    return JSON.stringify(val)
	  }
	  return val.split(';').join('\\;').split('#').join('\\#')
	};

	const unsafe = val => {
	  val = (val || '').trim();
	  if (isQuoted(val)) {
	    // remove the single quotes before calling JSON.parse
	    if (val.charAt(0) === "'") {
	      val = val.slice(1, -1);
	    }
	    try {
	      val = JSON.parse(val);
	    } catch {
	      // ignore errors
	    }
	  } else {
	    // walk the val to find the first not-escaped ; character
	    let esc = false;
	    let unesc = '';
	    for (let i = 0, l = val.length; i < l; i++) {
	      const c = val.charAt(i);
	      if (esc) {
	        if ('\\;#'.indexOf(c) !== -1) {
	          unesc += c;
	        } else {
	          unesc += '\\' + c;
	        }

	        esc = false;
	      } else if (';#'.indexOf(c) !== -1) {
	        break
	      } else if (c === '\\') {
	        esc = true;
	      } else {
	        unesc += c;
	      }
	    }
	    if (esc) {
	      unesc += '\\';
	    }

	    return unesc.trim()
	  }
	  return val
	};

	ini = {
	  parse: decode,
	  decode,
	  stringify: encode,
	  encode,
	  safe,
	  unsafe,
	};
	return ini;
}

var nopt = {exports: {}};

var lib$c;
var hasRequiredLib$c;

function requireLib$c () {
	if (hasRequiredLib$c) return lib$c;
	hasRequiredLib$c = 1;
	lib$c = abbrev;

	function abbrev (...args) {
	  let list = args;
	  if (args.length === 1 && (Array.isArray(args[0]) || typeof args[0] === 'string')) {
	    list = [].concat(args[0]);
	  }

	  for (let i = 0, l = list.length; i < l; i++) {
	    list[i] = typeof list[i] === 'string' ? list[i] : String(list[i]);
	  }

	  // sort them lexicographically, so that they're next to their nearest kin
	  list = list.sort(lexSort);

	  // walk through each, seeing how much it has in common with the next and previous
	  const abbrevs = {};
	  let prev = '';
	  for (let ii = 0, ll = list.length; ii < ll; ii++) {
	    const current = list[ii];
	    const next = list[ii + 1] || '';
	    let nextMatches = true;
	    let prevMatches = true;
	    if (current === next) {
	      continue
	    }
	    let j = 0;
	    const cl = current.length;
	    for (; j < cl; j++) {
	      const curChar = current.charAt(j);
	      nextMatches = nextMatches && curChar === next.charAt(j);
	      prevMatches = prevMatches && curChar === prev.charAt(j);
	      if (!nextMatches && !prevMatches) {
	        j++;
	        break
	      }
	    }
	    prev = current;
	    if (j === cl) {
	      abbrevs[current] = current;
	      continue
	    }
	    for (let a = current.slice(0, j); j <= cl; j++) {
	      abbrevs[a] = current;
	      a += current.charAt(j);
	    }
	  }
	  return abbrevs
	}

	function lexSort (a, b) {
	  return a === b ? 0 : a > b ? 1 : -1
	}
	return lib$c;
}

/* istanbul ignore next */

var debug;
var hasRequiredDebug;

function requireDebug () {
	if (hasRequiredDebug) return debug;
	hasRequiredDebug = 1;
	debug = process.env.DEBUG_NOPT || process.env.NOPT_DEBUG
	  // eslint-disable-next-line no-console
	  ? (...a) => console.error(...a)
	  : () => {};
	return debug;
}

var typeDefs$1;
var hasRequiredTypeDefs$1;

function requireTypeDefs$1 () {
	if (hasRequiredTypeDefs$1) return typeDefs$1;
	hasRequiredTypeDefs$1 = 1;
	const url = require$$0$1;
	const path = require$$0;
	const Stream = require$$2$1.Stream;
	const os = require$$1$2;
	const debug = requireDebug();

	function validateString (data, k, val) {
	  data[k] = String(val);
	}

	function validatePath (data, k, val) {
	  if (val === true) {
	    return false
	  }
	  if (val === null) {
	    return true
	  }

	  val = String(val);

	  const isWin = process.platform === 'win32';
	  const homePattern = isWin ? /^~(\/|\\)/ : /^~\//;
	  const home = os.homedir();

	  if (home && val.match(homePattern)) {
	    data[k] = path.resolve(home, val.slice(2));
	  } else {
	    data[k] = path.resolve(val);
	  }
	  return true
	}

	function validateNumber (data, k, val) {
	  debug('validate Number %j %j %j', k, val, isNaN(val));
	  if (isNaN(val)) {
	    return false
	  }
	  data[k] = +val;
	}

	function validateDate (data, k, val) {
	  const s = Date.parse(val);
	  debug('validate Date %j %j %j', k, val, s);
	  if (isNaN(s)) {
	    return false
	  }
	  data[k] = new Date(val);
	}

	function validateBoolean (data, k, val) {
	  if (typeof val === 'string') {
	    if (!isNaN(val)) {
	      val = !!(+val);
	    } else if (val === 'null' || val === 'false') {
	      val = false;
	    } else {
	      val = true;
	    }
	  } else {
	    val = !!val;
	  }
	  data[k] = val;
	}

	function validateUrl (data, k, val) {
	  // Changing this would be a breaking change in the npm cli
	  /* eslint-disable-next-line node/no-deprecated-api */
	  val = url.parse(String(val));
	  if (!val.host) {
	    return false
	  }
	  data[k] = val.href;
	}

	function validateStream (data, k, val) {
	  if (!(val instanceof Stream)) {
	    return false
	  }
	  data[k] = val;
	}

	typeDefs$1 = {
	  String: { type: String, validate: validateString },
	  Boolean: { type: Boolean, validate: validateBoolean },
	  url: { type: url, validate: validateUrl },
	  Number: { type: Number, validate: validateNumber },
	  path: { type: path, validate: validatePath },
	  Stream: { type: Stream, validate: validateStream },
	  Date: { type: Date, validate: validateDate },
	  Array: { type: Array },
	};
	return typeDefs$1;
}

var noptLib;
var hasRequiredNoptLib;

function requireNoptLib () {
	if (hasRequiredNoptLib) return noptLib;
	hasRequiredNoptLib = 1;
	const abbrev = requireLib$c();
	const debug = requireDebug();
	const defaultTypeDefs = requireTypeDefs$1();

	const hasOwn = (o, k) => Object.prototype.hasOwnProperty.call(o, k);

	const getType = (k, { types, dynamicTypes }) => {
	  let hasType = hasOwn(types, k);
	  let type = types[k];
	  if (!hasType && typeof dynamicTypes === 'function') {
	    const matchedType = dynamicTypes(k);
	    if (matchedType !== undefined) {
	      type = matchedType;
	      hasType = true;
	    }
	  }
	  return [hasType, type]
	};

	const isTypeDef = (type, def) => def && type === def;
	const hasTypeDef = (type, def) => def && type.indexOf(def) !== -1;
	const doesNotHaveTypeDef = (type, def) => def && !hasTypeDef(type, def);

	function nopt (args, {
	  types,
	  shorthands,
	  typeDefs,
	  invalidHandler, // opt is configured but its value does not validate against given type
	  unknownHandler, // opt is not configured
	  abbrevHandler, // opt is being expanded via abbrev
	  typeDefault,
	  dynamicTypes,
	} = {}) {
	  debug(types, shorthands, args, typeDefs);

	  const data = {};
	  const argv = {
	    remain: [],
	    cooked: args,
	    original: args.slice(0),
	  };

	  parse(args, data, argv.remain, {
	    typeDefs, types, dynamicTypes, shorthands, unknownHandler, abbrevHandler,
	  });

	  // now data is full
	  clean(data, { types, dynamicTypes, typeDefs, invalidHandler, typeDefault });
	  data.argv = argv;

	  Object.defineProperty(data.argv, 'toString', {
	    value: function () {
	      return this.original.map(JSON.stringify).join(' ')
	    },
	    enumerable: false,
	  });

	  return data
	}

	function clean (data, {
	  types = {},
	  typeDefs = {},
	  dynamicTypes,
	  invalidHandler,
	  typeDefault,
	} = {}) {
	  const StringType = typeDefs.String?.type;
	  const NumberType = typeDefs.Number?.type;
	  const ArrayType = typeDefs.Array?.type;
	  const BooleanType = typeDefs.Boolean?.type;
	  const DateType = typeDefs.Date?.type;

	  const hasTypeDefault = typeof typeDefault !== 'undefined';
	  if (!hasTypeDefault) {
	    typeDefault = [false, true, null];
	    if (StringType) {
	      typeDefault.push(StringType);
	    }
	    if (ArrayType) {
	      typeDefault.push(ArrayType);
	    }
	  }

	  const remove = {};

	  Object.keys(data).forEach((k) => {
	    if (k === 'argv') {
	      return
	    }
	    let val = data[k];
	    debug('val=%j', val);
	    const isArray = Array.isArray(val);
	    let [hasType, rawType] = getType(k, { types, dynamicTypes });
	    let type = rawType;
	    if (!isArray) {
	      val = [val];
	    }
	    if (!type) {
	      type = typeDefault;
	    }
	    if (isTypeDef(type, ArrayType)) {
	      type = typeDefault.concat(ArrayType);
	    }
	    if (!Array.isArray(type)) {
	      type = [type];
	    }

	    debug('val=%j', val);
	    debug('types=', type);
	    val = val.map((v) => {
	      // if it's an unknown value, then parse false/true/null/numbers/dates
	      if (typeof v === 'string') {
	        debug('string %j', v);
	        v = v.trim();
	        if ((v === 'null' && ~type.indexOf(null))
	            || (v === 'true' &&
	               (~type.indexOf(true) || hasTypeDef(type, BooleanType)))
	            || (v === 'false' &&
	               (~type.indexOf(false) || hasTypeDef(type, BooleanType)))) {
	          v = JSON.parse(v);
	          debug('jsonable %j', v);
	        } else if (hasTypeDef(type, NumberType) && !isNaN(v)) {
	          debug('convert to number', v);
	          v = +v;
	        } else if (hasTypeDef(type, DateType) && !isNaN(Date.parse(v))) {
	          debug('convert to date', v);
	          v = new Date(v);
	        }
	      }

	      if (!hasType) {
	        if (!hasTypeDefault) {
	          return v
	        }
	        // if the default type has been passed in then we want to validate the
	        // unknown data key instead of bailing out earlier. we also set the raw
	        // type which is passed to the invalid handler so that it can be
	        // determined if during validation if it is unknown vs invalid
	        rawType = typeDefault;
	      }

	      // allow `--no-blah` to set 'blah' to null if null is allowed
	      if (v === false && ~type.indexOf(null) &&
	          !(~type.indexOf(false) || hasTypeDef(type, BooleanType))) {
	        v = null;
	      }

	      const d = {};
	      d[k] = v;
	      debug('prevalidated val', d, v, rawType);
	      if (!validate(d, k, v, rawType, { typeDefs })) {
	        if (invalidHandler) {
	          invalidHandler(k, v, rawType, data);
	        } else if (invalidHandler !== false) {
	          debug('invalid: ' + k + '=' + v, rawType);
	        }
	        return remove
	      }
	      debug('validated v', d, v, rawType);
	      return d[k]
	    }).filter((v) => v !== remove);

	    // if we allow Array specifically, then an empty array is how we
	    // express 'no value here', not null.  Allow it.
	    if (!val.length && doesNotHaveTypeDef(type, ArrayType)) {
	      debug('VAL HAS NO LENGTH, DELETE IT', val, k, type.indexOf(ArrayType));
	      delete data[k];
	    } else if (isArray) {
	      debug(isArray, data[k], val);
	      data[k] = val;
	    } else {
	      data[k] = val[0];
	    }

	    debug('k=%s val=%j', k, val, data[k]);
	  });
	}

	function validate (data, k, val, type, { typeDefs } = {}) {
	  const ArrayType = typeDefs?.Array?.type;
	  // arrays are lists of types.
	  if (Array.isArray(type)) {
	    for (let i = 0, l = type.length; i < l; i++) {
	      if (isTypeDef(type[i], ArrayType)) {
	        continue
	      }
	      if (validate(data, k, val, type[i], { typeDefs })) {
	        return true
	      }
	    }
	    delete data[k];
	    return false
	  }

	  // an array of anything?
	  if (isTypeDef(type, ArrayType)) {
	    return true
	  }

	  // Original comment:
	  // NaN is poisonous.  Means that something is not allowed.
	  // New comment: Changing this to an isNaN check breaks a lot of tests.
	  // Something is being assumed here that is not actually what happens in
	  // practice.  Fixing it is outside the scope of getting linting to pass in
	  // this repo. Leaving as-is for now.
	  /* eslint-disable-next-line no-self-compare */
	  if (type !== type) {
	    debug('Poison NaN', k, val, type);
	    delete data[k];
	    return false
	  }

	  // explicit list of values
	  if (val === type) {
	    debug('Explicitly allowed %j', val);
	    data[k] = val;
	    return true
	  }

	  // now go through the list of typeDefs, validate against each one.
	  let ok = false;
	  const types = Object.keys(typeDefs);
	  for (let i = 0, l = types.length; i < l; i++) {
	    debug('test type %j %j %j', k, val, types[i]);
	    const t = typeDefs[types[i]];
	    if (t && (
	      (type && type.name && t.type && t.type.name) ?
	        (type.name === t.type.name) :
	        (type === t.type)
	    )) {
	      const d = {};
	      ok = t.validate(d, k, val) !== false;
	      val = d[k];
	      if (ok) {
	        data[k] = val;
	        break
	      }
	    }
	  }
	  debug('OK? %j (%j %j %j)', ok, k, val, types[types.length - 1]);

	  if (!ok) {
	    delete data[k];
	  }
	  return ok
	}

	function parse (args, data, remain, {
	  types = {},
	  typeDefs = {},
	  shorthands = {},
	  dynamicTypes,
	  unknownHandler,
	  abbrevHandler,
	} = {}) {
	  const StringType = typeDefs.String?.type;
	  const NumberType = typeDefs.Number?.type;
	  const ArrayType = typeDefs.Array?.type;
	  const BooleanType = typeDefs.Boolean?.type;

	  debug('parse', args, data, remain);

	  const abbrevs = abbrev(Object.keys(types));
	  debug('abbrevs=%j', abbrevs);
	  const shortAbbr = abbrev(Object.keys(shorthands));

	  for (let i = 0; i < args.length; i++) {
	    let arg = args[i];
	    debug('arg', arg);

	    if (arg.match(/^-{2,}$/)) {
	      // done with keys.
	      // the rest are args.
	      remain.push.apply(remain, args.slice(i + 1));
	      args[i] = '--';
	      break
	    }
	    let hadEq = false;
	    if (arg.charAt(0) === '-' && arg.length > 1) {
	      const at = arg.indexOf('=');
	      if (at > -1) {
	        hadEq = true;
	        const v = arg.slice(at + 1);
	        arg = arg.slice(0, at);
	        args.splice(i, 1, arg, v);
	      }

	      // see if it's a shorthand
	      // if so, splice and back up to re-parse it.
	      const shRes = resolveShort(arg, shortAbbr, abbrevs, { shorthands, abbrevHandler });
	      debug('arg=%j shRes=%j', arg, shRes);
	      if (shRes) {
	        args.splice.apply(args, [i, 1].concat(shRes));
	        if (arg !== shRes[0]) {
	          i--;
	          continue
	        }
	      }
	      arg = arg.replace(/^-+/, '');
	      let no = null;
	      while (arg.toLowerCase().indexOf('no-') === 0) {
	        no = !no;
	        arg = arg.slice(3);
	      }

	      // abbrev includes the original full string in its abbrev list
	      if (abbrevs[arg] && abbrevs[arg] !== arg) {
	        if (abbrevHandler) {
	          abbrevHandler(arg, abbrevs[arg]);
	        } else if (abbrevHandler !== false) {
	          debug(`abbrev: ${arg} -> ${abbrevs[arg]}`);
	        }
	        arg = abbrevs[arg];
	      }

	      let [hasType, argType] = getType(arg, { types, dynamicTypes });
	      let isTypeArray = Array.isArray(argType);
	      if (isTypeArray && argType.length === 1) {
	        isTypeArray = false;
	        argType = argType[0];
	      }

	      let isArray = isTypeDef(argType, ArrayType) ||
	        isTypeArray && hasTypeDef(argType, ArrayType);

	      // allow unknown things to be arrays if specified multiple times.
	      if (!hasType && hasOwn(data, arg)) {
	        if (!Array.isArray(data[arg])) {
	          data[arg] = [data[arg]];
	        }
	        isArray = true;
	      }

	      let val;
	      let la = args[i + 1];

	      const isBool = typeof no === 'boolean' ||
	        isTypeDef(argType, BooleanType) ||
	        isTypeArray && hasTypeDef(argType, BooleanType) ||
	        (typeof argType === 'undefined' && !hadEq) ||
	        (la === 'false' &&
	         (argType === null ||
	          isTypeArray && ~argType.indexOf(null)));

	      if (typeof argType === 'undefined') {
	        // la is going to unexpectedly be parsed outside the context of this arg
	        const hangingLa = !hadEq && la && !la?.startsWith('-') && !['true', 'false'].includes(la);
	        if (unknownHandler) {
	          if (hangingLa) {
	            unknownHandler(arg, la);
	          } else {
	            unknownHandler(arg);
	          }
	        } else if (unknownHandler !== false) {
	          debug(`unknown: ${arg}`);
	          if (hangingLa) {
	            debug(`unknown: ${la} parsed as normal opt`);
	          }
	        }
	      }

	      if (isBool) {
	        // just set and move along
	        val = !no;
	        // however, also support --bool true or --bool false
	        if (la === 'true' || la === 'false') {
	          val = JSON.parse(la);
	          la = null;
	          if (no) {
	            val = !val;
	          }
	          i++;
	        }

	        // also support "foo":[Boolean, "bar"] and "--foo bar"
	        if (isTypeArray && la) {
	          if (~argType.indexOf(la)) {
	            // an explicit type
	            val = la;
	            i++;
	          } else if (la === 'null' && ~argType.indexOf(null)) {
	            // null allowed
	            val = null;
	            i++;
	          } else if (!la.match(/^-{2,}[^-]/) &&
	                      !isNaN(la) &&
	                      hasTypeDef(argType, NumberType)) {
	            // number
	            val = +la;
	            i++;
	          } else if (!la.match(/^-[^-]/) && hasTypeDef(argType, StringType)) {
	            // string
	            val = la;
	            i++;
	          }
	        }

	        if (isArray) {
	          (data[arg] = data[arg] || []).push(val);
	        } else {
	          data[arg] = val;
	        }

	        continue
	      }

	      if (isTypeDef(argType, StringType)) {
	        if (la === undefined) {
	          la = '';
	        } else if (la.match(/^-{1,2}[^-]+/)) {
	          la = '';
	          i--;
	        }
	      }

	      if (la && la.match(/^-{2,}$/)) {
	        la = undefined;
	        i--;
	      }

	      val = la === undefined ? true : la;
	      if (isArray) {
	        (data[arg] = data[arg] || []).push(val);
	      } else {
	        data[arg] = val;
	      }

	      i++;
	      continue
	    }
	    remain.push(arg);
	  }
	}

	const SINGLES = Symbol('singles');
	const singleCharacters = (arg, shorthands) => {
	  let singles = shorthands[SINGLES];
	  if (!singles) {
	    singles = Object.keys(shorthands).filter((s) => s.length === 1).reduce((l, r) => {
	      l[r] = true;
	      return l
	    }, {});
	    shorthands[SINGLES] = singles;
	    debug('shorthand singles', singles);
	  }
	  const chrs = arg.split('').filter((c) => singles[c]);
	  return chrs.join('') === arg ? chrs : null
	};

	function resolveShort (arg, ...rest) {
	  const { abbrevHandler, types = {}, shorthands = {} } = rest.length ? rest.pop() : {};
	  const shortAbbr = rest[0] ?? abbrev(Object.keys(shorthands));
	  const abbrevs = rest[1] ?? abbrev(Object.keys(types));

	  // handle single-char shorthands glommed together, like
	  // npm ls -glp, but only if there is one dash, and only if
	  // all of the chars are single-char shorthands, and it's
	  // not a match to some other abbrev.
	  arg = arg.replace(/^-+/, '');

	  // if it's an exact known option, then don't go any further
	  if (abbrevs[arg] === arg) {
	    return null
	  }

	  // if it's an exact known shortopt, same deal
	  if (shorthands[arg]) {
	    // make it an array, if it's a list of words
	    if (shorthands[arg] && !Array.isArray(shorthands[arg])) {
	      shorthands[arg] = shorthands[arg].split(/\s+/);
	    }

	    return shorthands[arg]
	  }

	  // first check to see if this arg is a set of single-char shorthands
	  const chrs = singleCharacters(arg, shorthands);
	  if (chrs) {
	    return chrs.map((c) => shorthands[c]).reduce((l, r) => l.concat(r), [])
	  }

	  // if it's an arg abbrev, and not a literal shorthand, then prefer the arg
	  if (abbrevs[arg] && !shorthands[arg]) {
	    return null
	  }

	  // if it's an abbr for a shorthand, then use that
	  // exact match has already happened so we don't need to account for that here
	  if (shortAbbr[arg]) {
	    if (abbrevHandler) {
	      abbrevHandler(arg, shortAbbr[arg]);
	    } else if (abbrevHandler !== false) {
	      debug(`abbrev: ${arg} -> ${shortAbbr[arg]}`);
	    }
	    arg = shortAbbr[arg];
	  }

	  // make it an array, if it's a list of words
	  if (shorthands[arg] && !Array.isArray(shorthands[arg])) {
	    shorthands[arg] = shorthands[arg].split(/\s+/);
	  }

	  return shorthands[arg]
	}

	noptLib = {
	  nopt,
	  clean,
	  parse,
	  validate,
	  resolveShort,
	  typeDefs: defaultTypeDefs,
	};
	return noptLib;
}

var hasRequiredNopt;

function requireNopt () {
	if (hasRequiredNopt) return nopt.exports;
	hasRequiredNopt = 1;
	(function (module, exports) {
		const lib = requireNoptLib();
		const defaultTypeDefs = requireTypeDefs$1();

		// This is the version of nopt's API that requires setting typeDefs and invalidHandler
		// on the required `nopt` object since it is a singleton. To not do a breaking change
		// an API that requires all options be passed in is located in `nopt-lib.js` and
		// exported here as lib.
		// TODO(breaking): make API only work in non-singleton mode

		module.exports = exports = nopt;
		exports.clean = clean;
		exports.typeDefs = defaultTypeDefs;
		exports.lib = lib;

		function nopt (types, shorthands, args = process.argv, slice = 2) {
		  return lib.nopt(args.slice(slice), {
		    types: types || {},
		    shorthands: shorthands || {},
		    typeDefs: exports.typeDefs,
		    invalidHandler: exports.invalidHandler,
		    unknownHandler: exports.unknownHandler,
		    abbrevHandler: exports.abbrevHandler,
		  })
		}

		function clean (data, types, typeDefs = exports.typeDefs) {
		  return lib.clean(data, {
		    types: types || {},
		    typeDefs,
		    invalidHandler: exports.invalidHandler,
		    unknownHandler: exports.unknownHandler,
		    abbrevHandler: exports.abbrevHandler,
		  })
		} 
	} (nopt, nopt.exports));
	return nopt.exports;
}

var typeDefs = {exports: {}};

var umask;
var hasRequiredUmask;

function requireUmask () {
	if (hasRequiredUmask) return umask;
	hasRequiredUmask = 1;
	const parse = val => {
	  // this is run via nopt and parse field where everything is
	  // converted to a string first, ignoring coverage for now
	  // instead of figuring out what is happening under the hood in nopt
	  // istanbul ignore else
	  if (typeof val === 'string') {
	    if (/^0o?[0-7]+$/.test(val)) {
	      return parseInt(val.replace(/^0o?/, ''), 8)
	    } else if (/^[1-9][0-9]*$/.test(val)) {
	      return parseInt(val, 10)
	    } else {
	      throw new Error(`invalid umask value: ${val}`)
	    }
	  } else {
	    if (typeof val !== 'number') {
	      throw new Error(`invalid umask value: ${val}`)
	    }
	    val = Math.floor(val);
	    if (val < 0 || val > 511) {
	      throw new Error(`invalid umask value: ${val}`)
	    }
	    return val
	  }
	};

	const validate = (data, k, val) => {
	  try {
	    data[k] = parse(val);
	    return true
	  } catch (er) {
	    return false
	  }
	};

	umask = { parse, validate };
	return umask;
}

var hasRequiredTypeDefs;

function requireTypeDefs () {
	if (hasRequiredTypeDefs) return typeDefs.exports;
	hasRequiredTypeDefs = 1;
	(function (module) {
		const nopt = requireNopt();

		const { validate: validateUmask } = requireUmask();

		class Umask {}
		class Semver {}
		const semverValid = requireValid();
		const validateSemver = (data, k, val) => {
		  const valid = semverValid(val);
		  if (!valid) {
		    return false
		  }
		  data[k] = valid;
		};

		const noptValidatePath = nopt.typeDefs.path.validate;
		const validatePath = (data, k, val) => {
		  if (typeof val !== 'string') {
		    return false
		  }
		  return noptValidatePath(data, k, val)
		};

		// add descriptions so we can validate more usefully
		module.exports = {
		  ...nopt.typeDefs,
		  semver: {
		    type: Semver,
		    validate: validateSemver,
		    description: 'full valid SemVer string',
		  },
		  Umask: {
		    type: Umask,
		    validate: validateUmask,
		    description: 'octal number in range 0o000..0o777 (0..511)',
		  },
		  url: {
		    ...nopt.typeDefs.url,
		    description: 'full url with "http://"',
		  },
		  path: {
		    ...nopt.typeDefs.path,
		    validate: validatePath,
		    description: 'valid filesystem path',
		  },
		  Number: {
		    ...nopt.typeDefs.Number,
		    description: 'numeric value',
		  },
		  Boolean: {
		    ...nopt.typeDefs.Boolean,
		    description: 'boolean value (true or false)',
		  },
		  Date: {
		    ...nopt.typeDefs.Date,
		    description: 'valid Date string',
		  },
		};

		// TODO: make nopt less of a global beast so this kludge isn't necessary
		nopt.typeDefs = module.exports; 
	} (typeDefs));
	return typeDefs.exports;
}

var nerfDart;
var hasRequiredNerfDart;

function requireNerfDart () {
	if (hasRequiredNerfDart) return nerfDart;
	hasRequiredNerfDart = 1;
	const { URL } = require$$0$2;

	/**
	 * Maps a URL to an identifier.
	 *
	 * Name courtesy schiffertronix media LLC, a New Jersey corporation
	 *
	 * @param {String} uri The URL to be nerfed.
	 *
	 * @returns {String} A nerfed URL.
	 */
	nerfDart = (url) => {
	  const parsed = new URL(url);
	  const from = `${parsed.protocol}//${parsed.host}${parsed.pathname}`;
	  const rel = new URL('.', from);
	  const res = `//${rel.host}${rel.pathname}`;
	  return res
	};
	return nerfDart;
}

var envReplace;
var hasRequiredEnvReplace;

function requireEnvReplace () {
	if (hasRequiredEnvReplace) return envReplace;
	hasRequiredEnvReplace = 1;
	// replace any ${ENV} values with the appropriate environ.

	const envExpr = /(?<!\\)(\\*)\$\{([^${}]+)\}/g;

	envReplace = (f, env) => f.replace(envExpr, (orig, esc, name) => {
	  const val = env[name] !== undefined ? env[name] : `$\{${name}}`;

	  // consume the escape chars that are relevant.
	  if (esc.length % 2) {
	    return orig.slice((esc.length + 1) / 2)
	  }

	  return (esc.slice(esc.length / 2)) + val
	});
	return envReplace;
}

var parseField_1;
var hasRequiredParseField;

function requireParseField () {
	if (hasRequiredParseField) return parseField_1;
	hasRequiredParseField = 1;
	// Parse a field, coercing it to the best type available.
	const typeDefs = requireTypeDefs();
	const envReplace = requireEnvReplace();
	const { resolve } = require$$2$2;

	const { parse: umaskParse } = requireUmask();

	const parseField = (f, key, opts, listElement = false) => {
	  if (typeof f !== 'string' && !Array.isArray(f)) {
	    return f
	  }

	  const { platform, types, home, env } = opts;

	  // type can be array or a single thing.  coerce to array.
	  const typeList = new Set([].concat(types[key]));
	  const isPath = typeList.has(typeDefs.path.type);
	  const isBool = typeList.has(typeDefs.Boolean.type);
	  const isString = isPath || typeList.has(typeDefs.String.type);
	  const isUmask = typeList.has(typeDefs.Umask.type);
	  const isNumber = typeList.has(typeDefs.Number.type);
	  const isList = !listElement && typeList.has(Array);
	  const isDate = typeList.has(typeDefs.Date.type);

	  if (Array.isArray(f)) {
	    return !isList ? f : f.map(field => parseField(field, key, opts, true))
	  }

	  // now we know it's a string
	  f = f.trim();

	  // list types get put in the environment separated by double-\n
	  // usually a single \n would suffice, but ca/cert configs can contain
	  // line breaks and multiple entries.
	  if (isList) {
	    return parseField(f.split('\n\n'), key, opts)
	  }

	  // --foo is like --foo=true for boolean types
	  if (isBool && !isString && f === '') {
	    return true
	  }

	  // string types can be the string 'true', 'false', etc.
	  // otherwise, parse these values out
	  if (!isString && !isPath && !isNumber) {
	    switch (f) {
	      case 'true': return true
	      case 'false': return false
	      case 'null': return null
	      case 'undefined': return undefined
	    }
	  }

	  f = envReplace(f, env);

	  if (isDate) {
	    return new Date(f)
	  }

	  if (isPath) {
	    const homePattern = platform === 'win32' ? /^~(\/|\\)/ : /^~\//;
	    if (homePattern.test(f) && home) {
	      f = resolve(home, f.slice(2));
	    } else {
	      f = resolve(f);
	    }
	  }

	  if (isUmask) {
	    try {
	      return umaskParse(f)
	    } catch (er) {
	      // let it warn later when we validate
	      return f
	    }
	  }

	  if (isNumber && !isNaN(f)) {
	    f = +f;
	  }

	  return f
	};

	parseField_1 = parseField;
	return parseField_1;
}

var setEnvs_1;
var hasRequiredSetEnvs;

function requireSetEnvs () {
	if (hasRequiredSetEnvs) return setEnvs_1;
	hasRequiredSetEnvs = 1;
	// Set environment variables for any non-default configs,
	// so that they're already there when we run lifecycle scripts.
	//
	// See https://github.com/npm/rfcs/pull/90

	// Return the env key if this is a thing that belongs in the env.
	// Ie, if the key isn't a @scope, //nerf.dart, or _private,
	// and the value is a string or array.  Otherwise return false.
	const envKey = (key, val) => {
	  return !/^[/@_]/.test(key) &&
	    (typeof envVal(val) === 'string') &&
	      `npm_config_${key.replace(/-/g, '_').toLowerCase()}`
	};

	const envVal = val => Array.isArray(val) ? val.map(v => envVal(v)).join('\n\n')
	  : val === null || val === undefined || val === false ? ''
	  : typeof val === 'object' ? null
	  : String(val);

	const sameConfigValue = (def, val) =>
	  !Array.isArray(val) || !Array.isArray(def) ? def === val
	  : sameArrayValue(def, val);

	const sameArrayValue = (def, val) => {
	  if (def.length !== val.length) {
	    return false
	  }

	  for (let i = 0; i < def.length; i++) {
	    /* istanbul ignore next - there are no array configs where the default
	     * is not an empty array, so this loop is a no-op, but it's the correct
	     * thing to do if we ever DO add a config like that. */
	    if (def[i] !== val[i]) {
	      return false
	    }
	  }
	  return true
	};

	const setEnv = (env, rawKey, rawVal) => {
	  const val = envVal(rawVal);
	  const key = envKey(rawKey, val);
	  if (key && val !== null) {
	    env[key] = val;
	  }
	};

	const setEnvs = (config) => {
	  // This ensures that all npm config values that are not the defaults are
	  // shared appropriately with child processes, without false positives.
	  const {
	    env,
	    defaults,
	    definitions,
	    list: [cliConf, envConf],
	  } = config;

	  env.INIT_CWD = process.cwd();

	  // if the key is deprecated, skip it always.
	  // if the key is the default value,
	  //   if the environ is NOT the default value,
	  //     set the environ
	  //   else skip it, it's fine
	  // if the key is NOT the default value,
	  //   if the env is setting it, then leave it (already set)
	  //   otherwise, set the env
	  const cliSet = new Set(Object.keys(cliConf));
	  const envSet = new Set(Object.keys(envConf));
	  for (const key in cliConf) {
	    const { deprecated, envExport = true } = definitions[key] || {};
	    if (deprecated || envExport === false) {
	      continue
	    }

	    if (sameConfigValue(defaults[key], cliConf[key])) {
	      // config is the default, if the env thought different, then we
	      // have to set it BACK to the default in the environment.
	      if (!sameConfigValue(envConf[key], cliConf[key])) {
	        setEnv(env, key, cliConf[key]);
	      }
	    } else {
	      // config is not the default.  if the env wasn't the one to set
	      // it that way, then we have to put it in the env
	      if (!(envSet.has(key) && !cliSet.has(key))) {
	        setEnv(env, key, cliConf[key]);
	      }
	    }
	  }

	  // also set some other common nice envs that we want to rely on
	  env.HOME = config.home;
	  // TODO this may not be the best away to persist these
	  env.npm_config_global_prefix = config.globalPrefix;
	  env.npm_config_local_prefix = config.localPrefix;
	  if (cliConf.editor) {
	    env.EDITOR = cliConf.editor;
	  }

	  // note: this doesn't afect the *current* node process, of course, since
	  // it's already started, but it does affect the options passed to scripts.
	  if (cliConf['node-options']) {
	    env.NODE_OPTIONS = cliConf['node-options'];
	  }
	  // the node-gyp bin uses this so we always set it
	  env.npm_config_node_gyp = cliConf['node-gyp'];
	  // this doesn't have a full definition so we manually export it here
	  env.npm_config_npm_version = cliConf['npm-version'] || 'unknown';
	  env.npm_execpath = config.npmBin;
	  env.NODE = env.npm_node_execpath = config.execPath;
	};

	setEnvs_1 = setEnvs;
	return setEnvs_1;
}

var errors$1;
var hasRequiredErrors$1;

function requireErrors$1 () {
	if (hasRequiredErrors$1) return errors$1;
	hasRequiredErrors$1 = 1;

	class ErrInvalidAuth extends Error {
	  constructor (problems) {
	    let message = 'Invalid auth configuration found: ';
	    message += problems.map((problem) => {
	      // istanbul ignore else
	      if (problem.action === 'delete') {
	        return `\`${problem.key}\` is not allowed in ${problem.where} config`
	      } else if (problem.action === 'rename') {
	        return `\`${problem.from}\` must be renamed to \`${problem.to}\` in ${problem.where} config`
	      }
	    }).join(', ');
	    message += '\nPlease run `npm config fix` to repair your configuration.`';
	    super(message);
	    this.code = 'ERR_INVALID_AUTH';
	    this.problems = problems;
	  }
	}

	errors$1 = {
	  ErrInvalidAuth,
	};
	return errors$1;
}

var typeDescription_1;
var hasRequiredTypeDescription;

function requireTypeDescription () {
	if (hasRequiredTypeDescription) return typeDescription_1;
	hasRequiredTypeDescription = 1;
	// return the description of the valid values of a field
	// returns a string for one thing, or an array of descriptions
	const typeDefs = requireTypeDefs();
	const typeDescription = t => {
	  if (!t || typeof t !== 'function' && typeof t !== 'object') {
	    return t
	  }

	  if (Array.isArray(t)) {
	    return t.map(t => typeDescription(t))
	  }

	  for (const { type, description } of Object.values(typeDefs)) {
	    if (type === t) {
	      return description || type
	    }
	  }

	  return t
	};
	typeDescription_1 = t => [].concat(typeDescription(t)).filter(t => t !== undefined);
	return typeDescription_1;
}

var lib$b;
var hasRequiredLib$b;

function requireLib$b () {
	if (hasRequiredLib$b) return lib$b;
	hasRequiredLib$b = 1;

	const INDENT = Symbol.for('indent');
	const NEWLINE = Symbol.for('newline');

	const DEFAULT_NEWLINE = '\n';
	const DEFAULT_INDENT = '  ';
	const BOM = /^\uFEFF/;

	// only respect indentation if we got a line break, otherwise squash it
	// things other than objects and arrays aren't indented, so ignore those
	// Important: in both of these regexps, the $1 capture group is the newline
	// or undefined, and the $2 capture group is the indent, or undefined.
	const FORMAT = /^\s*[{[]((?:\r?\n)+)([\s\t]*)/;
	const EMPTY = /^(?:\{\}|\[\])((?:\r?\n)+)?$/;

	// Node 20 puts single quotes around the token and a comma after it
	const UNEXPECTED_TOKEN = /^Unexpected token '?(.)'?(,)? /i;

	const hexify = (char) => {
	  const h = char.charCodeAt(0).toString(16).toUpperCase();
	  return `0x${h.length % 2 ? '0' : ''}${h}`
	};

	// Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)
	// because the buffer-to-string conversion in `fs.readFileSync()`
	// translates it to FEFF, the UTF-16 BOM.
	const stripBOM = (txt) => String(txt).replace(BOM, '');

	const makeParsedError = (msg, parsing, position = 0) => ({
	  message: `${msg} while parsing ${parsing}`,
	  position,
	});

	const parseError = (e, txt, context = 20) => {
	  let msg = e.message;

	  if (!txt) {
	    return makeParsedError(msg, 'empty string')
	  }

	  const badTokenMatch = msg.match(UNEXPECTED_TOKEN);
	  const badIndexMatch = msg.match(/ position\s+(\d+)/i);

	  if (badTokenMatch) {
	    msg = msg.replace(
	      UNEXPECTED_TOKEN,
	      `Unexpected token ${JSON.stringify(badTokenMatch[1])} (${hexify(badTokenMatch[1])})$2 `
	    );
	  }

	  let errIdx;
	  if (badIndexMatch) {
	    errIdx = +badIndexMatch[1];
	  } else /* istanbul ignore next - doesnt happen in Node 22 */ if (
	    msg.match(/^Unexpected end of JSON.*/i)
	  ) {
	    errIdx = txt.length - 1;
	  }

	  if (errIdx == null) {
	    return makeParsedError(msg, `'${txt.slice(0, context * 2)}'`)
	  }

	  const start = errIdx <= context ? 0 : errIdx - context;
	  const end = errIdx + context >= txt.length ? txt.length : errIdx + context;
	  const slice = `${start ? '...' : ''}${txt.slice(start, end)}${end === txt.length ? '' : '...'}`;

	  return makeParsedError(
	    msg,
	    `${txt === slice ? '' : 'near '}${JSON.stringify(slice)}`,
	    errIdx
	  )
	};

	class JSONParseError extends SyntaxError {
	  constructor (er, txt, context, caller) {
	    const metadata = parseError(er, txt, context);
	    super(metadata.message);
	    Object.assign(this, metadata);
	    this.code = 'EJSONPARSE';
	    this.systemError = er;
	    Error.captureStackTrace(this, caller || this.constructor);
	  }

	  get name () {
	    return this.constructor.name
	  }

	  set name (n) {}

	  get [Symbol.toStringTag] () {
	    return this.constructor.name
	  }
	}

	const parseJson = (txt, reviver) => {
	  const result = JSON.parse(txt, reviver);
	  if (result && typeof result === 'object') {
	    // get the indentation so that we can save it back nicely
	    // if the file starts with {" then we have an indent of '', ie, none
	    // otherwise, pick the indentation of the next line after the first \n If the
	    // pattern doesn't match, then it means no indentation. JSON.stringify ignores
	    // symbols, so this is reasonably safe. if the string is '{}' or '[]', then
	    // use the default 2-space indent.
	    const match = txt.match(EMPTY) || txt.match(FORMAT) || [null, '', ''];
	    result[NEWLINE] = match[1] ?? DEFAULT_NEWLINE;
	    result[INDENT] = match[2] ?? DEFAULT_INDENT;
	  }
	  return result
	};

	const parseJsonError = (raw, reviver, context) => {
	  const txt = stripBOM(raw);
	  try {
	    return parseJson(txt, reviver)
	  } catch (e) {
	    if (typeof raw !== 'string' && !Buffer.isBuffer(raw)) {
	      const msg = Array.isArray(raw) && raw.length === 0 ? 'an empty array' : String(raw);
	      throw Object.assign(
	        new TypeError(`Cannot parse ${msg}`),
	        { code: 'EJSONPARSE', systemError: e }
	      )
	    }
	    throw new JSONParseError(e, txt, context, parseJsonError)
	  }
	};

	lib$b = parseJsonError;
	parseJsonError.JSONParseError = JSONParseError;
	parseJsonError.noExceptions = (raw, reviver) => {
	  try {
	    return parseJson(stripBOM(raw), reviver)
	  } catch {
	    // no exceptions
	  }
	};
	return lib$b;
}

var updateDependencies_1;
var hasRequiredUpdateDependencies;

function requireUpdateDependencies () {
	if (hasRequiredUpdateDependencies) return updateDependencies_1;
	hasRequiredUpdateDependencies = 1;
	const depTypes = new Set([
	  'dependencies',
	  'optionalDependencies',
	  'devDependencies',
	  'peerDependencies',
	]);

	// sort alphabetically all types of deps for a given package
	const orderDeps = (content) => {
	  for (const type of depTypes) {
	    if (content && content[type]) {
	      content[type] = Object.keys(content[type])
	        .sort((a, b) => a.localeCompare(b, 'en'))
	        .reduce((res, key) => {
	          res[key] = content[type][key];
	          return res
	        }, {});
	    }
	  }
	  return content
	};

	const updateDependencies = ({ content, originalContent }) => {
	  const pkg = orderDeps({
	    ...content,
	  });

	  // optionalDependencies don't need to be repeated in two places
	  if (pkg.dependencies) {
	    if (pkg.optionalDependencies) {
	      for (const name of Object.keys(pkg.optionalDependencies)) {
	        delete pkg.dependencies[name];
	      }
	    }
	  }

	  const result = { ...originalContent };

	  // loop through all types of dependencies and update package json pkg
	  for (const type of depTypes) {
	    if (pkg[type]) {
	      result[type] = pkg[type];
	    }

	    // prune empty type props from resulting object
	    const emptyDepType =
	      pkg[type]
	      && typeof pkg === 'object'
	      && Object.keys(pkg[type]).length === 0;
	    if (emptyDepType) {
	      delete result[type];
	    }
	  }

	  // if original package.json had dep in peerDeps AND deps, preserve that.
	  const { dependencies: origProd, peerDependencies: origPeer } =
	    originalContent || {};
	  const { peerDependencies: newPeer } = result;
	  if (origProd && origPeer && newPeer) {
	    // we have original prod/peer deps, and new peer deps
	    // copy over any that were in both in the original
	    for (const name of Object.keys(origPeer)) {
	      if (origProd[name] !== undefined && newPeer[name] !== undefined) {
	        result.dependencies = result.dependencies || {};
	        result.dependencies[name] = newPeer[name];
	      }
	    }
	  }

	  return result
	};

	updateDependencies.knownKeys = depTypes;

	updateDependencies_1 = updateDependencies;
	return updateDependencies_1;
}

var updateScripts_1;
var hasRequiredUpdateScripts;

function requireUpdateScripts () {
	if (hasRequiredUpdateScripts) return updateScripts_1;
	hasRequiredUpdateScripts = 1;
	const updateScripts = ({ content, originalContent = {} }) => {
	  const newScripts = content.scripts;

	  if (!newScripts) {
	    return originalContent
	  }

	  // validate scripts content being appended
	  const hasInvalidScripts = () =>
	    Object.entries(newScripts)
	      .some(([key, value]) =>
	        typeof key !== 'string' || typeof value !== 'string');
	  if (hasInvalidScripts()) {
	    throw Object.assign(
	      new TypeError(
	        'package.json scripts should be a key-value pair of strings.'),
	      { code: 'ESCRIPTSINVALID' }
	    )
	  }

	  return {
	    ...originalContent,
	    scripts: {
	      ...newScripts,
	    },
	  }
	};

	updateScripts_1 = updateScripts;
	return updateScripts_1;
}

var updateWorkspaces_1;
var hasRequiredUpdateWorkspaces;

function requireUpdateWorkspaces () {
	if (hasRequiredUpdateWorkspaces) return updateWorkspaces_1;
	hasRequiredUpdateWorkspaces = 1;
	const updateWorkspaces = ({ content, originalContent = {} }) => {
	  const newWorkspaces = content.workspaces;

	  if (!newWorkspaces) {
	    return originalContent
	  }

	  // validate workspaces content being appended
	  const hasInvalidWorkspaces = () =>
	    newWorkspaces.some(w => !(typeof w === 'string'));
	  if (!newWorkspaces.length || hasInvalidWorkspaces()) {
	    throw Object.assign(
	      new TypeError('workspaces should be an array of strings.'),
	      { code: 'EWORKSPACESINVALID' }
	    )
	  }

	  return {
	    ...originalContent,
	    workspaces: [
	      ...newWorkspaces,
	    ],
	  }
	};

	updateWorkspaces_1 = updateWorkspaces;
	return updateWorkspaces_1;
}

/* eslint-disable max-len */

var hosts_1;
var hasRequiredHosts;

function requireHosts () {
	if (hasRequiredHosts) return hosts_1;
	hasRequiredHosts = 1;

	const maybeJoin = (...args) => args.every(arg => arg) ? args.join('') : '';
	const maybeEncode = (arg) => arg ? encodeURIComponent(arg) : '';
	const formatHashFragment = (f) => f.toLowerCase()
	  .replace(/^\W+/g, '') // strip leading non-characters
	  .replace(/(?<!\W)\W+$/, '') // strip trailing non-characters
	  .replace(/\//g, '') // strip all slashes
	  .replace(/\W+/g, '-'); // replace remaining non-characters with '-'

	const defaults = {
	  sshtemplate: ({ domain, user, project, committish }) =>
	    `git@${domain}:${user}/${project}.git${maybeJoin('#', committish)}`,
	  sshurltemplate: ({ domain, user, project, committish }) =>
	    `git+ssh://git@${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
	  edittemplate: ({ domain, user, project, committish, editpath, path }) =>
	    `https://${domain}/${user}/${project}${maybeJoin('/', editpath, '/', maybeEncode(committish || 'HEAD'), '/', path)}`,
	  browsetemplate: ({ domain, user, project, committish, treepath }) =>
	    `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}`,
	  browsetreetemplate: ({ domain, user, project, committish, treepath, path, fragment, hashformat }) =>
	    `https://${domain}/${user}/${project}/${treepath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
	  browseblobtemplate: ({ domain, user, project, committish, blobpath, path, fragment, hashformat }) =>
	    `https://${domain}/${user}/${project}/${blobpath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
	  docstemplate: ({ domain, user, project, treepath, committish }) =>
	    `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}#readme`,
	  httpstemplate: ({ auth, domain, user, project, committish }) =>
	    `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
	  filetemplate: ({ domain, user, project, committish, path }) =>
	    `https://${domain}/${user}/${project}/raw/${maybeEncode(committish || 'HEAD')}/${path}`,
	  shortcuttemplate: ({ type, user, project, committish }) =>
	    `${type}:${user}/${project}${maybeJoin('#', committish)}`,
	  pathtemplate: ({ user, project, committish }) =>
	    `${user}/${project}${maybeJoin('#', committish)}`,
	  bugstemplate: ({ domain, user, project }) =>
	    `https://${domain}/${user}/${project}/issues`,
	  hashformat: formatHashFragment,
	};

	const hosts = {};
	hosts.github = {
	  // First two are insecure and generally shouldn't be used any more, but
	  // they are still supported.
	  protocols: ['git:', 'http:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
	  domain: 'github.com',
	  treepath: 'tree',
	  blobpath: 'blob',
	  editpath: 'edit',
	  filetemplate: ({ auth, user, project, committish, path }) =>
	    `https://${maybeJoin(auth, '@')}raw.githubusercontent.com/${user}/${project}/${maybeEncode(committish || 'HEAD')}/${path}`,
	  gittemplate: ({ auth, domain, user, project, committish }) =>
	    `git://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
	  tarballtemplate: ({ domain, user, project, committish }) =>
	    `https://codeload.${domain}/${user}/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
	  extract: (url) => {
	    let [, user, project, type, committish] = url.pathname.split('/', 5);
	    if (type && type !== 'tree') {
	      return
	    }

	    if (!type) {
	      committish = url.hash.slice(1);
	    }

	    if (project && project.endsWith('.git')) {
	      project = project.slice(0, -4);
	    }

	    if (!user || !project) {
	      return
	    }

	    return { user, project, committish }
	  },
	};

	hosts.bitbucket = {
	  protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
	  domain: 'bitbucket.org',
	  treepath: 'src',
	  blobpath: 'src',
	  editpath: '?mode=edit',
	  edittemplate: ({ domain, user, project, committish, treepath, path, editpath }) =>
	    `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish || 'HEAD'), '/', path, editpath)}`,
	  tarballtemplate: ({ domain, user, project, committish }) =>
	    `https://${domain}/${user}/${project}/get/${maybeEncode(committish || 'HEAD')}.tar.gz`,
	  extract: (url) => {
	    let [, user, project, aux] = url.pathname.split('/', 4);
	    if (['get'].includes(aux)) {
	      return
	    }

	    if (project && project.endsWith('.git')) {
	      project = project.slice(0, -4);
	    }

	    if (!user || !project) {
	      return
	    }

	    return { user, project, committish: url.hash.slice(1) }
	  },
	};

	hosts.gitlab = {
	  protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
	  domain: 'gitlab.com',
	  treepath: 'tree',
	  blobpath: 'tree',
	  editpath: '-/edit',
	  httpstemplate: ({ auth, domain, user, project, committish }) =>
	    `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
	  tarballtemplate: ({ domain, user, project, committish }) =>
	    `https://${domain}/${user}/${project}/repository/archive.tar.gz?ref=${maybeEncode(committish || 'HEAD')}`,
	  extract: (url) => {
	    const path = url.pathname.slice(1);
	    if (path.includes('/-/') || path.includes('/archive.tar.gz')) {
	      return
	    }

	    const segments = path.split('/');
	    let project = segments.pop();
	    if (project.endsWith('.git')) {
	      project = project.slice(0, -4);
	    }

	    const user = segments.join('/');
	    if (!user || !project) {
	      return
	    }

	    return { user, project, committish: url.hash.slice(1) }
	  },
	};

	hosts.gist = {
	  protocols: ['git:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
	  domain: 'gist.github.com',
	  editpath: 'edit',
	  sshtemplate: ({ domain, project, committish }) =>
	    `git@${domain}:${project}.git${maybeJoin('#', committish)}`,
	  sshurltemplate: ({ domain, project, committish }) =>
	    `git+ssh://git@${domain}/${project}.git${maybeJoin('#', committish)}`,
	  edittemplate: ({ domain, user, project, committish, editpath }) =>
	    `https://${domain}/${user}/${project}${maybeJoin('/', maybeEncode(committish))}/${editpath}`,
	  browsetemplate: ({ domain, project, committish }) =>
	    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
	  browsetreetemplate: ({ domain, project, committish, path, hashformat }) =>
	    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
	  browseblobtemplate: ({ domain, project, committish, path, hashformat }) =>
	    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
	  docstemplate: ({ domain, project, committish }) =>
	    `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
	  httpstemplate: ({ domain, project, committish }) =>
	    `git+https://${domain}/${project}.git${maybeJoin('#', committish)}`,
	  filetemplate: ({ user, project, committish, path }) =>
	    `https://gist.githubusercontent.com/${user}/${project}/raw${maybeJoin('/', maybeEncode(committish))}/${path}`,
	  shortcuttemplate: ({ type, project, committish }) =>
	    `${type}:${project}${maybeJoin('#', committish)}`,
	  pathtemplate: ({ project, committish }) =>
	    `${project}${maybeJoin('#', committish)}`,
	  bugstemplate: ({ domain, project }) =>
	    `https://${domain}/${project}`,
	  gittemplate: ({ domain, project, committish }) =>
	    `git://${domain}/${project}.git${maybeJoin('#', committish)}`,
	  tarballtemplate: ({ project, committish }) =>
	    `https://codeload.github.com/gist/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
	  extract: (url) => {
	    let [, user, project, aux] = url.pathname.split('/', 4);
	    if (aux === 'raw') {
	      return
	    }

	    if (!project) {
	      if (!user) {
	        return
	      }

	      project = user;
	      user = null;
	    }

	    if (project.endsWith('.git')) {
	      project = project.slice(0, -4);
	    }

	    return { user, project, committish: url.hash.slice(1) }
	  },
	  hashformat: function (fragment) {
	    return fragment && 'file-' + formatHashFragment(fragment)
	  },
	};

	hosts.sourcehut = {
	  protocols: ['git+ssh:', 'https:'],
	  domain: 'git.sr.ht',
	  treepath: 'tree',
	  blobpath: 'tree',
	  filetemplate: ({ domain, user, project, committish, path }) =>
	    `https://${domain}/${user}/${project}/blob/${maybeEncode(committish) || 'HEAD'}/${path}`,
	  httpstemplate: ({ domain, user, project, committish }) =>
	    `https://${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
	  tarballtemplate: ({ domain, user, project, committish }) =>
	    `https://${domain}/${user}/${project}/archive/${maybeEncode(committish) || 'HEAD'}.tar.gz`,
	  bugstemplate: () => null,
	  extract: (url) => {
	    let [, user, project, aux] = url.pathname.split('/', 4);

	    // tarball url
	    if (['archive'].includes(aux)) {
	      return
	    }

	    if (project && project.endsWith('.git')) {
	      project = project.slice(0, -4);
	    }

	    if (!user || !project) {
	      return
	    }

	    return { user, project, committish: url.hash.slice(1) }
	  },
	};

	for (const [name, host] of Object.entries(hosts)) {
	  hosts[name] = Object.assign({}, defaults, host);
	}

	hosts_1 = hosts;
	return hosts_1;
}

var parseUrl;
var hasRequiredParseUrl;

function requireParseUrl () {
	if (hasRequiredParseUrl) return parseUrl;
	hasRequiredParseUrl = 1;
	const url = require$$0$1;

	const lastIndexOfBefore = (str, char, beforeChar) => {
	  const startPosition = str.indexOf(beforeChar);
	  return str.lastIndexOf(char, startPosition > -1 ? startPosition : Infinity)
	};

	const safeUrl = (u) => {
	  try {
	    return new url.URL(u)
	  } catch {
	    // this fn should never throw
	  }
	};

	// accepts input like git:github.com:user/repo and inserts the // after the first :
	const correctProtocol = (arg, protocols) => {
	  const firstColon = arg.indexOf(':');
	  const proto = arg.slice(0, firstColon + 1);
	  if (Object.prototype.hasOwnProperty.call(protocols, proto)) {
	    return arg
	  }

	  const firstAt = arg.indexOf('@');
	  if (firstAt > -1) {
	    if (firstAt > firstColon) {
	      return `git+ssh://${arg}`
	    } else {
	      return arg
	    }
	  }

	  const doubleSlash = arg.indexOf('//');
	  if (doubleSlash === firstColon + 1) {
	    return arg
	  }

	  return `${arg.slice(0, firstColon + 1)}//${arg.slice(firstColon + 1)}`
	};

	// attempt to correct an scp style url so that it will parse with `new URL()`
	const correctUrl = (giturl) => {
	  // ignore @ that come after the first hash since the denotes the start
	  // of a committish which can contain @ characters
	  const firstAt = lastIndexOfBefore(giturl, '@', '#');
	  // ignore colons that come after the hash since that could include colons such as:
	  // git@github.com:user/package-2#semver:^1.0.0
	  const lastColonBeforeHash = lastIndexOfBefore(giturl, ':', '#');

	  if (lastColonBeforeHash > firstAt) {
	    // the last : comes after the first @ (or there is no @)
	    // like it would in:
	    // proto://hostname.com:user/repo
	    // username@hostname.com:user/repo
	    // :password@hostname.com:user/repo
	    // username:password@hostname.com:user/repo
	    // proto://username@hostname.com:user/repo
	    // proto://:password@hostname.com:user/repo
	    // proto://username:password@hostname.com:user/repo
	    // then we replace the last : with a / to create a valid path
	    giturl = giturl.slice(0, lastColonBeforeHash) + '/' + giturl.slice(lastColonBeforeHash + 1);
	  }

	  if (lastIndexOfBefore(giturl, ':', '#') === -1 && giturl.indexOf('//') === -1) {
	    // we have no : at all
	    // as it would be in:
	    // username@hostname.com/user/repo
	    // then we prepend a protocol
	    giturl = `git+ssh://${giturl}`;
	  }

	  return giturl
	};

	parseUrl = (giturl, protocols) => {
	  const withProtocol = protocols ? correctProtocol(giturl, protocols) : giturl;
	  return safeUrl(withProtocol) || safeUrl(correctUrl(withProtocol))
	};
	return parseUrl;
}

var fromUrl;
var hasRequiredFromUrl;

function requireFromUrl () {
	if (hasRequiredFromUrl) return fromUrl;
	hasRequiredFromUrl = 1;

	const parseUrl = requireParseUrl();

	// look for github shorthand inputs, such as npm/cli
	const isGitHubShorthand = (arg) => {
	  // it cannot contain whitespace before the first #
	  // it cannot start with a / because that's probably an absolute file path
	  // but it must include a slash since repos are username/repository
	  // it cannot start with a . because that's probably a relative file path
	  // it cannot start with an @ because that's a scoped package if it passes the other tests
	  // it cannot contain a : before a # because that tells us that there's a protocol
	  // a second / may not exist before a #
	  const firstHash = arg.indexOf('#');
	  const firstSlash = arg.indexOf('/');
	  const secondSlash = arg.indexOf('/', firstSlash + 1);
	  const firstColon = arg.indexOf(':');
	  const firstSpace = /\s/.exec(arg);
	  const firstAt = arg.indexOf('@');

	  const spaceOnlyAfterHash = !firstSpace || (firstHash > -1 && firstSpace.index > firstHash);
	  const atOnlyAfterHash = firstAt === -1 || (firstHash > -1 && firstAt > firstHash);
	  const colonOnlyAfterHash = firstColon === -1 || (firstHash > -1 && firstColon > firstHash);
	  const secondSlashOnlyAfterHash = secondSlash === -1 || (firstHash > -1 && secondSlash > firstHash);
	  const hasSlash = firstSlash > 0;
	  // if a # is found, what we really want to know is that the character
	  // immediately before # is not a /
	  const doesNotEndWithSlash = firstHash > -1 ? arg[firstHash - 1] !== '/' : !arg.endsWith('/');
	  const doesNotStartWithDot = !arg.startsWith('.');

	  return spaceOnlyAfterHash && hasSlash && doesNotEndWithSlash &&
	    doesNotStartWithDot && atOnlyAfterHash && colonOnlyAfterHash &&
	    secondSlashOnlyAfterHash
	};

	fromUrl = (giturl, opts, { gitHosts, protocols }) => {
	  if (!giturl) {
	    return
	  }

	  const correctedUrl = isGitHubShorthand(giturl) ? `github:${giturl}` : giturl;
	  const parsed = parseUrl(correctedUrl, protocols);
	  if (!parsed) {
	    return
	  }

	  const gitHostShortcut = gitHosts.byShortcut[parsed.protocol];
	  const gitHostDomain = gitHosts.byDomain[parsed.hostname.startsWith('www.')
	    ? parsed.hostname.slice(4)
	    : parsed.hostname];
	  const gitHostName = gitHostShortcut || gitHostDomain;
	  if (!gitHostName) {
	    return
	  }

	  const gitHostInfo = gitHosts[gitHostShortcut || gitHostDomain];
	  let auth = null;
	  if (protocols[parsed.protocol]?.auth && (parsed.username || parsed.password)) {
	    auth = `${parsed.username}${parsed.password ? ':' + parsed.password : ''}`;
	  }

	  let committish = null;
	  let user = null;
	  let project = null;
	  let defaultRepresentation = null;

	  try {
	    if (gitHostShortcut) {
	      let pathname = parsed.pathname.startsWith('/') ? parsed.pathname.slice(1) : parsed.pathname;
	      const firstAt = pathname.indexOf('@');
	      // we ignore auth for shortcuts, so just trim it out
	      if (firstAt > -1) {
	        pathname = pathname.slice(firstAt + 1);
	      }

	      const lastSlash = pathname.lastIndexOf('/');
	      if (lastSlash > -1) {
	        user = decodeURIComponent(pathname.slice(0, lastSlash));
	        // we want nulls only, never empty strings
	        if (!user) {
	          user = null;
	        }
	        project = decodeURIComponent(pathname.slice(lastSlash + 1));
	      } else {
	        project = decodeURIComponent(pathname);
	      }

	      if (project.endsWith('.git')) {
	        project = project.slice(0, -4);
	      }

	      if (parsed.hash) {
	        committish = decodeURIComponent(parsed.hash.slice(1));
	      }

	      defaultRepresentation = 'shortcut';
	    } else {
	      if (!gitHostInfo.protocols.includes(parsed.protocol)) {
	        return
	      }

	      const segments = gitHostInfo.extract(parsed);
	      if (!segments) {
	        return
	      }

	      user = segments.user && decodeURIComponent(segments.user);
	      project = decodeURIComponent(segments.project);
	      committish = decodeURIComponent(segments.committish);
	      defaultRepresentation = protocols[parsed.protocol]?.name || parsed.protocol.slice(0, -1);
	    }
	  } catch (err) {
	    /* istanbul ignore else */
	    if (err instanceof URIError) {
	      return
	    } else {
	      throw err
	    }
	  }

	  return [gitHostName, user, auth, project, committish, defaultRepresentation, opts]
	};
	return fromUrl;
}

var lib$a;
var hasRequiredLib$a;

function requireLib$a () {
	if (hasRequiredLib$a) return lib$a;
	hasRequiredLib$a = 1;

	const { LRUCache } = /*@__PURE__*/ requireCommonjs$4();
	const hosts = requireHosts();
	const fromUrl = requireFromUrl();
	const parseUrl = requireParseUrl();

	const cache = new LRUCache({ max: 1000 });

	function unknownHostedUrl (url) {
	  try {
	    const {
	      protocol,
	      hostname,
	      pathname,
	    } = new URL(url);

	    if (!hostname) {
	      return null
	    }

	    const proto = /(?:git\+)http:$/.test(protocol) ? 'http:' : 'https:';
	    const path = pathname.replace(/\.git$/, '');
	    return `${proto}//${hostname}${path}`
	  } catch {
	    return null
	  }
	}

	class GitHost {
	  constructor (type, user, auth, project, committish, defaultRepresentation, opts = {}) {
	    Object.assign(this, GitHost.#gitHosts[type], {
	      type,
	      user,
	      auth,
	      project,
	      committish,
	      default: defaultRepresentation,
	      opts,
	    });
	  }

	  static #gitHosts = { byShortcut: {}, byDomain: {} }
	  static #protocols = {
	    'git+ssh:': { name: 'sshurl' },
	    'ssh:': { name: 'sshurl' },
	    'git+https:': { name: 'https', auth: true },
	    'git:': { auth: true },
	    'http:': { auth: true },
	    'https:': { auth: true },
	    'git+http:': { auth: true },
	  }

	  static addHost (name, host) {
	    GitHost.#gitHosts[name] = host;
	    GitHost.#gitHosts.byDomain[host.domain] = name;
	    GitHost.#gitHosts.byShortcut[`${name}:`] = name;
	    GitHost.#protocols[`${name}:`] = { name };
	  }

	  static fromUrl (giturl, opts) {
	    if (typeof giturl !== 'string') {
	      return
	    }

	    const key = giturl + JSON.stringify(opts || {});

	    if (!cache.has(key)) {
	      const hostArgs = fromUrl(giturl, opts, {
	        gitHosts: GitHost.#gitHosts,
	        protocols: GitHost.#protocols,
	      });
	      cache.set(key, hostArgs ? new GitHost(...hostArgs) : undefined);
	    }

	    return cache.get(key)
	  }

	  static fromManifest (manifest, opts = {}) {
	    if (!manifest || typeof manifest !== 'object') {
	      return
	    }

	    const r = manifest.repository;
	    // TODO: look into also checking the `bugs`/`homepage` URLs

	    const rurl = r && (
	      typeof r === 'string'
	        ? r
	        : typeof r === 'object' && typeof r.url === 'string'
	          ? r.url
	          : null
	    );

	    if (!rurl) {
	      throw new Error('no repository')
	    }

	    const info = (rurl && GitHost.fromUrl(rurl.replace(/^git\+/, ''), opts)) || null;
	    if (info) {
	      return info
	    }
	    const unk = unknownHostedUrl(rurl);
	    return GitHost.fromUrl(unk, opts) || unk
	  }

	  static parseUrl (url) {
	    return parseUrl(url)
	  }

	  #fill (template, opts) {
	    if (typeof template !== 'function') {
	      return null
	    }

	    const options = { ...this, ...this.opts, ...opts };

	    // the path should always be set so we don't end up with 'undefined' in urls
	    if (!options.path) {
	      options.path = '';
	    }

	    // template functions will insert the leading slash themselves
	    if (options.path.startsWith('/')) {
	      options.path = options.path.slice(1);
	    }

	    if (options.noCommittish) {
	      options.committish = null;
	    }

	    const result = template(options);
	    return options.noGitPlus && result.startsWith('git+') ? result.slice(4) : result
	  }

	  hash () {
	    return this.committish ? `#${this.committish}` : ''
	  }

	  ssh (opts) {
	    return this.#fill(this.sshtemplate, opts)
	  }

	  sshurl (opts) {
	    return this.#fill(this.sshurltemplate, opts)
	  }

	  browse (path, ...args) {
	    // not a string, treat path as opts
	    if (typeof path !== 'string') {
	      return this.#fill(this.browsetemplate, path)
	    }

	    if (typeof args[0] !== 'string') {
	      return this.#fill(this.browsetreetemplate, { ...args[0], path })
	    }

	    return this.#fill(this.browsetreetemplate, { ...args[1], fragment: args[0], path })
	  }

	  // If the path is known to be a file, then browseFile should be used. For some hosts
	  // the url is the same as browse, but for others like GitHub a file can use both `/tree/`
	  // and `/blob/` in the path. When using a default committish of `HEAD` then the `/tree/`
	  // path will redirect to a specific commit. Using the `/blob/` path avoids this and
	  // does not redirect to a different commit.
	  browseFile (path, ...args) {
	    if (typeof args[0] !== 'string') {
	      return this.#fill(this.browseblobtemplate, { ...args[0], path })
	    }

	    return this.#fill(this.browseblobtemplate, { ...args[1], fragment: args[0], path })
	  }

	  docs (opts) {
	    return this.#fill(this.docstemplate, opts)
	  }

	  bugs (opts) {
	    return this.#fill(this.bugstemplate, opts)
	  }

	  https (opts) {
	    return this.#fill(this.httpstemplate, opts)
	  }

	  git (opts) {
	    return this.#fill(this.gittemplate, opts)
	  }

	  shortcut (opts) {
	    return this.#fill(this.shortcuttemplate, opts)
	  }

	  path (opts) {
	    return this.#fill(this.pathtemplate, opts)
	  }

	  tarball (opts) {
	    return this.#fill(this.tarballtemplate, { ...opts, noCommittish: false })
	  }

	  file (path, opts) {
	    return this.#fill(this.filetemplate, { ...opts, path })
	  }

	  edit (path, opts) {
	    return this.#fill(this.edittemplate, { ...opts, path })
	  }

	  getDefaultRepresentation () {
	    return this.default
	  }

	  toString (opts) {
	    if (this.default && typeof this[this.default] === 'function') {
	      return this[this.default](opts)
	    }

	    return this.sshurl(opts)
	  }
	}

	for (const [name, host] of Object.entries(hosts)) {
	  GitHost.addHost(name, host);
	}

	lib$a = GitHost;
	return lib$a;
}

var commonjs$2 = {};

var commonjs$1 = {};

var balancedMatch;
var hasRequiredBalancedMatch;

function requireBalancedMatch () {
	if (hasRequiredBalancedMatch) return balancedMatch;
	hasRequiredBalancedMatch = 1;
	balancedMatch = balanced;
	function balanced(a, b, str) {
	  if (a instanceof RegExp) a = maybeMatch(a, str);
	  if (b instanceof RegExp) b = maybeMatch(b, str);

	  var r = range(a, b, str);

	  return r && {
	    start: r[0],
	    end: r[1],
	    pre: str.slice(0, r[0]),
	    body: str.slice(r[0] + a.length, r[1]),
	    post: str.slice(r[1] + b.length)
	  };
	}

	function maybeMatch(reg, str) {
	  var m = str.match(reg);
	  return m ? m[0] : null;
	}

	balanced.range = range;
	function range(a, b, str) {
	  var begs, beg, left, right, result;
	  var ai = str.indexOf(a);
	  var bi = str.indexOf(b, ai + 1);
	  var i = ai;

	  if (ai >= 0 && bi > 0) {
	    if(a===b) {
	      return [ai, bi];
	    }
	    begs = [];
	    left = str.length;

	    while (i >= 0 && !result) {
	      if (i == ai) {
	        begs.push(i);
	        ai = str.indexOf(a, i + 1);
	      } else if (begs.length == 1) {
	        result = [ begs.pop(), bi ];
	      } else {
	        beg = begs.pop();
	        if (beg < left) {
	          left = beg;
	          right = bi;
	        }

	        bi = str.indexOf(b, i + 1);
	      }

	      i = ai < bi && ai >= 0 ? ai : bi;
	    }

	    if (begs.length) {
	      result = [ left, right ];
	    }
	  }

	  return result;
	}
	return balancedMatch;
}

var braceExpansion;
var hasRequiredBraceExpansion;

function requireBraceExpansion () {
	if (hasRequiredBraceExpansion) return braceExpansion;
	hasRequiredBraceExpansion = 1;
	var balanced = requireBalancedMatch();

	braceExpansion = expandTop;

	var escSlash = '\0SLASH'+Math.random()+'\0';
	var escOpen = '\0OPEN'+Math.random()+'\0';
	var escClose = '\0CLOSE'+Math.random()+'\0';
	var escComma = '\0COMMA'+Math.random()+'\0';
	var escPeriod = '\0PERIOD'+Math.random()+'\0';

	function numeric(str) {
	  return parseInt(str, 10) == str
	    ? parseInt(str, 10)
	    : str.charCodeAt(0);
	}

	function escapeBraces(str) {
	  return str.split('\\\\').join(escSlash)
	            .split('\\{').join(escOpen)
	            .split('\\}').join(escClose)
	            .split('\\,').join(escComma)
	            .split('\\.').join(escPeriod);
	}

	function unescapeBraces(str) {
	  return str.split(escSlash).join('\\')
	            .split(escOpen).join('{')
	            .split(escClose).join('}')
	            .split(escComma).join(',')
	            .split(escPeriod).join('.');
	}


	// Basically just str.split(","), but handling cases
	// where we have nested braced sections, which should be
	// treated as individual members, like {a,{b,c},d}
	function parseCommaParts(str) {
	  if (!str)
	    return [''];

	  var parts = [];
	  var m = balanced('{', '}', str);

	  if (!m)
	    return str.split(',');

	  var pre = m.pre;
	  var body = m.body;
	  var post = m.post;
	  var p = pre.split(',');

	  p[p.length-1] += '{' + body + '}';
	  var postParts = parseCommaParts(post);
	  if (post.length) {
	    p[p.length-1] += postParts.shift();
	    p.push.apply(p, postParts);
	  }

	  parts.push.apply(parts, p);

	  return parts;
	}

	function expandTop(str) {
	  if (!str)
	    return [];

	  // I don't know why Bash 4.3 does this, but it does.
	  // Anything starting with {} will have the first two bytes preserved
	  // but *only* at the top level, so {},a}b will not expand to anything,
	  // but a{},b}c will be expanded to [a}c,abc].
	  // One could argue that this is a bug in Bash, but since the goal of
	  // this module is to match Bash's rules, we escape a leading {}
	  if (str.substr(0, 2) === '{}') {
	    str = '\\{\\}' + str.substr(2);
	  }

	  return expand(escapeBraces(str), true).map(unescapeBraces);
	}

	function embrace(str) {
	  return '{' + str + '}';
	}
	function isPadded(el) {
	  return /^-?0\d/.test(el);
	}

	function lte(i, y) {
	  return i <= y;
	}
	function gte(i, y) {
	  return i >= y;
	}

	function expand(str, isTop) {
	  var expansions = [];

	  var m = balanced('{', '}', str);
	  if (!m) return [str];

	  // no need to expand pre, since it is guaranteed to be free of brace-sets
	  var pre = m.pre;
	  var post = m.post.length
	    ? expand(m.post, false)
	    : [''];

	  if (/\$$/.test(m.pre)) {    
	    for (var k = 0; k < post.length; k++) {
	      var expansion = pre+ '{' + m.body + '}' + post[k];
	      expansions.push(expansion);
	    }
	  } else {
	    var isNumericSequence = /^-?\d+\.\.-?\d+(?:\.\.-?\d+)?$/.test(m.body);
	    var isAlphaSequence = /^[a-zA-Z]\.\.[a-zA-Z](?:\.\.-?\d+)?$/.test(m.body);
	    var isSequence = isNumericSequence || isAlphaSequence;
	    var isOptions = m.body.indexOf(',') >= 0;
	    if (!isSequence && !isOptions) {
	      // {a},b}
	      if (m.post.match(/,(?!,).*\}/)) {
	        str = m.pre + '{' + m.body + escClose + m.post;
	        return expand(str);
	      }
	      return [str];
	    }

	    var n;
	    if (isSequence) {
	      n = m.body.split(/\.\./);
	    } else {
	      n = parseCommaParts(m.body);
	      if (n.length === 1) {
	        // x{{a,b}}y ==> x{a}y x{b}y
	        n = expand(n[0], false).map(embrace);
	        if (n.length === 1) {
	          return post.map(function(p) {
	            return m.pre + n[0] + p;
	          });
	        }
	      }
	    }

	    // at this point, n is the parts, and we know it's not a comma set
	    // with a single entry.
	    var N;

	    if (isSequence) {
	      var x = numeric(n[0]);
	      var y = numeric(n[1]);
	      var width = Math.max(n[0].length, n[1].length);
	      var incr = n.length == 3
	        ? Math.abs(numeric(n[2]))
	        : 1;
	      var test = lte;
	      var reverse = y < x;
	      if (reverse) {
	        incr *= -1;
	        test = gte;
	      }
	      var pad = n.some(isPadded);

	      N = [];

	      for (var i = x; test(i, y); i += incr) {
	        var c;
	        if (isAlphaSequence) {
	          c = String.fromCharCode(i);
	          if (c === '\\')
	            c = '';
	        } else {
	          c = String(i);
	          if (pad) {
	            var need = width - c.length;
	            if (need > 0) {
	              var z = new Array(need + 1).join('0');
	              if (i < 0)
	                c = '-' + z + c.slice(1);
	              else
	                c = z + c;
	            }
	          }
	        }
	        N.push(c);
	      }
	    } else {
	      N = [];

	      for (var j = 0; j < n.length; j++) {
	        N.push.apply(N, expand(n[j], false));
	      }
	    }

	    for (var j = 0; j < N.length; j++) {
	      for (var k = 0; k < post.length; k++) {
	        var expansion = pre + N[j] + post[k];
	        if (!isTop || isSequence || expansion)
	          expansions.push(expansion);
	      }
	    }
	  }

	  return expansions;
	}
	return braceExpansion;
}

var assertValidPattern = {};

var hasRequiredAssertValidPattern;

function requireAssertValidPattern () {
	if (hasRequiredAssertValidPattern) return assertValidPattern;
	hasRequiredAssertValidPattern = 1;
	Object.defineProperty(assertValidPattern, "__esModule", { value: true });
	assertValidPattern.assertValidPattern = void 0;
	const MAX_PATTERN_LENGTH = 1024 * 64;
	const assertValidPattern$1 = (pattern) => {
	    if (typeof pattern !== 'string') {
	        throw new TypeError('invalid pattern');
	    }
	    if (pattern.length > MAX_PATTERN_LENGTH) {
	        throw new TypeError('pattern is too long');
	    }
	};
	assertValidPattern.assertValidPattern = assertValidPattern$1;
	
	return assertValidPattern;
}

var ast = {};

var braceExpressions = {};

var hasRequiredBraceExpressions;

function requireBraceExpressions () {
	if (hasRequiredBraceExpressions) return braceExpressions;
	hasRequiredBraceExpressions = 1;
	// translate the various posix character classes into unicode properties
	// this works across all unicode locales
	Object.defineProperty(braceExpressions, "__esModule", { value: true });
	braceExpressions.parseClass = void 0;
	// { <posix class>: [<translation>, /u flag required, negated]
	const posixClasses = {
	    '[:alnum:]': ['\\p{L}\\p{Nl}\\p{Nd}', true],
	    '[:alpha:]': ['\\p{L}\\p{Nl}', true],
	    '[:ascii:]': ['\\x' + '00-\\x' + '7f', false],
	    '[:blank:]': ['\\p{Zs}\\t', true],
	    '[:cntrl:]': ['\\p{Cc}', true],
	    '[:digit:]': ['\\p{Nd}', true],
	    '[:graph:]': ['\\p{Z}\\p{C}', true, true],
	    '[:lower:]': ['\\p{Ll}', true],
	    '[:print:]': ['\\p{C}', true],
	    '[:punct:]': ['\\p{P}', true],
	    '[:space:]': ['\\p{Z}\\t\\r\\n\\v\\f', true],
	    '[:upper:]': ['\\p{Lu}', true],
	    '[:word:]': ['\\p{L}\\p{Nl}\\p{Nd}\\p{Pc}', true],
	    '[:xdigit:]': ['A-Fa-f0-9', false],
	};
	// only need to escape a few things inside of brace expressions
	// escapes: [ \ ] -
	const braceEscape = (s) => s.replace(/[[\]\\-]/g, '\\$&');
	// escape all regexp magic characters
	const regexpEscape = (s) => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
	// everything has already been escaped, we just have to join
	const rangesToString = (ranges) => ranges.join('');
	// takes a glob string at a posix brace expression, and returns
	// an equivalent regular expression source, and boolean indicating
	// whether the /u flag needs to be applied, and the number of chars
	// consumed to parse the character class.
	// This also removes out of order ranges, and returns ($.) if the
	// entire class just no good.
	const parseClass = (glob, position) => {
	    const pos = position;
	    /* c8 ignore start */
	    if (glob.charAt(pos) !== '[') {
	        throw new Error('not in a brace expression');
	    }
	    /* c8 ignore stop */
	    const ranges = [];
	    const negs = [];
	    let i = pos + 1;
	    let sawStart = false;
	    let uflag = false;
	    let escaping = false;
	    let negate = false;
	    let endPos = pos;
	    let rangeStart = '';
	    WHILE: while (i < glob.length) {
	        const c = glob.charAt(i);
	        if ((c === '!' || c === '^') && i === pos + 1) {
	            negate = true;
	            i++;
	            continue;
	        }
	        if (c === ']' && sawStart && !escaping) {
	            endPos = i + 1;
	            break;
	        }
	        sawStart = true;
	        if (c === '\\') {
	            if (!escaping) {
	                escaping = true;
	                i++;
	                continue;
	            }
	            // escaped \ char, fall through and treat like normal char
	        }
	        if (c === '[' && !escaping) {
	            // either a posix class, a collation equivalent, or just a [
	            for (const [cls, [unip, u, neg]] of Object.entries(posixClasses)) {
	                if (glob.startsWith(cls, i)) {
	                    // invalid, [a-[] is fine, but not [a-[:alpha]]
	                    if (rangeStart) {
	                        return ['$.', false, glob.length - pos, true];
	                    }
	                    i += cls.length;
	                    if (neg)
	                        negs.push(unip);
	                    else
	                        ranges.push(unip);
	                    uflag = uflag || u;
	                    continue WHILE;
	                }
	            }
	        }
	        // now it's just a normal character, effectively
	        escaping = false;
	        if (rangeStart) {
	            // throw this range away if it's not valid, but others
	            // can still match.
	            if (c > rangeStart) {
	                ranges.push(braceEscape(rangeStart) + '-' + braceEscape(c));
	            }
	            else if (c === rangeStart) {
	                ranges.push(braceEscape(c));
	            }
	            rangeStart = '';
	            i++;
	            continue;
	        }
	        // now might be the start of a range.
	        // can be either c-d or c-] or c<more...>] or c] at this point
	        if (glob.startsWith('-]', i + 1)) {
	            ranges.push(braceEscape(c + '-'));
	            i += 2;
	            continue;
	        }
	        if (glob.startsWith('-', i + 1)) {
	            rangeStart = c;
	            i += 2;
	            continue;
	        }
	        // not the start of a range, just a single character
	        ranges.push(braceEscape(c));
	        i++;
	    }
	    if (endPos < i) {
	        // didn't see the end of the class, not a valid class,
	        // but might still be valid as a literal match.
	        return ['', false, 0, false];
	    }
	    // if we got no ranges and no negates, then we have a range that
	    // cannot possibly match anything, and that poisons the whole glob
	    if (!ranges.length && !negs.length) {
	        return ['$.', false, glob.length - pos, true];
	    }
	    // if we got one positive range, and it's a single character, then that's
	    // not actually a magic pattern, it's just that one literal character.
	    // we should not treat that as "magic", we should just return the literal
	    // character. [_] is a perfectly valid way to escape glob magic chars.
	    if (negs.length === 0 &&
	        ranges.length === 1 &&
	        /^\\?.$/.test(ranges[0]) &&
	        !negate) {
	        const r = ranges[0].length === 2 ? ranges[0].slice(-1) : ranges[0];
	        return [regexpEscape(r), false, endPos - pos, false];
	    }
	    const sranges = '[' + (negate ? '^' : '') + rangesToString(ranges) + ']';
	    const snegs = '[' + (negate ? '' : '^') + rangesToString(negs) + ']';
	    const comb = ranges.length && negs.length
	        ? '(' + sranges + '|' + snegs + ')'
	        : ranges.length
	            ? sranges
	            : snegs;
	    return [comb, uflag, endPos - pos, true];
	};
	braceExpressions.parseClass = parseClass;
	
	return braceExpressions;
}

var _unescape = {};

var hasRequired_unescape;

function require_unescape () {
	if (hasRequired_unescape) return _unescape;
	hasRequired_unescape = 1;
	Object.defineProperty(_unescape, "__esModule", { value: true });
	_unescape.unescape = void 0;
	/**
	 * Un-escape a string that has been escaped with {@link escape}.
	 *
	 * If the {@link windowsPathsNoEscape} option is used, then square-brace
	 * escapes are removed, but not backslash escapes.  For example, it will turn
	 * the string `'[*]'` into `*`, but it will not turn `'\\*'` into `'*'`,
	 * becuase `\` is a path separator in `windowsPathsNoEscape` mode.
	 *
	 * When `windowsPathsNoEscape` is not set, then both brace escapes and
	 * backslash escapes are removed.
	 *
	 * Slashes (and backslashes in `windowsPathsNoEscape` mode) cannot be escaped
	 * or unescaped.
	 */
	const unescape = (s, { windowsPathsNoEscape = false, } = {}) => {
	    return windowsPathsNoEscape
	        ? s.replace(/\[([^\/\\])\]/g, '$1')
	        : s.replace(/((?!\\).|^)\[([^\/\\])\]/g, '$1$2').replace(/\\([^\/])/g, '$1');
	};
	_unescape.unescape = unescape;
	
	return _unescape;
}

var hasRequiredAst;

function requireAst () {
	if (hasRequiredAst) return ast;
	hasRequiredAst = 1;
	// parse a single path portion
	Object.defineProperty(ast, "__esModule", { value: true });
	ast.AST = void 0;
	const brace_expressions_js_1 = requireBraceExpressions();
	const unescape_js_1 = require_unescape();
	const types = new Set(['!', '?', '+', '*', '@']);
	const isExtglobType = (c) => types.has(c);
	// Patterns that get prepended to bind to the start of either the
	// entire string, or just a single path portion, to prevent dots
	// and/or traversal patterns, when needed.
	// Exts don't need the ^ or / bit, because the root binds that already.
	const startNoTraversal = '(?!(?:^|/)\\.\\.?(?:$|/))';
	const startNoDot = '(?!\\.)';
	// characters that indicate a start of pattern needs the "no dots" bit,
	// because a dot *might* be matched. ( is not in the list, because in
	// the case of a child extglob, it will handle the prevention itself.
	const addPatternStart = new Set(['[', '.']);
	// cases where traversal is A-OK, no dot prevention needed
	const justDots = new Set(['..', '.']);
	const reSpecials = new Set('().*{}+?[]^$\\!');
	const regExpEscape = (s) => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
	// any single thing other than /
	const qmark = '[^/]';
	// * => any number of characters
	const star = qmark + '*?';
	// use + when we need to ensure that *something* matches, because the * is
	// the only thing in the path portion.
	const starNoEmpty = qmark + '+?';
	// remove the \ chars that we added if we end up doing a nonmagic compare
	// const deslash = (s: string) => s.replace(/\\(.)/g, '$1')
	class AST {
	    type;
	    #root;
	    #hasMagic;
	    #uflag = false;
	    #parts = [];
	    #parent;
	    #parentIndex;
	    #negs;
	    #filledNegs = false;
	    #options;
	    #toString;
	    // set to true if it's an extglob with no children
	    // (which really means one child of '')
	    #emptyExt = false;
	    constructor(type, parent, options = {}) {
	        this.type = type;
	        // extglobs are inherently magical
	        if (type)
	            this.#hasMagic = true;
	        this.#parent = parent;
	        this.#root = this.#parent ? this.#parent.#root : this;
	        this.#options = this.#root === this ? options : this.#root.#options;
	        this.#negs = this.#root === this ? [] : this.#root.#negs;
	        if (type === '!' && !this.#root.#filledNegs)
	            this.#negs.push(this);
	        this.#parentIndex = this.#parent ? this.#parent.#parts.length : 0;
	    }
	    get hasMagic() {
	        /* c8 ignore start */
	        if (this.#hasMagic !== undefined)
	            return this.#hasMagic;
	        /* c8 ignore stop */
	        for (const p of this.#parts) {
	            if (typeof p === 'string')
	                continue;
	            if (p.type || p.hasMagic)
	                return (this.#hasMagic = true);
	        }
	        // note: will be undefined until we generate the regexp src and find out
	        return this.#hasMagic;
	    }
	    // reconstructs the pattern
	    toString() {
	        if (this.#toString !== undefined)
	            return this.#toString;
	        if (!this.type) {
	            return (this.#toString = this.#parts.map(p => String(p)).join(''));
	        }
	        else {
	            return (this.#toString =
	                this.type + '(' + this.#parts.map(p => String(p)).join('|') + ')');
	        }
	    }
	    #fillNegs() {
	        /* c8 ignore start */
	        if (this !== this.#root)
	            throw new Error('should only call on root');
	        if (this.#filledNegs)
	            return this;
	        /* c8 ignore stop */
	        // call toString() once to fill this out
	        this.toString();
	        this.#filledNegs = true;
	        let n;
	        while ((n = this.#negs.pop())) {
	            if (n.type !== '!')
	                continue;
	            // walk up the tree, appending everthing that comes AFTER parentIndex
	            let p = n;
	            let pp = p.#parent;
	            while (pp) {
	                for (let i = p.#parentIndex + 1; !pp.type && i < pp.#parts.length; i++) {
	                    for (const part of n.#parts) {
	                        /* c8 ignore start */
	                        if (typeof part === 'string') {
	                            throw new Error('string part in extglob AST??');
	                        }
	                        /* c8 ignore stop */
	                        part.copyIn(pp.#parts[i]);
	                    }
	                }
	                p = pp;
	                pp = p.#parent;
	            }
	        }
	        return this;
	    }
	    push(...parts) {
	        for (const p of parts) {
	            if (p === '')
	                continue;
	            /* c8 ignore start */
	            if (typeof p !== 'string' && !(p instanceof AST && p.#parent === this)) {
	                throw new Error('invalid part: ' + p);
	            }
	            /* c8 ignore stop */
	            this.#parts.push(p);
	        }
	    }
	    toJSON() {
	        const ret = this.type === null
	            ? this.#parts.slice().map(p => (typeof p === 'string' ? p : p.toJSON()))
	            : [this.type, ...this.#parts.map(p => p.toJSON())];
	        if (this.isStart() && !this.type)
	            ret.unshift([]);
	        if (this.isEnd() &&
	            (this === this.#root ||
	                (this.#root.#filledNegs && this.#parent?.type === '!'))) {
	            ret.push({});
	        }
	        return ret;
	    }
	    isStart() {
	        if (this.#root === this)
	            return true;
	        // if (this.type) return !!this.#parent?.isStart()
	        if (!this.#parent?.isStart())
	            return false;
	        if (this.#parentIndex === 0)
	            return true;
	        // if everything AHEAD of this is a negation, then it's still the "start"
	        const p = this.#parent;
	        for (let i = 0; i < this.#parentIndex; i++) {
	            const pp = p.#parts[i];
	            if (!(pp instanceof AST && pp.type === '!')) {
	                return false;
	            }
	        }
	        return true;
	    }
	    isEnd() {
	        if (this.#root === this)
	            return true;
	        if (this.#parent?.type === '!')
	            return true;
	        if (!this.#parent?.isEnd())
	            return false;
	        if (!this.type)
	            return this.#parent?.isEnd();
	        // if not root, it'll always have a parent
	        /* c8 ignore start */
	        const pl = this.#parent ? this.#parent.#parts.length : 0;
	        /* c8 ignore stop */
	        return this.#parentIndex === pl - 1;
	    }
	    copyIn(part) {
	        if (typeof part === 'string')
	            this.push(part);
	        else
	            this.push(part.clone(this));
	    }
	    clone(parent) {
	        const c = new AST(this.type, parent);
	        for (const p of this.#parts) {
	            c.copyIn(p);
	        }
	        return c;
	    }
	    static #parseAST(str, ast, pos, opt) {
	        let escaping = false;
	        let inBrace = false;
	        let braceStart = -1;
	        let braceNeg = false;
	        if (ast.type === null) {
	            // outside of a extglob, append until we find a start
	            let i = pos;
	            let acc = '';
	            while (i < str.length) {
	                const c = str.charAt(i++);
	                // still accumulate escapes at this point, but we do ignore
	                // starts that are escaped
	                if (escaping || c === '\\') {
	                    escaping = !escaping;
	                    acc += c;
	                    continue;
	                }
	                if (inBrace) {
	                    if (i === braceStart + 1) {
	                        if (c === '^' || c === '!') {
	                            braceNeg = true;
	                        }
	                    }
	                    else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {
	                        inBrace = false;
	                    }
	                    acc += c;
	                    continue;
	                }
	                else if (c === '[') {
	                    inBrace = true;
	                    braceStart = i;
	                    braceNeg = false;
	                    acc += c;
	                    continue;
	                }
	                if (!opt.noext && isExtglobType(c) && str.charAt(i) === '(') {
	                    ast.push(acc);
	                    acc = '';
	                    const ext = new AST(c, ast);
	                    i = AST.#parseAST(str, ext, i, opt);
	                    ast.push(ext);
	                    continue;
	                }
	                acc += c;
	            }
	            ast.push(acc);
	            return i;
	        }
	        // some kind of extglob, pos is at the (
	        // find the next | or )
	        let i = pos + 1;
	        let part = new AST(null, ast);
	        const parts = [];
	        let acc = '';
	        while (i < str.length) {
	            const c = str.charAt(i++);
	            // still accumulate escapes at this point, but we do ignore
	            // starts that are escaped
	            if (escaping || c === '\\') {
	                escaping = !escaping;
	                acc += c;
	                continue;
	            }
	            if (inBrace) {
	                if (i === braceStart + 1) {
	                    if (c === '^' || c === '!') {
	                        braceNeg = true;
	                    }
	                }
	                else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {
	                    inBrace = false;
	                }
	                acc += c;
	                continue;
	            }
	            else if (c === '[') {
	                inBrace = true;
	                braceStart = i;
	                braceNeg = false;
	                acc += c;
	                continue;
	            }
	            if (isExtglobType(c) && str.charAt(i) === '(') {
	                part.push(acc);
	                acc = '';
	                const ext = new AST(c, part);
	                part.push(ext);
	                i = AST.#parseAST(str, ext, i, opt);
	                continue;
	            }
	            if (c === '|') {
	                part.push(acc);
	                acc = '';
	                parts.push(part);
	                part = new AST(null, ast);
	                continue;
	            }
	            if (c === ')') {
	                if (acc === '' && ast.#parts.length === 0) {
	                    ast.#emptyExt = true;
	                }
	                part.push(acc);
	                acc = '';
	                ast.push(...parts, part);
	                return i;
	            }
	            acc += c;
	        }
	        // unfinished extglob
	        // if we got here, it was a malformed extglob! not an extglob, but
	        // maybe something else in there.
	        ast.type = null;
	        ast.#hasMagic = undefined;
	        ast.#parts = [str.substring(pos - 1)];
	        return i;
	    }
	    static fromGlob(pattern, options = {}) {
	        const ast = new AST(null, undefined, options);
	        AST.#parseAST(pattern, ast, 0, options);
	        return ast;
	    }
	    // returns the regular expression if there's magic, or the unescaped
	    // string if not.
	    toMMPattern() {
	        // should only be called on root
	        /* c8 ignore start */
	        if (this !== this.#root)
	            return this.#root.toMMPattern();
	        /* c8 ignore stop */
	        const glob = this.toString();
	        const [re, body, hasMagic, uflag] = this.toRegExpSource();
	        // if we're in nocase mode, and not nocaseMagicOnly, then we do
	        // still need a regular expression if we have to case-insensitively
	        // match capital/lowercase characters.
	        const anyMagic = hasMagic ||
	            this.#hasMagic ||
	            (this.#options.nocase &&
	                !this.#options.nocaseMagicOnly &&
	                glob.toUpperCase() !== glob.toLowerCase());
	        if (!anyMagic) {
	            return body;
	        }
	        const flags = (this.#options.nocase ? 'i' : '') + (uflag ? 'u' : '');
	        return Object.assign(new RegExp(`^${re}$`, flags), {
	            _src: re,
	            _glob: glob,
	        });
	    }
	    get options() {
	        return this.#options;
	    }
	    // returns the string match, the regexp source, whether there's magic
	    // in the regexp (so a regular expression is required) and whether or
	    // not the uflag is needed for the regular expression (for posix classes)
	    // TODO: instead of injecting the start/end at this point, just return
	    // the BODY of the regexp, along with the start/end portions suitable
	    // for binding the start/end in either a joined full-path makeRe context
	    // (where we bind to (^|/), or a standalone matchPart context (where
	    // we bind to ^, and not /).  Otherwise slashes get duped!
	    //
	    // In part-matching mode, the start is:
	    // - if not isStart: nothing
	    // - if traversal possible, but not allowed: ^(?!\.\.?$)
	    // - if dots allowed or not possible: ^
	    // - if dots possible and not allowed: ^(?!\.)
	    // end is:
	    // - if not isEnd(): nothing
	    // - else: $
	    //
	    // In full-path matching mode, we put the slash at the START of the
	    // pattern, so start is:
	    // - if first pattern: same as part-matching mode
	    // - if not isStart(): nothing
	    // - if traversal possible, but not allowed: /(?!\.\.?(?:$|/))
	    // - if dots allowed or not possible: /
	    // - if dots possible and not allowed: /(?!\.)
	    // end is:
	    // - if last pattern, same as part-matching mode
	    // - else nothing
	    //
	    // Always put the (?:$|/) on negated tails, though, because that has to be
	    // there to bind the end of the negated pattern portion, and it's easier to
	    // just stick it in now rather than try to inject it later in the middle of
	    // the pattern.
	    //
	    // We can just always return the same end, and leave it up to the caller
	    // to know whether it's going to be used joined or in parts.
	    // And, if the start is adjusted slightly, can do the same there:
	    // - if not isStart: nothing
	    // - if traversal possible, but not allowed: (?:/|^)(?!\.\.?$)
	    // - if dots allowed or not possible: (?:/|^)
	    // - if dots possible and not allowed: (?:/|^)(?!\.)
	    //
	    // But it's better to have a simpler binding without a conditional, for
	    // performance, so probably better to return both start options.
	    //
	    // Then the caller just ignores the end if it's not the first pattern,
	    // and the start always gets applied.
	    //
	    // But that's always going to be $ if it's the ending pattern, or nothing,
	    // so the caller can just attach $ at the end of the pattern when building.
	    //
	    // So the todo is:
	    // - better detect what kind of start is needed
	    // - return both flavors of starting pattern
	    // - attach $ at the end of the pattern when creating the actual RegExp
	    //
	    // Ah, but wait, no, that all only applies to the root when the first pattern
	    // is not an extglob. If the first pattern IS an extglob, then we need all
	    // that dot prevention biz to live in the extglob portions, because eg
	    // +(*|.x*) can match .xy but not .yx.
	    //
	    // So, return the two flavors if it's #root and the first child is not an
	    // AST, otherwise leave it to the child AST to handle it, and there,
	    // use the (?:^|/) style of start binding.
	    //
	    // Even simplified further:
	    // - Since the start for a join is eg /(?!\.) and the start for a part
	    // is ^(?!\.), we can just prepend (?!\.) to the pattern (either root
	    // or start or whatever) and prepend ^ or / at the Regexp construction.
	    toRegExpSource(allowDot) {
	        const dot = allowDot ?? !!this.#options.dot;
	        if (this.#root === this)
	            this.#fillNegs();
	        if (!this.type) {
	            const noEmpty = this.isStart() && this.isEnd();
	            const src = this.#parts
	                .map(p => {
	                const [re, _, hasMagic, uflag] = typeof p === 'string'
	                    ? AST.#parseGlob(p, this.#hasMagic, noEmpty)
	                    : p.toRegExpSource(allowDot);
	                this.#hasMagic = this.#hasMagic || hasMagic;
	                this.#uflag = this.#uflag || uflag;
	                return re;
	            })
	                .join('');
	            let start = '';
	            if (this.isStart()) {
	                if (typeof this.#parts[0] === 'string') {
	                    // this is the string that will match the start of the pattern,
	                    // so we need to protect against dots and such.
	                    // '.' and '..' cannot match unless the pattern is that exactly,
	                    // even if it starts with . or dot:true is set.
	                    const dotTravAllowed = this.#parts.length === 1 && justDots.has(this.#parts[0]);
	                    if (!dotTravAllowed) {
	                        const aps = addPatternStart;
	                        // check if we have a possibility of matching . or ..,
	                        // and prevent that.
	                        const needNoTrav = 
	                        // dots are allowed, and the pattern starts with [ or .
	                        (dot && aps.has(src.charAt(0))) ||
	                            // the pattern starts with \., and then [ or .
	                            (src.startsWith('\\.') && aps.has(src.charAt(2))) ||
	                            // the pattern starts with \.\., and then [ or .
	                            (src.startsWith('\\.\\.') && aps.has(src.charAt(4)));
	                        // no need to prevent dots if it can't match a dot, or if a
	                        // sub-pattern will be preventing it anyway.
	                        const needNoDot = !dot && !allowDot && aps.has(src.charAt(0));
	                        start = needNoTrav ? startNoTraversal : needNoDot ? startNoDot : '';
	                    }
	                }
	            }
	            // append the "end of path portion" pattern to negation tails
	            let end = '';
	            if (this.isEnd() &&
	                this.#root.#filledNegs &&
	                this.#parent?.type === '!') {
	                end = '(?:$|\\/)';
	            }
	            const final = start + src + end;
	            return [
	                final,
	                (0, unescape_js_1.unescape)(src),
	                (this.#hasMagic = !!this.#hasMagic),
	                this.#uflag,
	            ];
	        }
	        // We need to calculate the body *twice* if it's a repeat pattern
	        // at the start, once in nodot mode, then again in dot mode, so a
	        // pattern like *(?) can match 'x.y'
	        const repeated = this.type === '*' || this.type === '+';
	        // some kind of extglob
	        const start = this.type === '!' ? '(?:(?!(?:' : '(?:';
	        let body = this.#partsToRegExp(dot);
	        if (this.isStart() && this.isEnd() && !body && this.type !== '!') {
	            // invalid extglob, has to at least be *something* present, if it's
	            // the entire path portion.
	            const s = this.toString();
	            this.#parts = [s];
	            this.type = null;
	            this.#hasMagic = undefined;
	            return [s, (0, unescape_js_1.unescape)(this.toString()), false, false];
	        }
	        // XXX abstract out this map method
	        let bodyDotAllowed = !repeated || allowDot || dot || !startNoDot
	            ? ''
	            : this.#partsToRegExp(true);
	        if (bodyDotAllowed === body) {
	            bodyDotAllowed = '';
	        }
	        if (bodyDotAllowed) {
	            body = `(?:${body})(?:${bodyDotAllowed})*?`;
	        }
	        // an empty !() is exactly equivalent to a starNoEmpty
	        let final = '';
	        if (this.type === '!' && this.#emptyExt) {
	            final = (this.isStart() && !dot ? startNoDot : '') + starNoEmpty;
	        }
	        else {
	            const close = this.type === '!'
	                ? // !() must match something,but !(x) can match ''
	                    '))' +
	                        (this.isStart() && !dot && !allowDot ? startNoDot : '') +
	                        star +
	                        ')'
	                : this.type === '@'
	                    ? ')'
	                    : this.type === '?'
	                        ? ')?'
	                        : this.type === '+' && bodyDotAllowed
	                            ? ')'
	                            : this.type === '*' && bodyDotAllowed
	                                ? `)?`
	                                : `)${this.type}`;
	            final = start + body + close;
	        }
	        return [
	            final,
	            (0, unescape_js_1.unescape)(body),
	            (this.#hasMagic = !!this.#hasMagic),
	            this.#uflag,
	        ];
	    }
	    #partsToRegExp(dot) {
	        return this.#parts
	            .map(p => {
	            // extglob ASTs should only contain parent ASTs
	            /* c8 ignore start */
	            if (typeof p === 'string') {
	                throw new Error('string type in extglob ast??');
	            }
	            /* c8 ignore stop */
	            // can ignore hasMagic, because extglobs are already always magic
	            const [re, _, _hasMagic, uflag] = p.toRegExpSource(dot);
	            this.#uflag = this.#uflag || uflag;
	            return re;
	        })
	            .filter(p => !(this.isStart() && this.isEnd()) || !!p)
	            .join('|');
	    }
	    static #parseGlob(glob, hasMagic, noEmpty = false) {
	        let escaping = false;
	        let re = '';
	        let uflag = false;
	        for (let i = 0; i < glob.length; i++) {
	            const c = glob.charAt(i);
	            if (escaping) {
	                escaping = false;
	                re += (reSpecials.has(c) ? '\\' : '') + c;
	                continue;
	            }
	            if (c === '\\') {
	                if (i === glob.length - 1) {
	                    re += '\\\\';
	                }
	                else {
	                    escaping = true;
	                }
	                continue;
	            }
	            if (c === '[') {
	                const [src, needUflag, consumed, magic] = (0, brace_expressions_js_1.parseClass)(glob, i);
	                if (consumed) {
	                    re += src;
	                    uflag = uflag || needUflag;
	                    i += consumed - 1;
	                    hasMagic = hasMagic || magic;
	                    continue;
	                }
	            }
	            if (c === '*') {
	                if (noEmpty && glob === '*')
	                    re += starNoEmpty;
	                else
	                    re += star;
	                hasMagic = true;
	                continue;
	            }
	            if (c === '?') {
	                re += qmark;
	                hasMagic = true;
	                continue;
	            }
	            re += regExpEscape(c);
	        }
	        return [re, (0, unescape_js_1.unescape)(glob), !!hasMagic, uflag];
	    }
	}
	ast.AST = AST;
	
	return ast;
}

var _escape$1 = {};

var hasRequired_escape$1;

function require_escape$1 () {
	if (hasRequired_escape$1) return _escape$1;
	hasRequired_escape$1 = 1;
	Object.defineProperty(_escape$1, "__esModule", { value: true });
	_escape$1.escape = void 0;
	/**
	 * Escape all magic characters in a glob pattern.
	 *
	 * If the {@link windowsPathsNoEscape | GlobOptions.windowsPathsNoEscape}
	 * option is used, then characters are escaped by wrapping in `[]`, because
	 * a magic character wrapped in a character class can only be satisfied by
	 * that exact character.  In this mode, `\` is _not_ escaped, because it is
	 * not interpreted as a magic character, but instead as a path separator.
	 */
	const escape = (s, { windowsPathsNoEscape = false, } = {}) => {
	    // don't need to escape +@! because we escape the parens
	    // that make those magic, and escaping ! as [!] isn't valid,
	    // because [!]] is a valid glob class meaning not ']'.
	    return windowsPathsNoEscape
	        ? s.replace(/[?*()[\]]/g, '[$&]')
	        : s.replace(/[?*()[\]\\]/g, '\\$&');
	};
	_escape$1.escape = escape;
	
	return _escape$1;
}

var hasRequiredCommonjs$2;

function requireCommonjs$2 () {
	if (hasRequiredCommonjs$2) return commonjs$1;
	hasRequiredCommonjs$2 = 1;
	(function (exports) {
		var __importDefault = (commonjs$1 && commonjs$1.__importDefault) || function (mod) {
		    return (mod && mod.__esModule) ? mod : { "default": mod };
		};
		Object.defineProperty(exports, "__esModule", { value: true });
		exports.unescape = exports.escape = exports.AST = exports.Minimatch = exports.match = exports.makeRe = exports.braceExpand = exports.defaults = exports.filter = exports.GLOBSTAR = exports.sep = exports.minimatch = void 0;
		const brace_expansion_1 = __importDefault(requireBraceExpansion());
		const assert_valid_pattern_js_1 = requireAssertValidPattern();
		const ast_js_1 = requireAst();
		const escape_js_1 = require_escape$1();
		const unescape_js_1 = require_unescape();
		const minimatch = (p, pattern, options = {}) => {
		    (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);
		    // shortcut: comments match nothing.
		    if (!options.nocomment && pattern.charAt(0) === '#') {
		        return false;
		    }
		    return new Minimatch(pattern, options).match(p);
		};
		exports.minimatch = minimatch;
		// Optimized checking for the most common glob patterns.
		const starDotExtRE = /^\*+([^+@!?\*\[\(]*)$/;
		const starDotExtTest = (ext) => (f) => !f.startsWith('.') && f.endsWith(ext);
		const starDotExtTestDot = (ext) => (f) => f.endsWith(ext);
		const starDotExtTestNocase = (ext) => {
		    ext = ext.toLowerCase();
		    return (f) => !f.startsWith('.') && f.toLowerCase().endsWith(ext);
		};
		const starDotExtTestNocaseDot = (ext) => {
		    ext = ext.toLowerCase();
		    return (f) => f.toLowerCase().endsWith(ext);
		};
		const starDotStarRE = /^\*+\.\*+$/;
		const starDotStarTest = (f) => !f.startsWith('.') && f.includes('.');
		const starDotStarTestDot = (f) => f !== '.' && f !== '..' && f.includes('.');
		const dotStarRE = /^\.\*+$/;
		const dotStarTest = (f) => f !== '.' && f !== '..' && f.startsWith('.');
		const starRE = /^\*+$/;
		const starTest = (f) => f.length !== 0 && !f.startsWith('.');
		const starTestDot = (f) => f.length !== 0 && f !== '.' && f !== '..';
		const qmarksRE = /^\?+([^+@!?\*\[\(]*)?$/;
		const qmarksTestNocase = ([$0, ext = '']) => {
		    const noext = qmarksTestNoExt([$0]);
		    if (!ext)
		        return noext;
		    ext = ext.toLowerCase();
		    return (f) => noext(f) && f.toLowerCase().endsWith(ext);
		};
		const qmarksTestNocaseDot = ([$0, ext = '']) => {
		    const noext = qmarksTestNoExtDot([$0]);
		    if (!ext)
		        return noext;
		    ext = ext.toLowerCase();
		    return (f) => noext(f) && f.toLowerCase().endsWith(ext);
		};
		const qmarksTestDot = ([$0, ext = '']) => {
		    const noext = qmarksTestNoExtDot([$0]);
		    return !ext ? noext : (f) => noext(f) && f.endsWith(ext);
		};
		const qmarksTest = ([$0, ext = '']) => {
		    const noext = qmarksTestNoExt([$0]);
		    return !ext ? noext : (f) => noext(f) && f.endsWith(ext);
		};
		const qmarksTestNoExt = ([$0]) => {
		    const len = $0.length;
		    return (f) => f.length === len && !f.startsWith('.');
		};
		const qmarksTestNoExtDot = ([$0]) => {
		    const len = $0.length;
		    return (f) => f.length === len && f !== '.' && f !== '..';
		};
		/* c8 ignore start */
		const defaultPlatform = (typeof process === 'object' && process
		    ? (typeof process.env === 'object' &&
		        process.env &&
		        process.env.__MINIMATCH_TESTING_PLATFORM__) ||
		        process.platform
		    : 'posix');
		const path = {
		    win32: { sep: '\\' },
		    posix: { sep: '/' },
		};
		/* c8 ignore stop */
		exports.sep = defaultPlatform === 'win32' ? path.win32.sep : path.posix.sep;
		exports.minimatch.sep = exports.sep;
		exports.GLOBSTAR = Symbol('globstar **');
		exports.minimatch.GLOBSTAR = exports.GLOBSTAR;
		// any single thing other than /
		// don't need to escape / when using new RegExp()
		const qmark = '[^/]';
		// * => any number of characters
		const star = qmark + '*?';
		// ** when dots are allowed.  Anything goes, except .. and .
		// not (^ or / followed by one or two dots followed by $ or /),
		// followed by anything, any number of times.
		const twoStarDot = '(?:(?!(?:\\/|^)(?:\\.{1,2})($|\\/)).)*?';
		// not a ^ or / followed by a dot,
		// followed by anything, any number of times.
		const twoStarNoDot = '(?:(?!(?:\\/|^)\\.).)*?';
		const filter = (pattern, options = {}) => (p) => (0, exports.minimatch)(p, pattern, options);
		exports.filter = filter;
		exports.minimatch.filter = exports.filter;
		const ext = (a, b = {}) => Object.assign({}, a, b);
		const defaults = (def) => {
		    if (!def || typeof def !== 'object' || !Object.keys(def).length) {
		        return exports.minimatch;
		    }
		    const orig = exports.minimatch;
		    const m = (p, pattern, options = {}) => orig(p, pattern, ext(def, options));
		    return Object.assign(m, {
		        Minimatch: class Minimatch extends orig.Minimatch {
		            constructor(pattern, options = {}) {
		                super(pattern, ext(def, options));
		            }
		            static defaults(options) {
		                return orig.defaults(ext(def, options)).Minimatch;
		            }
		        },
		        AST: class AST extends orig.AST {
		            /* c8 ignore start */
		            constructor(type, parent, options = {}) {
		                super(type, parent, ext(def, options));
		            }
		            /* c8 ignore stop */
		            static fromGlob(pattern, options = {}) {
		                return orig.AST.fromGlob(pattern, ext(def, options));
		            }
		        },
		        unescape: (s, options = {}) => orig.unescape(s, ext(def, options)),
		        escape: (s, options = {}) => orig.escape(s, ext(def, options)),
		        filter: (pattern, options = {}) => orig.filter(pattern, ext(def, options)),
		        defaults: (options) => orig.defaults(ext(def, options)),
		        makeRe: (pattern, options = {}) => orig.makeRe(pattern, ext(def, options)),
		        braceExpand: (pattern, options = {}) => orig.braceExpand(pattern, ext(def, options)),
		        match: (list, pattern, options = {}) => orig.match(list, pattern, ext(def, options)),
		        sep: orig.sep,
		        GLOBSTAR: exports.GLOBSTAR,
		    });
		};
		exports.defaults = defaults;
		exports.minimatch.defaults = exports.defaults;
		// Brace expansion:
		// a{b,c}d -> abd acd
		// a{b,}c -> abc ac
		// a{0..3}d -> a0d a1d a2d a3d
		// a{b,c{d,e}f}g -> abg acdfg acefg
		// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg
		//
		// Invalid sets are not expanded.
		// a{2..}b -> a{2..}b
		// a{b}c -> a{b}c
		const braceExpand = (pattern, options = {}) => {
		    (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);
		    // Thanks to Yeting Li <https://github.com/yetingli> for
		    // improving this regexp to avoid a ReDOS vulnerability.
		    if (options.nobrace || !/\{(?:(?!\{).)*\}/.test(pattern)) {
		        // shortcut. no need to expand.
		        return [pattern];
		    }
		    return (0, brace_expansion_1.default)(pattern);
		};
		exports.braceExpand = braceExpand;
		exports.minimatch.braceExpand = exports.braceExpand;
		// parse a component of the expanded set.
		// At this point, no pattern may contain "/" in it
		// so we're going to return a 2d array, where each entry is the full
		// pattern, split on '/', and then turned into a regular expression.
		// A regexp is made at the end which joins each array with an
		// escaped /, and another full one which joins each regexp with |.
		//
		// Following the lead of Bash 4.1, note that "**" only has special meaning
		// when it is the *only* thing in a path portion.  Otherwise, any series
		// of * is equivalent to a single *.  Globstar behavior is enabled by
		// default, and can be disabled by setting options.noglobstar.
		const makeRe = (pattern, options = {}) => new Minimatch(pattern, options).makeRe();
		exports.makeRe = makeRe;
		exports.minimatch.makeRe = exports.makeRe;
		const match = (list, pattern, options = {}) => {
		    const mm = new Minimatch(pattern, options);
		    list = list.filter(f => mm.match(f));
		    if (mm.options.nonull && !list.length) {
		        list.push(pattern);
		    }
		    return list;
		};
		exports.match = match;
		exports.minimatch.match = exports.match;
		// replace stuff like \* with *
		const globMagic = /[?*]|[+@!]\(.*?\)|\[|\]/;
		const regExpEscape = (s) => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
		class Minimatch {
		    options;
		    set;
		    pattern;
		    windowsPathsNoEscape;
		    nonegate;
		    negate;
		    comment;
		    empty;
		    preserveMultipleSlashes;
		    partial;
		    globSet;
		    globParts;
		    nocase;
		    isWindows;
		    platform;
		    windowsNoMagicRoot;
		    regexp;
		    constructor(pattern, options = {}) {
		        (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);
		        options = options || {};
		        this.options = options;
		        this.pattern = pattern;
		        this.platform = options.platform || defaultPlatform;
		        this.isWindows = this.platform === 'win32';
		        this.windowsPathsNoEscape =
		            !!options.windowsPathsNoEscape || options.allowWindowsEscape === false;
		        if (this.windowsPathsNoEscape) {
		            this.pattern = this.pattern.replace(/\\/g, '/');
		        }
		        this.preserveMultipleSlashes = !!options.preserveMultipleSlashes;
		        this.regexp = null;
		        this.negate = false;
		        this.nonegate = !!options.nonegate;
		        this.comment = false;
		        this.empty = false;
		        this.partial = !!options.partial;
		        this.nocase = !!this.options.nocase;
		        this.windowsNoMagicRoot =
		            options.windowsNoMagicRoot !== undefined
		                ? options.windowsNoMagicRoot
		                : !!(this.isWindows && this.nocase);
		        this.globSet = [];
		        this.globParts = [];
		        this.set = [];
		        // make the set of regexps etc.
		        this.make();
		    }
		    hasMagic() {
		        if (this.options.magicalBraces && this.set.length > 1) {
		            return true;
		        }
		        for (const pattern of this.set) {
		            for (const part of pattern) {
		                if (typeof part !== 'string')
		                    return true;
		            }
		        }
		        return false;
		    }
		    debug(..._) { }
		    make() {
		        const pattern = this.pattern;
		        const options = this.options;
		        // empty patterns and comments match nothing.
		        if (!options.nocomment && pattern.charAt(0) === '#') {
		            this.comment = true;
		            return;
		        }
		        if (!pattern) {
		            this.empty = true;
		            return;
		        }
		        // step 1: figure out negation, etc.
		        this.parseNegate();
		        // step 2: expand braces
		        this.globSet = [...new Set(this.braceExpand())];
		        if (options.debug) {
		            this.debug = (...args) => console.error(...args);
		        }
		        this.debug(this.pattern, this.globSet);
		        // step 3: now we have a set, so turn each one into a series of
		        // path-portion matching patterns.
		        // These will be regexps, except in the case of "**", which is
		        // set to the GLOBSTAR object for globstar behavior,
		        // and will not contain any / characters
		        //
		        // First, we preprocess to make the glob pattern sets a bit simpler
		        // and deduped.  There are some perf-killing patterns that can cause
		        // problems with a glob walk, but we can simplify them down a bit.
		        const rawGlobParts = this.globSet.map(s => this.slashSplit(s));
		        this.globParts = this.preprocess(rawGlobParts);
		        this.debug(this.pattern, this.globParts);
		        // glob --> regexps
		        let set = this.globParts.map((s, _, __) => {
		            if (this.isWindows && this.windowsNoMagicRoot) {
		                // check if it's a drive or unc path.
		                const isUNC = s[0] === '' &&
		                    s[1] === '' &&
		                    (s[2] === '?' || !globMagic.test(s[2])) &&
		                    !globMagic.test(s[3]);
		                const isDrive = /^[a-z]:/i.test(s[0]);
		                if (isUNC) {
		                    return [...s.slice(0, 4), ...s.slice(4).map(ss => this.parse(ss))];
		                }
		                else if (isDrive) {
		                    return [s[0], ...s.slice(1).map(ss => this.parse(ss))];
		                }
		            }
		            return s.map(ss => this.parse(ss));
		        });
		        this.debug(this.pattern, set);
		        // filter out everything that didn't compile properly.
		        this.set = set.filter(s => s.indexOf(false) === -1);
		        // do not treat the ? in UNC paths as magic
		        if (this.isWindows) {
		            for (let i = 0; i < this.set.length; i++) {
		                const p = this.set[i];
		                if (p[0] === '' &&
		                    p[1] === '' &&
		                    this.globParts[i][2] === '?' &&
		                    typeof p[3] === 'string' &&
		                    /^[a-z]:$/i.test(p[3])) {
		                    p[2] = '?';
		                }
		            }
		        }
		        this.debug(this.pattern, this.set);
		    }
		    // various transforms to equivalent pattern sets that are
		    // faster to process in a filesystem walk.  The goal is to
		    // eliminate what we can, and push all ** patterns as far
		    // to the right as possible, even if it increases the number
		    // of patterns that we have to process.
		    preprocess(globParts) {
		        // if we're not in globstar mode, then turn all ** into *
		        if (this.options.noglobstar) {
		            for (let i = 0; i < globParts.length; i++) {
		                for (let j = 0; j < globParts[i].length; j++) {
		                    if (globParts[i][j] === '**') {
		                        globParts[i][j] = '*';
		                    }
		                }
		            }
		        }
		        const { optimizationLevel = 1 } = this.options;
		        if (optimizationLevel >= 2) {
		            // aggressive optimization for the purpose of fs walking
		            globParts = this.firstPhasePreProcess(globParts);
		            globParts = this.secondPhasePreProcess(globParts);
		        }
		        else if (optimizationLevel >= 1) {
		            // just basic optimizations to remove some .. parts
		            globParts = this.levelOneOptimize(globParts);
		        }
		        else {
		            // just collapse multiple ** portions into one
		            globParts = this.adjascentGlobstarOptimize(globParts);
		        }
		        return globParts;
		    }
		    // just get rid of adjascent ** portions
		    adjascentGlobstarOptimize(globParts) {
		        return globParts.map(parts => {
		            let gs = -1;
		            while (-1 !== (gs = parts.indexOf('**', gs + 1))) {
		                let i = gs;
		                while (parts[i + 1] === '**') {
		                    i++;
		                }
		                if (i !== gs) {
		                    parts.splice(gs, i - gs);
		                }
		            }
		            return parts;
		        });
		    }
		    // get rid of adjascent ** and resolve .. portions
		    levelOneOptimize(globParts) {
		        return globParts.map(parts => {
		            parts = parts.reduce((set, part) => {
		                const prev = set[set.length - 1];
		                if (part === '**' && prev === '**') {
		                    return set;
		                }
		                if (part === '..') {
		                    if (prev && prev !== '..' && prev !== '.' && prev !== '**') {
		                        set.pop();
		                        return set;
		                    }
		                }
		                set.push(part);
		                return set;
		            }, []);
		            return parts.length === 0 ? [''] : parts;
		        });
		    }
		    levelTwoFileOptimize(parts) {
		        if (!Array.isArray(parts)) {
		            parts = this.slashSplit(parts);
		        }
		        let didSomething = false;
		        do {
		            didSomething = false;
		            // <pre>/<e>/<rest> -> <pre>/<rest>
		            if (!this.preserveMultipleSlashes) {
		                for (let i = 1; i < parts.length - 1; i++) {
		                    const p = parts[i];
		                    // don't squeeze out UNC patterns
		                    if (i === 1 && p === '' && parts[0] === '')
		                        continue;
		                    if (p === '.' || p === '') {
		                        didSomething = true;
		                        parts.splice(i, 1);
		                        i--;
		                    }
		                }
		                if (parts[0] === '.' &&
		                    parts.length === 2 &&
		                    (parts[1] === '.' || parts[1] === '')) {
		                    didSomething = true;
		                    parts.pop();
		                }
		            }
		            // <pre>/<p>/../<rest> -> <pre>/<rest>
		            let dd = 0;
		            while (-1 !== (dd = parts.indexOf('..', dd + 1))) {
		                const p = parts[dd - 1];
		                if (p && p !== '.' && p !== '..' && p !== '**') {
		                    didSomething = true;
		                    parts.splice(dd - 1, 2);
		                    dd -= 2;
		                }
		            }
		        } while (didSomething);
		        return parts.length === 0 ? [''] : parts;
		    }
		    // First phase: single-pattern processing
		    // <pre> is 1 or more portions
		    // <rest> is 1 or more portions
		    // <p> is any portion other than ., .., '', or **
		    // <e> is . or ''
		    //
		    // **/.. is *brutal* for filesystem walking performance, because
		    // it effectively resets the recursive walk each time it occurs,
		    // and ** cannot be reduced out by a .. pattern part like a regexp
		    // or most strings (other than .., ., and '') can be.
		    //
		    // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}
		    // <pre>/<e>/<rest> -> <pre>/<rest>
		    // <pre>/<p>/../<rest> -> <pre>/<rest>
		    // **/**/<rest> -> **/<rest>
		    //
		    // **/*/<rest> -> */**/<rest> <== not valid because ** doesn't follow
		    // this WOULD be allowed if ** did follow symlinks, or * didn't
		    firstPhasePreProcess(globParts) {
		        let didSomething = false;
		        do {
		            didSomething = false;
		            // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}
		            for (let parts of globParts) {
		                let gs = -1;
		                while (-1 !== (gs = parts.indexOf('**', gs + 1))) {
		                    let gss = gs;
		                    while (parts[gss + 1] === '**') {
		                        // <pre>/**/**/<rest> -> <pre>/**/<rest>
		                        gss++;
		                    }
		                    // eg, if gs is 2 and gss is 4, that means we have 3 **
		                    // parts, and can remove 2 of them.
		                    if (gss > gs) {
		                        parts.splice(gs + 1, gss - gs);
		                    }
		                    let next = parts[gs + 1];
		                    const p = parts[gs + 2];
		                    const p2 = parts[gs + 3];
		                    if (next !== '..')
		                        continue;
		                    if (!p ||
		                        p === '.' ||
		                        p === '..' ||
		                        !p2 ||
		                        p2 === '.' ||
		                        p2 === '..') {
		                        continue;
		                    }
		                    didSomething = true;
		                    // edit parts in place, and push the new one
		                    parts.splice(gs, 1);
		                    const other = parts.slice(0);
		                    other[gs] = '**';
		                    globParts.push(other);
		                    gs--;
		                }
		                // <pre>/<e>/<rest> -> <pre>/<rest>
		                if (!this.preserveMultipleSlashes) {
		                    for (let i = 1; i < parts.length - 1; i++) {
		                        const p = parts[i];
		                        // don't squeeze out UNC patterns
		                        if (i === 1 && p === '' && parts[0] === '')
		                            continue;
		                        if (p === '.' || p === '') {
		                            didSomething = true;
		                            parts.splice(i, 1);
		                            i--;
		                        }
		                    }
		                    if (parts[0] === '.' &&
		                        parts.length === 2 &&
		                        (parts[1] === '.' || parts[1] === '')) {
		                        didSomething = true;
		                        parts.pop();
		                    }
		                }
		                // <pre>/<p>/../<rest> -> <pre>/<rest>
		                let dd = 0;
		                while (-1 !== (dd = parts.indexOf('..', dd + 1))) {
		                    const p = parts[dd - 1];
		                    if (p && p !== '.' && p !== '..' && p !== '**') {
		                        didSomething = true;
		                        const needDot = dd === 1 && parts[dd + 1] === '**';
		                        const splin = needDot ? ['.'] : [];
		                        parts.splice(dd - 1, 2, ...splin);
		                        if (parts.length === 0)
		                            parts.push('');
		                        dd -= 2;
		                    }
		                }
		            }
		        } while (didSomething);
		        return globParts;
		    }
		    // second phase: multi-pattern dedupes
		    // {<pre>/*/<rest>,<pre>/<p>/<rest>} -> <pre>/*/<rest>
		    // {<pre>/<rest>,<pre>/<rest>} -> <pre>/<rest>
		    // {<pre>/**/<rest>,<pre>/<rest>} -> <pre>/**/<rest>
		    //
		    // {<pre>/**/<rest>,<pre>/**/<p>/<rest>} -> <pre>/**/<rest>
		    // ^-- not valid because ** doens't follow symlinks
		    secondPhasePreProcess(globParts) {
		        for (let i = 0; i < globParts.length - 1; i++) {
		            for (let j = i + 1; j < globParts.length; j++) {
		                const matched = this.partsMatch(globParts[i], globParts[j], !this.preserveMultipleSlashes);
		                if (matched) {
		                    globParts[i] = [];
		                    globParts[j] = matched;
		                    break;
		                }
		            }
		        }
		        return globParts.filter(gs => gs.length);
		    }
		    partsMatch(a, b, emptyGSMatch = false) {
		        let ai = 0;
		        let bi = 0;
		        let result = [];
		        let which = '';
		        while (ai < a.length && bi < b.length) {
		            if (a[ai] === b[bi]) {
		                result.push(which === 'b' ? b[bi] : a[ai]);
		                ai++;
		                bi++;
		            }
		            else if (emptyGSMatch && a[ai] === '**' && b[bi] === a[ai + 1]) {
		                result.push(a[ai]);
		                ai++;
		            }
		            else if (emptyGSMatch && b[bi] === '**' && a[ai] === b[bi + 1]) {
		                result.push(b[bi]);
		                bi++;
		            }
		            else if (a[ai] === '*' &&
		                b[bi] &&
		                (this.options.dot || !b[bi].startsWith('.')) &&
		                b[bi] !== '**') {
		                if (which === 'b')
		                    return false;
		                which = 'a';
		                result.push(a[ai]);
		                ai++;
		                bi++;
		            }
		            else if (b[bi] === '*' &&
		                a[ai] &&
		                (this.options.dot || !a[ai].startsWith('.')) &&
		                a[ai] !== '**') {
		                if (which === 'a')
		                    return false;
		                which = 'b';
		                result.push(b[bi]);
		                ai++;
		                bi++;
		            }
		            else {
		                return false;
		            }
		        }
		        // if we fall out of the loop, it means they two are identical
		        // as long as their lengths match
		        return a.length === b.length && result;
		    }
		    parseNegate() {
		        if (this.nonegate)
		            return;
		        const pattern = this.pattern;
		        let negate = false;
		        let negateOffset = 0;
		        for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {
		            negate = !negate;
		            negateOffset++;
		        }
		        if (negateOffset)
		            this.pattern = pattern.slice(negateOffset);
		        this.negate = negate;
		    }
		    // set partial to true to test if, for example,
		    // "/a/b" matches the start of "/*/b/*/d"
		    // Partial means, if you run out of file before you run
		    // out of pattern, then that's fine, as long as all
		    // the parts match.
		    matchOne(file, pattern, partial = false) {
		        const options = this.options;
		        // UNC paths like //?/X:/... can match X:/... and vice versa
		        // Drive letters in absolute drive or unc paths are always compared
		        // case-insensitively.
		        if (this.isWindows) {
		            const fileDrive = typeof file[0] === 'string' && /^[a-z]:$/i.test(file[0]);
		            const fileUNC = !fileDrive &&
		                file[0] === '' &&
		                file[1] === '' &&
		                file[2] === '?' &&
		                /^[a-z]:$/i.test(file[3]);
		            const patternDrive = typeof pattern[0] === 'string' && /^[a-z]:$/i.test(pattern[0]);
		            const patternUNC = !patternDrive &&
		                pattern[0] === '' &&
		                pattern[1] === '' &&
		                pattern[2] === '?' &&
		                typeof pattern[3] === 'string' &&
		                /^[a-z]:$/i.test(pattern[3]);
		            const fdi = fileUNC ? 3 : fileDrive ? 0 : undefined;
		            const pdi = patternUNC ? 3 : patternDrive ? 0 : undefined;
		            if (typeof fdi === 'number' && typeof pdi === 'number') {
		                const [fd, pd] = [file[fdi], pattern[pdi]];
		                if (fd.toLowerCase() === pd.toLowerCase()) {
		                    pattern[pdi] = fd;
		                    if (pdi > fdi) {
		                        pattern = pattern.slice(pdi);
		                    }
		                    else if (fdi > pdi) {
		                        file = file.slice(fdi);
		                    }
		                }
		            }
		        }
		        // resolve and reduce . and .. portions in the file as well.
		        // dont' need to do the second phase, because it's only one string[]
		        const { optimizationLevel = 1 } = this.options;
		        if (optimizationLevel >= 2) {
		            file = this.levelTwoFileOptimize(file);
		        }
		        this.debug('matchOne', this, { file, pattern });
		        this.debug('matchOne', file.length, pattern.length);
		        for (var fi = 0, pi = 0, fl = file.length, pl = pattern.length; fi < fl && pi < pl; fi++, pi++) {
		            this.debug('matchOne loop');
		            var p = pattern[pi];
		            var f = file[fi];
		            this.debug(pattern, p, f);
		            // should be impossible.
		            // some invalid regexp stuff in the set.
		            /* c8 ignore start */
		            if (p === false) {
		                return false;
		            }
		            /* c8 ignore stop */
		            if (p === exports.GLOBSTAR) {
		                this.debug('GLOBSTAR', [pattern, p, f]);
		                // "**"
		                // a/**/b/**/c would match the following:
		                // a/b/x/y/z/c
		                // a/x/y/z/b/c
		                // a/b/x/b/x/c
		                // a/b/c
		                // To do this, take the rest of the pattern after
		                // the **, and see if it would match the file remainder.
		                // If so, return success.
		                // If not, the ** "swallows" a segment, and try again.
		                // This is recursively awful.
		                //
		                // a/**/b/**/c matching a/b/x/y/z/c
		                // - a matches a
		                // - doublestar
		                //   - matchOne(b/x/y/z/c, b/**/c)
		                //     - b matches b
		                //     - doublestar
		                //       - matchOne(x/y/z/c, c) -> no
		                //       - matchOne(y/z/c, c) -> no
		                //       - matchOne(z/c, c) -> no
		                //       - matchOne(c, c) yes, hit
		                var fr = fi;
		                var pr = pi + 1;
		                if (pr === pl) {
		                    this.debug('** at the end');
		                    // a ** at the end will just swallow the rest.
		                    // We have found a match.
		                    // however, it will not swallow /.x, unless
		                    // options.dot is set.
		                    // . and .. are *never* matched by **, for explosively
		                    // exponential reasons.
		                    for (; fi < fl; fi++) {
		                        if (file[fi] === '.' ||
		                            file[fi] === '..' ||
		                            (!options.dot && file[fi].charAt(0) === '.'))
		                            return false;
		                    }
		                    return true;
		                }
		                // ok, let's see if we can swallow whatever we can.
		                while (fr < fl) {
		                    var swallowee = file[fr];
		                    this.debug('\nglobstar while', file, fr, pattern, pr, swallowee);
		                    // XXX remove this slice.  Just pass the start index.
		                    if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {
		                        this.debug('globstar found match!', fr, fl, swallowee);
		                        // found a match.
		                        return true;
		                    }
		                    else {
		                        // can't swallow "." or ".." ever.
		                        // can only swallow ".foo" when explicitly asked.
		                        if (swallowee === '.' ||
		                            swallowee === '..' ||
		                            (!options.dot && swallowee.charAt(0) === '.')) {
		                            this.debug('dot detected!', file, fr, pattern, pr);
		                            break;
		                        }
		                        // ** swallows a segment, and continue.
		                        this.debug('globstar swallow a segment, and continue');
		                        fr++;
		                    }
		                }
		                // no match was found.
		                // However, in partial mode, we can't say this is necessarily over.
		                /* c8 ignore start */
		                if (partial) {
		                    // ran out of file
		                    this.debug('\n>>> no match, partial?', file, fr, pattern, pr);
		                    if (fr === fl) {
		                        return true;
		                    }
		                }
		                /* c8 ignore stop */
		                return false;
		            }
		            // something other than **
		            // non-magic patterns just have to match exactly
		            // patterns with magic have been turned into regexps.
		            let hit;
		            if (typeof p === 'string') {
		                hit = f === p;
		                this.debug('string match', p, f, hit);
		            }
		            else {
		                hit = p.test(f);
		                this.debug('pattern match', p, f, hit);
		            }
		            if (!hit)
		                return false;
		        }
		        // Note: ending in / means that we'll get a final ""
		        // at the end of the pattern.  This can only match a
		        // corresponding "" at the end of the file.
		        // If the file ends in /, then it can only match a
		        // a pattern that ends in /, unless the pattern just
		        // doesn't have any more for it. But, a/b/ should *not*
		        // match "a/b/*", even though "" matches against the
		        // [^/]*? pattern, except in partial mode, where it might
		        // simply not be reached yet.
		        // However, a/b/ should still satisfy a/*
		        // now either we fell off the end of the pattern, or we're done.
		        if (fi === fl && pi === pl) {
		            // ran out of pattern and filename at the same time.
		            // an exact hit!
		            return true;
		        }
		        else if (fi === fl) {
		            // ran out of file, but still had pattern left.
		            // this is ok if we're doing the match as part of
		            // a glob fs traversal.
		            return partial;
		        }
		        else if (pi === pl) {
		            // ran out of pattern, still have file left.
		            // this is only acceptable if we're on the very last
		            // empty segment of a file with a trailing slash.
		            // a/* should match a/b/
		            return fi === fl - 1 && file[fi] === '';
		            /* c8 ignore start */
		        }
		        else {
		            // should be unreachable.
		            throw new Error('wtf?');
		        }
		        /* c8 ignore stop */
		    }
		    braceExpand() {
		        return (0, exports.braceExpand)(this.pattern, this.options);
		    }
		    parse(pattern) {
		        (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);
		        const options = this.options;
		        // shortcuts
		        if (pattern === '**')
		            return exports.GLOBSTAR;
		        if (pattern === '')
		            return '';
		        // far and away, the most common glob pattern parts are
		        // *, *.*, and *.<ext>  Add a fast check method for those.
		        let m;
		        let fastTest = null;
		        if ((m = pattern.match(starRE))) {
		            fastTest = options.dot ? starTestDot : starTest;
		        }
		        else if ((m = pattern.match(starDotExtRE))) {
		            fastTest = (options.nocase
		                ? options.dot
		                    ? starDotExtTestNocaseDot
		                    : starDotExtTestNocase
		                : options.dot
		                    ? starDotExtTestDot
		                    : starDotExtTest)(m[1]);
		        }
		        else if ((m = pattern.match(qmarksRE))) {
		            fastTest = (options.nocase
		                ? options.dot
		                    ? qmarksTestNocaseDot
		                    : qmarksTestNocase
		                : options.dot
		                    ? qmarksTestDot
		                    : qmarksTest)(m);
		        }
		        else if ((m = pattern.match(starDotStarRE))) {
		            fastTest = options.dot ? starDotStarTestDot : starDotStarTest;
		        }
		        else if ((m = pattern.match(dotStarRE))) {
		            fastTest = dotStarTest;
		        }
		        const re = ast_js_1.AST.fromGlob(pattern, this.options).toMMPattern();
		        if (fastTest && typeof re === 'object') {
		            // Avoids overriding in frozen environments
		            Reflect.defineProperty(re, 'test', { value: fastTest });
		        }
		        return re;
		    }
		    makeRe() {
		        if (this.regexp || this.regexp === false)
		            return this.regexp;
		        // at this point, this.set is a 2d array of partial
		        // pattern strings, or "**".
		        //
		        // It's better to use .match().  This function shouldn't
		        // be used, really, but it's pretty convenient sometimes,
		        // when you just want to work with a regex.
		        const set = this.set;
		        if (!set.length) {
		            this.regexp = false;
		            return this.regexp;
		        }
		        const options = this.options;
		        const twoStar = options.noglobstar
		            ? star
		            : options.dot
		                ? twoStarDot
		                : twoStarNoDot;
		        const flags = new Set(options.nocase ? ['i'] : []);
		        // regexpify non-globstar patterns
		        // if ** is only item, then we just do one twoStar
		        // if ** is first, and there are more, prepend (\/|twoStar\/)? to next
		        // if ** is last, append (\/twoStar|) to previous
		        // if ** is in the middle, append (\/|\/twoStar\/) to previous
		        // then filter out GLOBSTAR symbols
		        let re = set
		            .map(pattern => {
		            const pp = pattern.map(p => {
		                if (p instanceof RegExp) {
		                    for (const f of p.flags.split(''))
		                        flags.add(f);
		                }
		                return typeof p === 'string'
		                    ? regExpEscape(p)
		                    : p === exports.GLOBSTAR
		                        ? exports.GLOBSTAR
		                        : p._src;
		            });
		            pp.forEach((p, i) => {
		                const next = pp[i + 1];
		                const prev = pp[i - 1];
		                if (p !== exports.GLOBSTAR || prev === exports.GLOBSTAR) {
		                    return;
		                }
		                if (prev === undefined) {
		                    if (next !== undefined && next !== exports.GLOBSTAR) {
		                        pp[i + 1] = '(?:\\/|' + twoStar + '\\/)?' + next;
		                    }
		                    else {
		                        pp[i] = twoStar;
		                    }
		                }
		                else if (next === undefined) {
		                    pp[i - 1] = prev + '(?:\\/|' + twoStar + ')?';
		                }
		                else if (next !== exports.GLOBSTAR) {
		                    pp[i - 1] = prev + '(?:\\/|\\/' + twoStar + '\\/)' + next;
		                    pp[i + 1] = exports.GLOBSTAR;
		                }
		            });
		            return pp.filter(p => p !== exports.GLOBSTAR).join('/');
		        })
		            .join('|');
		        // need to wrap in parens if we had more than one thing with |,
		        // otherwise only the first will be anchored to ^ and the last to $
		        const [open, close] = set.length > 1 ? ['(?:', ')'] : ['', ''];
		        // must match entire pattern
		        // ending in a * or ** will make it less strict.
		        re = '^' + open + re + close + '$';
		        // can match anything, as long as it's not this.
		        if (this.negate)
		            re = '^(?!' + re + ').+$';
		        try {
		            this.regexp = new RegExp(re, [...flags].join(''));
		            /* c8 ignore start */
		        }
		        catch (ex) {
		            // should be impossible
		            this.regexp = false;
		        }
		        /* c8 ignore stop */
		        return this.regexp;
		    }
		    slashSplit(p) {
		        // if p starts with // on windows, we preserve that
		        // so that UNC paths aren't broken.  Otherwise, any number of
		        // / characters are coalesced into one, unless
		        // preserveMultipleSlashes is set to true.
		        if (this.preserveMultipleSlashes) {
		            return p.split('/');
		        }
		        else if (this.isWindows && /^\/\/[^\/]+/.test(p)) {
		            // add an extra '' for the one we lose
		            return ['', ...p.split(/\/+/)];
		        }
		        else {
		            return p.split(/\/+/);
		        }
		    }
		    match(f, partial = this.partial) {
		        this.debug('match', f, this.pattern);
		        // short-circuit in the case of busted things.
		        // comments, etc.
		        if (this.comment) {
		            return false;
		        }
		        if (this.empty) {
		            return f === '';
		        }
		        if (f === '/' && partial) {
		            return true;
		        }
		        const options = this.options;
		        // windows: need to use /, not \
		        if (this.isWindows) {
		            f = f.split('\\').join('/');
		        }
		        // treat the test path as a set of pathparts.
		        const ff = this.slashSplit(f);
		        this.debug(this.pattern, 'split', ff);
		        // just ONE of the pattern sets in this.set needs to match
		        // in order for it to be valid.  If negating, then just one
		        // match means that we have failed.
		        // Either way, return on the first hit.
		        const set = this.set;
		        this.debug(this.pattern, 'set', set);
		        // Find the basename of the path by looking for the last non-empty segment
		        let filename = ff[ff.length - 1];
		        if (!filename) {
		            for (let i = ff.length - 2; !filename && i >= 0; i--) {
		                filename = ff[i];
		            }
		        }
		        for (let i = 0; i < set.length; i++) {
		            const pattern = set[i];
		            let file = ff;
		            if (options.matchBase && pattern.length === 1) {
		                file = [filename];
		            }
		            const hit = this.matchOne(file, pattern, partial);
		            if (hit) {
		                if (options.flipNegate) {
		                    return true;
		                }
		                return !this.negate;
		            }
		        }
		        // didn't get any hits.  this is success if it's a negative
		        // pattern, failure otherwise.
		        if (options.flipNegate) {
		            return false;
		        }
		        return this.negate;
		    }
		    static defaults(def) {
		        return exports.minimatch.defaults(def).Minimatch;
		    }
		}
		exports.Minimatch = Minimatch;
		/* c8 ignore start */
		var ast_js_2 = requireAst();
		Object.defineProperty(exports, "AST", { enumerable: true, get: function () { return ast_js_2.AST; } });
		var escape_js_2 = require_escape$1();
		Object.defineProperty(exports, "escape", { enumerable: true, get: function () { return escape_js_2.escape; } });
		var unescape_js_2 = require_unescape();
		Object.defineProperty(exports, "unescape", { enumerable: true, get: function () { return unescape_js_2.unescape; } });
		/* c8 ignore stop */
		exports.minimatch.AST = ast_js_1.AST;
		exports.minimatch.Minimatch = Minimatch;
		exports.minimatch.escape = escape_js_1.escape;
		exports.minimatch.unescape = unescape_js_1.unescape;
		
	} (commonjs$1));
	return commonjs$1;
}

var glob = {};

var commonjs = {};

var hasRequiredCommonjs$1;

function requireCommonjs$1 () {
	if (hasRequiredCommonjs$1) return commonjs;
	hasRequiredCommonjs$1 = 1;
	var __createBinding = (commonjs && commonjs.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjs && commonjs.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjs && commonjs.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(commonjs, "__esModule", { value: true });
	commonjs.PathScurry = commonjs.Path = commonjs.PathScurryDarwin = commonjs.PathScurryPosix = commonjs.PathScurryWin32 = commonjs.PathScurryBase = commonjs.PathPosix = commonjs.PathWin32 = commonjs.PathBase = commonjs.ChildrenCache = commonjs.ResolveCache = void 0;
	const lru_cache_1 = /*@__PURE__*/ requireCommonjs$4();
	const node_path_1 = require$$2$2;
	const node_url_1 = require$$0$2;
	const fs_1 = require$$0$3;
	const actualFS = __importStar(require$$4);
	const realpathSync = fs_1.realpathSync.native;
	// TODO: test perf of fs/promises realpath vs realpathCB,
	// since the promises one uses realpath.native
	const promises_1 = require$$5;
	const minipass_1 = requireCommonjs$5();
	const defaultFS = {
	    lstatSync: fs_1.lstatSync,
	    readdir: fs_1.readdir,
	    readdirSync: fs_1.readdirSync,
	    readlinkSync: fs_1.readlinkSync,
	    realpathSync,
	    promises: {
	        lstat: promises_1.lstat,
	        readdir: promises_1.readdir,
	        readlink: promises_1.readlink,
	        realpath: promises_1.realpath,
	    },
	};
	// if they just gave us require('fs') then use our default
	const fsFromOption = (fsOption) => !fsOption || fsOption === defaultFS || fsOption === actualFS ?
	    defaultFS
	    : {
	        ...defaultFS,
	        ...fsOption,
	        promises: {
	            ...defaultFS.promises,
	            ...(fsOption.promises || {}),
	        },
	    };
	// turn something like //?/c:/ into c:\
	const uncDriveRegexp = /^\\\\\?\\([a-z]:)\\?$/i;
	const uncToDrive = (rootPath) => rootPath.replace(/\//g, '\\').replace(uncDriveRegexp, '$1\\');
	// windows paths are separated by either / or \
	const eitherSep = /[\\\/]/;
	const UNKNOWN = 0; // may not even exist, for all we know
	const IFIFO = 0b0001;
	const IFCHR = 0b0010;
	const IFDIR = 0b0100;
	const IFBLK = 0b0110;
	const IFREG = 0b1000;
	const IFLNK = 0b1010;
	const IFSOCK = 0b1100;
	const IFMT = 0b1111;
	// mask to unset low 4 bits
	const IFMT_UNKNOWN = ~IFMT;
	// set after successfully calling readdir() and getting entries.
	const READDIR_CALLED = 0b0000_0001_0000;
	// set after a successful lstat()
	const LSTAT_CALLED = 0b0000_0010_0000;
	// set if an entry (or one of its parents) is definitely not a dir
	const ENOTDIR = 0b0000_0100_0000;
	// set if an entry (or one of its parents) does not exist
	// (can also be set on lstat errors like EACCES or ENAMETOOLONG)
	const ENOENT = 0b0000_1000_0000;
	// cannot have child entries -- also verify &IFMT is either IFDIR or IFLNK
	// set if we fail to readlink
	const ENOREADLINK = 0b0001_0000_0000;
	// set if we know realpath() will fail
	const ENOREALPATH = 0b0010_0000_0000;
	const ENOCHILD = ENOTDIR | ENOENT | ENOREALPATH;
	const TYPEMASK = 0b0011_1111_1111;
	const entToType = (s) => s.isFile() ? IFREG
	    : s.isDirectory() ? IFDIR
	        : s.isSymbolicLink() ? IFLNK
	            : s.isCharacterDevice() ? IFCHR
	                : s.isBlockDevice() ? IFBLK
	                    : s.isSocket() ? IFSOCK
	                        : s.isFIFO() ? IFIFO
	                            : UNKNOWN;
	// normalize unicode path names
	const normalizeCache = new Map();
	const normalize = (s) => {
	    const c = normalizeCache.get(s);
	    if (c)
	        return c;
	    const n = s.normalize('NFKD');
	    normalizeCache.set(s, n);
	    return n;
	};
	const normalizeNocaseCache = new Map();
	const normalizeNocase = (s) => {
	    const c = normalizeNocaseCache.get(s);
	    if (c)
	        return c;
	    const n = normalize(s.toLowerCase());
	    normalizeNocaseCache.set(s, n);
	    return n;
	};
	/**
	 * An LRUCache for storing resolved path strings or Path objects.
	 * @internal
	 */
	class ResolveCache extends lru_cache_1.LRUCache {
	    constructor() {
	        super({ max: 256 });
	    }
	}
	commonjs.ResolveCache = ResolveCache;
	// In order to prevent blowing out the js heap by allocating hundreds of
	// thousands of Path entries when walking extremely large trees, the "children"
	// in this tree are represented by storing an array of Path entries in an
	// LRUCache, indexed by the parent.  At any time, Path.children() may return an
	// empty array, indicating that it doesn't know about any of its children, and
	// thus has to rebuild that cache.  This is fine, it just means that we don't
	// benefit as much from having the cached entries, but huge directory walks
	// don't blow out the stack, and smaller ones are still as fast as possible.
	//
	//It does impose some complexity when building up the readdir data, because we
	//need to pass a reference to the children array that we started with.
	/**
	 * an LRUCache for storing child entries.
	 * @internal
	 */
	class ChildrenCache extends lru_cache_1.LRUCache {
	    constructor(maxSize = 16 * 1024) {
	        super({
	            maxSize,
	            // parent + children
	            sizeCalculation: a => a.length + 1,
	        });
	    }
	}
	commonjs.ChildrenCache = ChildrenCache;
	const setAsCwd = Symbol('PathScurry setAsCwd');
	/**
	 * Path objects are sort of like a super-powered
	 * {@link https://nodejs.org/docs/latest/api/fs.html#class-fsdirent fs.Dirent}
	 *
	 * Each one represents a single filesystem entry on disk, which may or may not
	 * exist. It includes methods for reading various types of information via
	 * lstat, readlink, and readdir, and caches all information to the greatest
	 * degree possible.
	 *
	 * Note that fs operations that would normally throw will instead return an
	 * "empty" value. This is in order to prevent excessive overhead from error
	 * stack traces.
	 */
	class PathBase {
	    /**
	     * the basename of this path
	     *
	     * **Important**: *always* test the path name against any test string
	     * usingthe {@link isNamed} method, and not by directly comparing this
	     * string. Otherwise, unicode path strings that the system sees as identical
	     * will not be properly treated as the same path, leading to incorrect
	     * behavior and possible security issues.
	     */
	    name;
	    /**
	     * the Path entry corresponding to the path root.
	     *
	     * @internal
	     */
	    root;
	    /**
	     * All roots found within the current PathScurry family
	     *
	     * @internal
	     */
	    roots;
	    /**
	     * a reference to the parent path, or undefined in the case of root entries
	     *
	     * @internal
	     */
	    parent;
	    /**
	     * boolean indicating whether paths are compared case-insensitively
	     * @internal
	     */
	    nocase;
	    /**
	     * boolean indicating that this path is the current working directory
	     * of the PathScurry collection that contains it.
	     */
	    isCWD = false;
	    // potential default fs override
	    #fs;
	    // Stats fields
	    #dev;
	    get dev() {
	        return this.#dev;
	    }
	    #mode;
	    get mode() {
	        return this.#mode;
	    }
	    #nlink;
	    get nlink() {
	        return this.#nlink;
	    }
	    #uid;
	    get uid() {
	        return this.#uid;
	    }
	    #gid;
	    get gid() {
	        return this.#gid;
	    }
	    #rdev;
	    get rdev() {
	        return this.#rdev;
	    }
	    #blksize;
	    get blksize() {
	        return this.#blksize;
	    }
	    #ino;
	    get ino() {
	        return this.#ino;
	    }
	    #size;
	    get size() {
	        return this.#size;
	    }
	    #blocks;
	    get blocks() {
	        return this.#blocks;
	    }
	    #atimeMs;
	    get atimeMs() {
	        return this.#atimeMs;
	    }
	    #mtimeMs;
	    get mtimeMs() {
	        return this.#mtimeMs;
	    }
	    #ctimeMs;
	    get ctimeMs() {
	        return this.#ctimeMs;
	    }
	    #birthtimeMs;
	    get birthtimeMs() {
	        return this.#birthtimeMs;
	    }
	    #atime;
	    get atime() {
	        return this.#atime;
	    }
	    #mtime;
	    get mtime() {
	        return this.#mtime;
	    }
	    #ctime;
	    get ctime() {
	        return this.#ctime;
	    }
	    #birthtime;
	    get birthtime() {
	        return this.#birthtime;
	    }
	    #matchName;
	    #depth;
	    #fullpath;
	    #fullpathPosix;
	    #relative;
	    #relativePosix;
	    #type;
	    #children;
	    #linkTarget;
	    #realpath;
	    /**
	     * This property is for compatibility with the Dirent class as of
	     * Node v20, where Dirent['parentPath'] refers to the path of the
	     * directory that was passed to readdir. For root entries, it's the path
	     * to the entry itself.
	     */
	    get parentPath() {
	        return (this.parent || this).fullpath();
	    }
	    /**
	     * Deprecated alias for Dirent['parentPath'] Somewhat counterintuitively,
	     * this property refers to the *parent* path, not the path object itself.
	     */
	    get path() {
	        return this.parentPath;
	    }
	    /**
	     * Do not create new Path objects directly.  They should always be accessed
	     * via the PathScurry class or other methods on the Path class.
	     *
	     * @internal
	     */
	    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
	        this.name = name;
	        this.#matchName = nocase ? normalizeNocase(name) : normalize(name);
	        this.#type = type & TYPEMASK;
	        this.nocase = nocase;
	        this.roots = roots;
	        this.root = root || this;
	        this.#children = children;
	        this.#fullpath = opts.fullpath;
	        this.#relative = opts.relative;
	        this.#relativePosix = opts.relativePosix;
	        this.parent = opts.parent;
	        if (this.parent) {
	            this.#fs = this.parent.#fs;
	        }
	        else {
	            this.#fs = fsFromOption(opts.fs);
	        }
	    }
	    /**
	     * Returns the depth of the Path object from its root.
	     *
	     * For example, a path at `/foo/bar` would have a depth of 2.
	     */
	    depth() {
	        if (this.#depth !== undefined)
	            return this.#depth;
	        if (!this.parent)
	            return (this.#depth = 0);
	        return (this.#depth = this.parent.depth() + 1);
	    }
	    /**
	     * @internal
	     */
	    childrenCache() {
	        return this.#children;
	    }
	    /**
	     * Get the Path object referenced by the string path, resolved from this Path
	     */
	    resolve(path) {
	        if (!path) {
	            return this;
	        }
	        const rootPath = this.getRootString(path);
	        const dir = path.substring(rootPath.length);
	        const dirParts = dir.split(this.splitSep);
	        const result = rootPath ?
	            this.getRoot(rootPath).#resolveParts(dirParts)
	            : this.#resolveParts(dirParts);
	        return result;
	    }
	    #resolveParts(dirParts) {
	        let p = this;
	        for (const part of dirParts) {
	            p = p.child(part);
	        }
	        return p;
	    }
	    /**
	     * Returns the cached children Path objects, if still available.  If they
	     * have fallen out of the cache, then returns an empty array, and resets the
	     * READDIR_CALLED bit, so that future calls to readdir() will require an fs
	     * lookup.
	     *
	     * @internal
	     */
	    children() {
	        const cached = this.#children.get(this);
	        if (cached) {
	            return cached;
	        }
	        const children = Object.assign([], { provisional: 0 });
	        this.#children.set(this, children);
	        this.#type &= ~READDIR_CALLED;
	        return children;
	    }
	    /**
	     * Resolves a path portion and returns or creates the child Path.
	     *
	     * Returns `this` if pathPart is `''` or `'.'`, or `parent` if pathPart is
	     * `'..'`.
	     *
	     * This should not be called directly.  If `pathPart` contains any path
	     * separators, it will lead to unsafe undefined behavior.
	     *
	     * Use `Path.resolve()` instead.
	     *
	     * @internal
	     */
	    child(pathPart, opts) {
	        if (pathPart === '' || pathPart === '.') {
	            return this;
	        }
	        if (pathPart === '..') {
	            return this.parent || this;
	        }
	        // find the child
	        const children = this.children();
	        const name = this.nocase ? normalizeNocase(pathPart) : normalize(pathPart);
	        for (const p of children) {
	            if (p.#matchName === name) {
	                return p;
	            }
	        }
	        // didn't find it, create provisional child, since it might not
	        // actually exist.  If we know the parent isn't a dir, then
	        // in fact it CAN'T exist.
	        const s = this.parent ? this.sep : '';
	        const fullpath = this.#fullpath ? this.#fullpath + s + pathPart : undefined;
	        const pchild = this.newChild(pathPart, UNKNOWN, {
	            ...opts,
	            parent: this,
	            fullpath,
	        });
	        if (!this.canReaddir()) {
	            pchild.#type |= ENOENT;
	        }
	        // don't have to update provisional, because if we have real children,
	        // then provisional is set to children.length, otherwise a lower number
	        children.push(pchild);
	        return pchild;
	    }
	    /**
	     * The relative path from the cwd. If it does not share an ancestor with
	     * the cwd, then this ends up being equivalent to the fullpath()
	     */
	    relative() {
	        if (this.isCWD)
	            return '';
	        if (this.#relative !== undefined) {
	            return this.#relative;
	        }
	        const name = this.name;
	        const p = this.parent;
	        if (!p) {
	            return (this.#relative = this.name);
	        }
	        const pv = p.relative();
	        return pv + (!pv || !p.parent ? '' : this.sep) + name;
	    }
	    /**
	     * The relative path from the cwd, using / as the path separator.
	     * If it does not share an ancestor with
	     * the cwd, then this ends up being equivalent to the fullpathPosix()
	     * On posix systems, this is identical to relative().
	     */
	    relativePosix() {
	        if (this.sep === '/')
	            return this.relative();
	        if (this.isCWD)
	            return '';
	        if (this.#relativePosix !== undefined)
	            return this.#relativePosix;
	        const name = this.name;
	        const p = this.parent;
	        if (!p) {
	            return (this.#relativePosix = this.fullpathPosix());
	        }
	        const pv = p.relativePosix();
	        return pv + (!pv || !p.parent ? '' : '/') + name;
	    }
	    /**
	     * The fully resolved path string for this Path entry
	     */
	    fullpath() {
	        if (this.#fullpath !== undefined) {
	            return this.#fullpath;
	        }
	        const name = this.name;
	        const p = this.parent;
	        if (!p) {
	            return (this.#fullpath = this.name);
	        }
	        const pv = p.fullpath();
	        const fp = pv + (!p.parent ? '' : this.sep) + name;
	        return (this.#fullpath = fp);
	    }
	    /**
	     * On platforms other than windows, this is identical to fullpath.
	     *
	     * On windows, this is overridden to return the forward-slash form of the
	     * full UNC path.
	     */
	    fullpathPosix() {
	        if (this.#fullpathPosix !== undefined)
	            return this.#fullpathPosix;
	        if (this.sep === '/')
	            return (this.#fullpathPosix = this.fullpath());
	        if (!this.parent) {
	            const p = this.fullpath().replace(/\\/g, '/');
	            if (/^[a-z]:\//i.test(p)) {
	                return (this.#fullpathPosix = `//?/${p}`);
	            }
	            else {
	                return (this.#fullpathPosix = p);
	            }
	        }
	        const p = this.parent;
	        const pfpp = p.fullpathPosix();
	        const fpp = pfpp + (!pfpp || !p.parent ? '' : '/') + this.name;
	        return (this.#fullpathPosix = fpp);
	    }
	    /**
	     * Is the Path of an unknown type?
	     *
	     * Note that we might know *something* about it if there has been a previous
	     * filesystem operation, for example that it does not exist, or is not a
	     * link, or whether it has child entries.
	     */
	    isUnknown() {
	        return (this.#type & IFMT) === UNKNOWN;
	    }
	    isType(type) {
	        return this[`is${type}`]();
	    }
	    getType() {
	        return (this.isUnknown() ? 'Unknown'
	            : this.isDirectory() ? 'Directory'
	                : this.isFile() ? 'File'
	                    : this.isSymbolicLink() ? 'SymbolicLink'
	                        : this.isFIFO() ? 'FIFO'
	                            : this.isCharacterDevice() ? 'CharacterDevice'
	                                : this.isBlockDevice() ? 'BlockDevice'
	                                    : /* c8 ignore start */ this.isSocket() ? 'Socket'
	                                        : 'Unknown');
	        /* c8 ignore stop */
	    }
	    /**
	     * Is the Path a regular file?
	     */
	    isFile() {
	        return (this.#type & IFMT) === IFREG;
	    }
	    /**
	     * Is the Path a directory?
	     */
	    isDirectory() {
	        return (this.#type & IFMT) === IFDIR;
	    }
	    /**
	     * Is the path a character device?
	     */
	    isCharacterDevice() {
	        return (this.#type & IFMT) === IFCHR;
	    }
	    /**
	     * Is the path a block device?
	     */
	    isBlockDevice() {
	        return (this.#type & IFMT) === IFBLK;
	    }
	    /**
	     * Is the path a FIFO pipe?
	     */
	    isFIFO() {
	        return (this.#type & IFMT) === IFIFO;
	    }
	    /**
	     * Is the path a socket?
	     */
	    isSocket() {
	        return (this.#type & IFMT) === IFSOCK;
	    }
	    /**
	     * Is the path a symbolic link?
	     */
	    isSymbolicLink() {
	        return (this.#type & IFLNK) === IFLNK;
	    }
	    /**
	     * Return the entry if it has been subject of a successful lstat, or
	     * undefined otherwise.
	     *
	     * Does not read the filesystem, so an undefined result *could* simply
	     * mean that we haven't called lstat on it.
	     */
	    lstatCached() {
	        return this.#type & LSTAT_CALLED ? this : undefined;
	    }
	    /**
	     * Return the cached link target if the entry has been the subject of a
	     * successful readlink, or undefined otherwise.
	     *
	     * Does not read the filesystem, so an undefined result *could* just mean we
	     * don't have any cached data. Only use it if you are very sure that a
	     * readlink() has been called at some point.
	     */
	    readlinkCached() {
	        return this.#linkTarget;
	    }
	    /**
	     * Returns the cached realpath target if the entry has been the subject
	     * of a successful realpath, or undefined otherwise.
	     *
	     * Does not read the filesystem, so an undefined result *could* just mean we
	     * don't have any cached data. Only use it if you are very sure that a
	     * realpath() has been called at some point.
	     */
	    realpathCached() {
	        return this.#realpath;
	    }
	    /**
	     * Returns the cached child Path entries array if the entry has been the
	     * subject of a successful readdir(), or [] otherwise.
	     *
	     * Does not read the filesystem, so an empty array *could* just mean we
	     * don't have any cached data. Only use it if you are very sure that a
	     * readdir() has been called recently enough to still be valid.
	     */
	    readdirCached() {
	        const children = this.children();
	        return children.slice(0, children.provisional);
	    }
	    /**
	     * Return true if it's worth trying to readlink.  Ie, we don't (yet) have
	     * any indication that readlink will definitely fail.
	     *
	     * Returns false if the path is known to not be a symlink, if a previous
	     * readlink failed, or if the entry does not exist.
	     */
	    canReadlink() {
	        if (this.#linkTarget)
	            return true;
	        if (!this.parent)
	            return false;
	        // cases where it cannot possibly succeed
	        const ifmt = this.#type & IFMT;
	        return !((ifmt !== UNKNOWN && ifmt !== IFLNK) ||
	            this.#type & ENOREADLINK ||
	            this.#type & ENOENT);
	    }
	    /**
	     * Return true if readdir has previously been successfully called on this
	     * path, indicating that cachedReaddir() is likely valid.
	     */
	    calledReaddir() {
	        return !!(this.#type & READDIR_CALLED);
	    }
	    /**
	     * Returns true if the path is known to not exist. That is, a previous lstat
	     * or readdir failed to verify its existence when that would have been
	     * expected, or a parent entry was marked either enoent or enotdir.
	     */
	    isENOENT() {
	        return !!(this.#type & ENOENT);
	    }
	    /**
	     * Return true if the path is a match for the given path name.  This handles
	     * case sensitivity and unicode normalization.
	     *
	     * Note: even on case-sensitive systems, it is **not** safe to test the
	     * equality of the `.name` property to determine whether a given pathname
	     * matches, due to unicode normalization mismatches.
	     *
	     * Always use this method instead of testing the `path.name` property
	     * directly.
	     */
	    isNamed(n) {
	        return !this.nocase ?
	            this.#matchName === normalize(n)
	            : this.#matchName === normalizeNocase(n);
	    }
	    /**
	     * Return the Path object corresponding to the target of a symbolic link.
	     *
	     * If the Path is not a symbolic link, or if the readlink call fails for any
	     * reason, `undefined` is returned.
	     *
	     * Result is cached, and thus may be outdated if the filesystem is mutated.
	     */
	    async readlink() {
	        const target = this.#linkTarget;
	        if (target) {
	            return target;
	        }
	        if (!this.canReadlink()) {
	            return undefined;
	        }
	        /* c8 ignore start */
	        // already covered by the canReadlink test, here for ts grumples
	        if (!this.parent) {
	            return undefined;
	        }
	        /* c8 ignore stop */
	        try {
	            const read = await this.#fs.promises.readlink(this.fullpath());
	            const linkTarget = (await this.parent.realpath())?.resolve(read);
	            if (linkTarget) {
	                return (this.#linkTarget = linkTarget);
	            }
	        }
	        catch (er) {
	            this.#readlinkFail(er.code);
	            return undefined;
	        }
	    }
	    /**
	     * Synchronous {@link PathBase.readlink}
	     */
	    readlinkSync() {
	        const target = this.#linkTarget;
	        if (target) {
	            return target;
	        }
	        if (!this.canReadlink()) {
	            return undefined;
	        }
	        /* c8 ignore start */
	        // already covered by the canReadlink test, here for ts grumples
	        if (!this.parent) {
	            return undefined;
	        }
	        /* c8 ignore stop */
	        try {
	            const read = this.#fs.readlinkSync(this.fullpath());
	            const linkTarget = this.parent.realpathSync()?.resolve(read);
	            if (linkTarget) {
	                return (this.#linkTarget = linkTarget);
	            }
	        }
	        catch (er) {
	            this.#readlinkFail(er.code);
	            return undefined;
	        }
	    }
	    #readdirSuccess(children) {
	        // succeeded, mark readdir called bit
	        this.#type |= READDIR_CALLED;
	        // mark all remaining provisional children as ENOENT
	        for (let p = children.provisional; p < children.length; p++) {
	            const c = children[p];
	            if (c)
	                c.#markENOENT();
	        }
	    }
	    #markENOENT() {
	        // mark as UNKNOWN and ENOENT
	        if (this.#type & ENOENT)
	            return;
	        this.#type = (this.#type | ENOENT) & IFMT_UNKNOWN;
	        this.#markChildrenENOENT();
	    }
	    #markChildrenENOENT() {
	        // all children are provisional and do not exist
	        const children = this.children();
	        children.provisional = 0;
	        for (const p of children) {
	            p.#markENOENT();
	        }
	    }
	    #markENOREALPATH() {
	        this.#type |= ENOREALPATH;
	        this.#markENOTDIR();
	    }
	    // save the information when we know the entry is not a dir
	    #markENOTDIR() {
	        // entry is not a directory, so any children can't exist.
	        // this *should* be impossible, since any children created
	        // after it's been marked ENOTDIR should be marked ENOENT,
	        // so it won't even get to this point.
	        /* c8 ignore start */
	        if (this.#type & ENOTDIR)
	            return;
	        /* c8 ignore stop */
	        let t = this.#type;
	        // this could happen if we stat a dir, then delete it,
	        // then try to read it or one of its children.
	        if ((t & IFMT) === IFDIR)
	            t &= IFMT_UNKNOWN;
	        this.#type = t | ENOTDIR;
	        this.#markChildrenENOENT();
	    }
	    #readdirFail(code = '') {
	        // markENOTDIR and markENOENT also set provisional=0
	        if (code === 'ENOTDIR' || code === 'EPERM') {
	            this.#markENOTDIR();
	        }
	        else if (code === 'ENOENT') {
	            this.#markENOENT();
	        }
	        else {
	            this.children().provisional = 0;
	        }
	    }
	    #lstatFail(code = '') {
	        // Windows just raises ENOENT in this case, disable for win CI
	        /* c8 ignore start */
	        if (code === 'ENOTDIR') {
	            // already know it has a parent by this point
	            const p = this.parent;
	            p.#markENOTDIR();
	        }
	        else if (code === 'ENOENT') {
	            /* c8 ignore stop */
	            this.#markENOENT();
	        }
	    }
	    #readlinkFail(code = '') {
	        let ter = this.#type;
	        ter |= ENOREADLINK;
	        if (code === 'ENOENT')
	            ter |= ENOENT;
	        // windows gets a weird error when you try to readlink a file
	        if (code === 'EINVAL' || code === 'UNKNOWN') {
	            // exists, but not a symlink, we don't know WHAT it is, so remove
	            // all IFMT bits.
	            ter &= IFMT_UNKNOWN;
	        }
	        this.#type = ter;
	        // windows just gets ENOENT in this case.  We do cover the case,
	        // just disabled because it's impossible on Windows CI
	        /* c8 ignore start */
	        if (code === 'ENOTDIR' && this.parent) {
	            this.parent.#markENOTDIR();
	        }
	        /* c8 ignore stop */
	    }
	    #readdirAddChild(e, c) {
	        return (this.#readdirMaybePromoteChild(e, c) ||
	            this.#readdirAddNewChild(e, c));
	    }
	    #readdirAddNewChild(e, c) {
	        // alloc new entry at head, so it's never provisional
	        const type = entToType(e);
	        const child = this.newChild(e.name, type, { parent: this });
	        const ifmt = child.#type & IFMT;
	        if (ifmt !== IFDIR && ifmt !== IFLNK && ifmt !== UNKNOWN) {
	            child.#type |= ENOTDIR;
	        }
	        c.unshift(child);
	        c.provisional++;
	        return child;
	    }
	    #readdirMaybePromoteChild(e, c) {
	        for (let p = c.provisional; p < c.length; p++) {
	            const pchild = c[p];
	            const name = this.nocase ? normalizeNocase(e.name) : normalize(e.name);
	            if (name !== pchild.#matchName) {
	                continue;
	            }
	            return this.#readdirPromoteChild(e, pchild, p, c);
	        }
	    }
	    #readdirPromoteChild(e, p, index, c) {
	        const v = p.name;
	        // retain any other flags, but set ifmt from dirent
	        p.#type = (p.#type & IFMT_UNKNOWN) | entToType(e);
	        // case sensitivity fixing when we learn the true name.
	        if (v !== e.name)
	            p.name = e.name;
	        // just advance provisional index (potentially off the list),
	        // otherwise we have to splice/pop it out and re-insert at head
	        if (index !== c.provisional) {
	            if (index === c.length - 1)
	                c.pop();
	            else
	                c.splice(index, 1);
	            c.unshift(p);
	        }
	        c.provisional++;
	        return p;
	    }
	    /**
	     * Call lstat() on this Path, and update all known information that can be
	     * determined.
	     *
	     * Note that unlike `fs.lstat()`, the returned value does not contain some
	     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that
	     * information is required, you will need to call `fs.lstat` yourself.
	     *
	     * If the Path refers to a nonexistent file, or if the lstat call fails for
	     * any reason, `undefined` is returned.  Otherwise the updated Path object is
	     * returned.
	     *
	     * Results are cached, and thus may be out of date if the filesystem is
	     * mutated.
	     */
	    async lstat() {
	        if ((this.#type & ENOENT) === 0) {
	            try {
	                this.#applyStat(await this.#fs.promises.lstat(this.fullpath()));
	                return this;
	            }
	            catch (er) {
	                this.#lstatFail(er.code);
	            }
	        }
	    }
	    /**
	     * synchronous {@link PathBase.lstat}
	     */
	    lstatSync() {
	        if ((this.#type & ENOENT) === 0) {
	            try {
	                this.#applyStat(this.#fs.lstatSync(this.fullpath()));
	                return this;
	            }
	            catch (er) {
	                this.#lstatFail(er.code);
	            }
	        }
	    }
	    #applyStat(st) {
	        const { atime, atimeMs, birthtime, birthtimeMs, blksize, blocks, ctime, ctimeMs, dev, gid, ino, mode, mtime, mtimeMs, nlink, rdev, size, uid, } = st;
	        this.#atime = atime;
	        this.#atimeMs = atimeMs;
	        this.#birthtime = birthtime;
	        this.#birthtimeMs = birthtimeMs;
	        this.#blksize = blksize;
	        this.#blocks = blocks;
	        this.#ctime = ctime;
	        this.#ctimeMs = ctimeMs;
	        this.#dev = dev;
	        this.#gid = gid;
	        this.#ino = ino;
	        this.#mode = mode;
	        this.#mtime = mtime;
	        this.#mtimeMs = mtimeMs;
	        this.#nlink = nlink;
	        this.#rdev = rdev;
	        this.#size = size;
	        this.#uid = uid;
	        const ifmt = entToType(st);
	        // retain any other flags, but set the ifmt
	        this.#type = (this.#type & IFMT_UNKNOWN) | ifmt | LSTAT_CALLED;
	        if (ifmt !== UNKNOWN && ifmt !== IFDIR && ifmt !== IFLNK) {
	            this.#type |= ENOTDIR;
	        }
	    }
	    #onReaddirCB = [];
	    #readdirCBInFlight = false;
	    #callOnReaddirCB(children) {
	        this.#readdirCBInFlight = false;
	        const cbs = this.#onReaddirCB.slice();
	        this.#onReaddirCB.length = 0;
	        cbs.forEach(cb => cb(null, children));
	    }
	    /**
	     * Standard node-style callback interface to get list of directory entries.
	     *
	     * If the Path cannot or does not contain any children, then an empty array
	     * is returned.
	     *
	     * Results are cached, and thus may be out of date if the filesystem is
	     * mutated.
	     *
	     * @param cb The callback called with (er, entries).  Note that the `er`
	     * param is somewhat extraneous, as all readdir() errors are handled and
	     * simply result in an empty set of entries being returned.
	     * @param allowZalgo Boolean indicating that immediately known results should
	     * *not* be deferred with `queueMicrotask`. Defaults to `false`. Release
	     * zalgo at your peril, the dark pony lord is devious and unforgiving.
	     */
	    readdirCB(cb, allowZalgo = false) {
	        if (!this.canReaddir()) {
	            if (allowZalgo)
	                cb(null, []);
	            else
	                queueMicrotask(() => cb(null, []));
	            return;
	        }
	        const children = this.children();
	        if (this.calledReaddir()) {
	            const c = children.slice(0, children.provisional);
	            if (allowZalgo)
	                cb(null, c);
	            else
	                queueMicrotask(() => cb(null, c));
	            return;
	        }
	        // don't have to worry about zalgo at this point.
	        this.#onReaddirCB.push(cb);
	        if (this.#readdirCBInFlight) {
	            return;
	        }
	        this.#readdirCBInFlight = true;
	        // else read the directory, fill up children
	        // de-provisionalize any provisional children.
	        const fullpath = this.fullpath();
	        this.#fs.readdir(fullpath, { withFileTypes: true }, (er, entries) => {
	            if (er) {
	                this.#readdirFail(er.code);
	                children.provisional = 0;
	            }
	            else {
	                // if we didn't get an error, we always get entries.
	                //@ts-ignore
	                for (const e of entries) {
	                    this.#readdirAddChild(e, children);
	                }
	                this.#readdirSuccess(children);
	            }
	            this.#callOnReaddirCB(children.slice(0, children.provisional));
	            return;
	        });
	    }
	    #asyncReaddirInFlight;
	    /**
	     * Return an array of known child entries.
	     *
	     * If the Path cannot or does not contain any children, then an empty array
	     * is returned.
	     *
	     * Results are cached, and thus may be out of date if the filesystem is
	     * mutated.
	     */
	    async readdir() {
	        if (!this.canReaddir()) {
	            return [];
	        }
	        const children = this.children();
	        if (this.calledReaddir()) {
	            return children.slice(0, children.provisional);
	        }
	        // else read the directory, fill up children
	        // de-provisionalize any provisional children.
	        const fullpath = this.fullpath();
	        if (this.#asyncReaddirInFlight) {
	            await this.#asyncReaddirInFlight;
	        }
	        else {
	            /* c8 ignore start */
	            let resolve = () => { };
	            /* c8 ignore stop */
	            this.#asyncReaddirInFlight = new Promise(res => (resolve = res));
	            try {
	                for (const e of await this.#fs.promises.readdir(fullpath, {
	                    withFileTypes: true,
	                })) {
	                    this.#readdirAddChild(e, children);
	                }
	                this.#readdirSuccess(children);
	            }
	            catch (er) {
	                this.#readdirFail(er.code);
	                children.provisional = 0;
	            }
	            this.#asyncReaddirInFlight = undefined;
	            resolve();
	        }
	        return children.slice(0, children.provisional);
	    }
	    /**
	     * synchronous {@link PathBase.readdir}
	     */
	    readdirSync() {
	        if (!this.canReaddir()) {
	            return [];
	        }
	        const children = this.children();
	        if (this.calledReaddir()) {
	            return children.slice(0, children.provisional);
	        }
	        // else read the directory, fill up children
	        // de-provisionalize any provisional children.
	        const fullpath = this.fullpath();
	        try {
	            for (const e of this.#fs.readdirSync(fullpath, {
	                withFileTypes: true,
	            })) {
	                this.#readdirAddChild(e, children);
	            }
	            this.#readdirSuccess(children);
	        }
	        catch (er) {
	            this.#readdirFail(er.code);
	            children.provisional = 0;
	        }
	        return children.slice(0, children.provisional);
	    }
	    canReaddir() {
	        if (this.#type & ENOCHILD)
	            return false;
	        const ifmt = IFMT & this.#type;
	        // we always set ENOTDIR when setting IFMT, so should be impossible
	        /* c8 ignore start */
	        if (!(ifmt === UNKNOWN || ifmt === IFDIR || ifmt === IFLNK)) {
	            return false;
	        }
	        /* c8 ignore stop */
	        return true;
	    }
	    shouldWalk(dirs, walkFilter) {
	        return ((this.#type & IFDIR) === IFDIR &&
	            !(this.#type & ENOCHILD) &&
	            !dirs.has(this) &&
	            (!walkFilter || walkFilter(this)));
	    }
	    /**
	     * Return the Path object corresponding to path as resolved
	     * by realpath(3).
	     *
	     * If the realpath call fails for any reason, `undefined` is returned.
	     *
	     * Result is cached, and thus may be outdated if the filesystem is mutated.
	     * On success, returns a Path object.
	     */
	    async realpath() {
	        if (this.#realpath)
	            return this.#realpath;
	        if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type)
	            return undefined;
	        try {
	            const rp = await this.#fs.promises.realpath(this.fullpath());
	            return (this.#realpath = this.resolve(rp));
	        }
	        catch (_) {
	            this.#markENOREALPATH();
	        }
	    }
	    /**
	     * Synchronous {@link realpath}
	     */
	    realpathSync() {
	        if (this.#realpath)
	            return this.#realpath;
	        if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type)
	            return undefined;
	        try {
	            const rp = this.#fs.realpathSync(this.fullpath());
	            return (this.#realpath = this.resolve(rp));
	        }
	        catch (_) {
	            this.#markENOREALPATH();
	        }
	    }
	    /**
	     * Internal method to mark this Path object as the scurry cwd,
	     * called by {@link PathScurry#chdir}
	     *
	     * @internal
	     */
	    [setAsCwd](oldCwd) {
	        if (oldCwd === this)
	            return;
	        oldCwd.isCWD = false;
	        this.isCWD = true;
	        const changed = new Set([]);
	        let rp = [];
	        let p = this;
	        while (p && p.parent) {
	            changed.add(p);
	            p.#relative = rp.join(this.sep);
	            p.#relativePosix = rp.join('/');
	            p = p.parent;
	            rp.push('..');
	        }
	        // now un-memoize parents of old cwd
	        p = oldCwd;
	        while (p && p.parent && !changed.has(p)) {
	            p.#relative = undefined;
	            p.#relativePosix = undefined;
	            p = p.parent;
	        }
	    }
	}
	commonjs.PathBase = PathBase;
	/**
	 * Path class used on win32 systems
	 *
	 * Uses `'\\'` as the path separator for returned paths, either `'\\'` or `'/'`
	 * as the path separator for parsing paths.
	 */
	class PathWin32 extends PathBase {
	    /**
	     * Separator for generating path strings.
	     */
	    sep = '\\';
	    /**
	     * Separator for parsing path strings.
	     */
	    splitSep = eitherSep;
	    /**
	     * Do not create new Path objects directly.  They should always be accessed
	     * via the PathScurry class or other methods on the Path class.
	     *
	     * @internal
	     */
	    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
	        super(name, type, root, roots, nocase, children, opts);
	    }
	    /**
	     * @internal
	     */
	    newChild(name, type = UNKNOWN, opts = {}) {
	        return new PathWin32(name, type, this.root, this.roots, this.nocase, this.childrenCache(), opts);
	    }
	    /**
	     * @internal
	     */
	    getRootString(path) {
	        return node_path_1.win32.parse(path).root;
	    }
	    /**
	     * @internal
	     */
	    getRoot(rootPath) {
	        rootPath = uncToDrive(rootPath.toUpperCase());
	        if (rootPath === this.root.name) {
	            return this.root;
	        }
	        // ok, not that one, check if it matches another we know about
	        for (const [compare, root] of Object.entries(this.roots)) {
	            if (this.sameRoot(rootPath, compare)) {
	                return (this.roots[rootPath] = root);
	            }
	        }
	        // otherwise, have to create a new one.
	        return (this.roots[rootPath] = new PathScurryWin32(rootPath, this).root);
	    }
	    /**
	     * @internal
	     */
	    sameRoot(rootPath, compare = this.root.name) {
	        // windows can (rarely) have case-sensitive filesystem, but
	        // UNC and drive letters are always case-insensitive, and canonically
	        // represented uppercase.
	        rootPath = rootPath
	            .toUpperCase()
	            .replace(/\//g, '\\')
	            .replace(uncDriveRegexp, '$1\\');
	        return rootPath === compare;
	    }
	}
	commonjs.PathWin32 = PathWin32;
	/**
	 * Path class used on all posix systems.
	 *
	 * Uses `'/'` as the path separator.
	 */
	class PathPosix extends PathBase {
	    /**
	     * separator for parsing path strings
	     */
	    splitSep = '/';
	    /**
	     * separator for generating path strings
	     */
	    sep = '/';
	    /**
	     * Do not create new Path objects directly.  They should always be accessed
	     * via the PathScurry class or other methods on the Path class.
	     *
	     * @internal
	     */
	    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
	        super(name, type, root, roots, nocase, children, opts);
	    }
	    /**
	     * @internal
	     */
	    getRootString(path) {
	        return path.startsWith('/') ? '/' : '';
	    }
	    /**
	     * @internal
	     */
	    getRoot(_rootPath) {
	        return this.root;
	    }
	    /**
	     * @internal
	     */
	    newChild(name, type = UNKNOWN, opts = {}) {
	        return new PathPosix(name, type, this.root, this.roots, this.nocase, this.childrenCache(), opts);
	    }
	}
	commonjs.PathPosix = PathPosix;
	/**
	 * The base class for all PathScurry classes, providing the interface for path
	 * resolution and filesystem operations.
	 *
	 * Typically, you should *not* instantiate this class directly, but rather one
	 * of the platform-specific classes, or the exported {@link PathScurry} which
	 * defaults to the current platform.
	 */
	class PathScurryBase {
	    /**
	     * The root Path entry for the current working directory of this Scurry
	     */
	    root;
	    /**
	     * The string path for the root of this Scurry's current working directory
	     */
	    rootPath;
	    /**
	     * A collection of all roots encountered, referenced by rootPath
	     */
	    roots;
	    /**
	     * The Path entry corresponding to this PathScurry's current working directory.
	     */
	    cwd;
	    #resolveCache;
	    #resolvePosixCache;
	    #children;
	    /**
	     * Perform path comparisons case-insensitively.
	     *
	     * Defaults true on Darwin and Windows systems, false elsewhere.
	     */
	    nocase;
	    #fs;
	    /**
	     * This class should not be instantiated directly.
	     *
	     * Use PathScurryWin32, PathScurryDarwin, PathScurryPosix, or PathScurry
	     *
	     * @internal
	     */
	    constructor(cwd = process.cwd(), pathImpl, sep, { nocase, childrenCacheSize = 16 * 1024, fs = defaultFS, } = {}) {
	        this.#fs = fsFromOption(fs);
	        if (cwd instanceof URL || cwd.startsWith('file://')) {
	            cwd = (0, node_url_1.fileURLToPath)(cwd);
	        }
	        // resolve and split root, and then add to the store.
	        // this is the only time we call path.resolve()
	        const cwdPath = pathImpl.resolve(cwd);
	        this.roots = Object.create(null);
	        this.rootPath = this.parseRootPath(cwdPath);
	        this.#resolveCache = new ResolveCache();
	        this.#resolvePosixCache = new ResolveCache();
	        this.#children = new ChildrenCache(childrenCacheSize);
	        const split = cwdPath.substring(this.rootPath.length).split(sep);
	        // resolve('/') leaves '', splits to [''], we don't want that.
	        if (split.length === 1 && !split[0]) {
	            split.pop();
	        }
	        /* c8 ignore start */
	        if (nocase === undefined) {
	            throw new TypeError('must provide nocase setting to PathScurryBase ctor');
	        }
	        /* c8 ignore stop */
	        this.nocase = nocase;
	        this.root = this.newRoot(this.#fs);
	        this.roots[this.rootPath] = this.root;
	        let prev = this.root;
	        let len = split.length - 1;
	        const joinSep = pathImpl.sep;
	        let abs = this.rootPath;
	        let sawFirst = false;
	        for (const part of split) {
	            const l = len--;
	            prev = prev.child(part, {
	                relative: new Array(l).fill('..').join(joinSep),
	                relativePosix: new Array(l).fill('..').join('/'),
	                fullpath: (abs += (sawFirst ? '' : joinSep) + part),
	            });
	            sawFirst = true;
	        }
	        this.cwd = prev;
	    }
	    /**
	     * Get the depth of a provided path, string, or the cwd
	     */
	    depth(path = this.cwd) {
	        if (typeof path === 'string') {
	            path = this.cwd.resolve(path);
	        }
	        return path.depth();
	    }
	    /**
	     * Return the cache of child entries.  Exposed so subclasses can create
	     * child Path objects in a platform-specific way.
	     *
	     * @internal
	     */
	    childrenCache() {
	        return this.#children;
	    }
	    /**
	     * Resolve one or more path strings to a resolved string
	     *
	     * Same interface as require('path').resolve.
	     *
	     * Much faster than path.resolve() when called multiple times for the same
	     * path, because the resolved Path objects are cached.  Much slower
	     * otherwise.
	     */
	    resolve(...paths) {
	        // first figure out the minimum number of paths we have to test
	        // we always start at cwd, but any absolutes will bump the start
	        let r = '';
	        for (let i = paths.length - 1; i >= 0; i--) {
	            const p = paths[i];
	            if (!p || p === '.')
	                continue;
	            r = r ? `${p}/${r}` : p;
	            if (this.isAbsolute(p)) {
	                break;
	            }
	        }
	        const cached = this.#resolveCache.get(r);
	        if (cached !== undefined) {
	            return cached;
	        }
	        const result = this.cwd.resolve(r).fullpath();
	        this.#resolveCache.set(r, result);
	        return result;
	    }
	    /**
	     * Resolve one or more path strings to a resolved string, returning
	     * the posix path.  Identical to .resolve() on posix systems, but on
	     * windows will return a forward-slash separated UNC path.
	     *
	     * Same interface as require('path').resolve.
	     *
	     * Much faster than path.resolve() when called multiple times for the same
	     * path, because the resolved Path objects are cached.  Much slower
	     * otherwise.
	     */
	    resolvePosix(...paths) {
	        // first figure out the minimum number of paths we have to test
	        // we always start at cwd, but any absolutes will bump the start
	        let r = '';
	        for (let i = paths.length - 1; i >= 0; i--) {
	            const p = paths[i];
	            if (!p || p === '.')
	                continue;
	            r = r ? `${p}/${r}` : p;
	            if (this.isAbsolute(p)) {
	                break;
	            }
	        }
	        const cached = this.#resolvePosixCache.get(r);
	        if (cached !== undefined) {
	            return cached;
	        }
	        const result = this.cwd.resolve(r).fullpathPosix();
	        this.#resolvePosixCache.set(r, result);
	        return result;
	    }
	    /**
	     * find the relative path from the cwd to the supplied path string or entry
	     */
	    relative(entry = this.cwd) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        return entry.relative();
	    }
	    /**
	     * find the relative path from the cwd to the supplied path string or
	     * entry, using / as the path delimiter, even on Windows.
	     */
	    relativePosix(entry = this.cwd) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        return entry.relativePosix();
	    }
	    /**
	     * Return the basename for the provided string or Path object
	     */
	    basename(entry = this.cwd) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        return entry.name;
	    }
	    /**
	     * Return the dirname for the provided string or Path object
	     */
	    dirname(entry = this.cwd) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        return (entry.parent || entry).fullpath();
	    }
	    async readdir(entry = this.cwd, opts = {
	        withFileTypes: true,
	    }) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes } = opts;
	        if (!entry.canReaddir()) {
	            return [];
	        }
	        else {
	            const p = await entry.readdir();
	            return withFileTypes ? p : p.map(e => e.name);
	        }
	    }
	    readdirSync(entry = this.cwd, opts = {
	        withFileTypes: true,
	    }) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes = true } = opts;
	        if (!entry.canReaddir()) {
	            return [];
	        }
	        else if (withFileTypes) {
	            return entry.readdirSync();
	        }
	        else {
	            return entry.readdirSync().map(e => e.name);
	        }
	    }
	    /**
	     * Call lstat() on the string or Path object, and update all known
	     * information that can be determined.
	     *
	     * Note that unlike `fs.lstat()`, the returned value does not contain some
	     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that
	     * information is required, you will need to call `fs.lstat` yourself.
	     *
	     * If the Path refers to a nonexistent file, or if the lstat call fails for
	     * any reason, `undefined` is returned.  Otherwise the updated Path object is
	     * returned.
	     *
	     * Results are cached, and thus may be out of date if the filesystem is
	     * mutated.
	     */
	    async lstat(entry = this.cwd) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        return entry.lstat();
	    }
	    /**
	     * synchronous {@link PathScurryBase.lstat}
	     */
	    lstatSync(entry = this.cwd) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        return entry.lstatSync();
	    }
	    async readlink(entry = this.cwd, { withFileTypes } = {
	        withFileTypes: false,
	    }) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            withFileTypes = entry.withFileTypes;
	            entry = this.cwd;
	        }
	        const e = await entry.readlink();
	        return withFileTypes ? e : e?.fullpath();
	    }
	    readlinkSync(entry = this.cwd, { withFileTypes } = {
	        withFileTypes: false,
	    }) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            withFileTypes = entry.withFileTypes;
	            entry = this.cwd;
	        }
	        const e = entry.readlinkSync();
	        return withFileTypes ? e : e?.fullpath();
	    }
	    async realpath(entry = this.cwd, { withFileTypes } = {
	        withFileTypes: false,
	    }) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            withFileTypes = entry.withFileTypes;
	            entry = this.cwd;
	        }
	        const e = await entry.realpath();
	        return withFileTypes ? e : e?.fullpath();
	    }
	    realpathSync(entry = this.cwd, { withFileTypes } = {
	        withFileTypes: false,
	    }) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            withFileTypes = entry.withFileTypes;
	            entry = this.cwd;
	        }
	        const e = entry.realpathSync();
	        return withFileTypes ? e : e?.fullpath();
	    }
	    async walk(entry = this.cwd, opts = {}) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
	        const results = [];
	        if (!filter || filter(entry)) {
	            results.push(withFileTypes ? entry : entry.fullpath());
	        }
	        const dirs = new Set();
	        const walk = (dir, cb) => {
	            dirs.add(dir);
	            dir.readdirCB((er, entries) => {
	                /* c8 ignore start */
	                if (er) {
	                    return cb(er);
	                }
	                /* c8 ignore stop */
	                let len = entries.length;
	                if (!len)
	                    return cb();
	                const next = () => {
	                    if (--len === 0) {
	                        cb();
	                    }
	                };
	                for (const e of entries) {
	                    if (!filter || filter(e)) {
	                        results.push(withFileTypes ? e : e.fullpath());
	                    }
	                    if (follow && e.isSymbolicLink()) {
	                        e.realpath()
	                            .then(r => (r?.isUnknown() ? r.lstat() : r))
	                            .then(r => r?.shouldWalk(dirs, walkFilter) ? walk(r, next) : next());
	                    }
	                    else {
	                        if (e.shouldWalk(dirs, walkFilter)) {
	                            walk(e, next);
	                        }
	                        else {
	                            next();
	                        }
	                    }
	                }
	            }, true); // zalgooooooo
	        };
	        const start = entry;
	        return new Promise((res, rej) => {
	            walk(start, er => {
	                /* c8 ignore start */
	                if (er)
	                    return rej(er);
	                /* c8 ignore stop */
	                res(results);
	            });
	        });
	    }
	    walkSync(entry = this.cwd, opts = {}) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
	        const results = [];
	        if (!filter || filter(entry)) {
	            results.push(withFileTypes ? entry : entry.fullpath());
	        }
	        const dirs = new Set([entry]);
	        for (const dir of dirs) {
	            const entries = dir.readdirSync();
	            for (const e of entries) {
	                if (!filter || filter(e)) {
	                    results.push(withFileTypes ? e : e.fullpath());
	                }
	                let r = e;
	                if (e.isSymbolicLink()) {
	                    if (!(follow && (r = e.realpathSync())))
	                        continue;
	                    if (r.isUnknown())
	                        r.lstatSync();
	                }
	                if (r.shouldWalk(dirs, walkFilter)) {
	                    dirs.add(r);
	                }
	            }
	        }
	        return results;
	    }
	    /**
	     * Support for `for await`
	     *
	     * Alias for {@link PathScurryBase.iterate}
	     *
	     * Note: As of Node 19, this is very slow, compared to other methods of
	     * walking.  Consider using {@link PathScurryBase.stream} if memory overhead
	     * and backpressure are concerns, or {@link PathScurryBase.walk} if not.
	     */
	    [Symbol.asyncIterator]() {
	        return this.iterate();
	    }
	    iterate(entry = this.cwd, options = {}) {
	        // iterating async over the stream is significantly more performant,
	        // especially in the warm-cache scenario, because it buffers up directory
	        // entries in the background instead of waiting for a yield for each one.
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            options = entry;
	            entry = this.cwd;
	        }
	        return this.stream(entry, options)[Symbol.asyncIterator]();
	    }
	    /**
	     * Iterating over a PathScurry performs a synchronous walk.
	     *
	     * Alias for {@link PathScurryBase.iterateSync}
	     */
	    [Symbol.iterator]() {
	        return this.iterateSync();
	    }
	    *iterateSync(entry = this.cwd, opts = {}) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
	        if (!filter || filter(entry)) {
	            yield withFileTypes ? entry : entry.fullpath();
	        }
	        const dirs = new Set([entry]);
	        for (const dir of dirs) {
	            const entries = dir.readdirSync();
	            for (const e of entries) {
	                if (!filter || filter(e)) {
	                    yield withFileTypes ? e : e.fullpath();
	                }
	                let r = e;
	                if (e.isSymbolicLink()) {
	                    if (!(follow && (r = e.realpathSync())))
	                        continue;
	                    if (r.isUnknown())
	                        r.lstatSync();
	                }
	                if (r.shouldWalk(dirs, walkFilter)) {
	                    dirs.add(r);
	                }
	            }
	        }
	    }
	    stream(entry = this.cwd, opts = {}) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
	        const results = new minipass_1.Minipass({ objectMode: true });
	        if (!filter || filter(entry)) {
	            results.write(withFileTypes ? entry : entry.fullpath());
	        }
	        const dirs = new Set();
	        const queue = [entry];
	        let processing = 0;
	        const process = () => {
	            let paused = false;
	            while (!paused) {
	                const dir = queue.shift();
	                if (!dir) {
	                    if (processing === 0)
	                        results.end();
	                    return;
	                }
	                processing++;
	                dirs.add(dir);
	                const onReaddir = (er, entries, didRealpaths = false) => {
	                    /* c8 ignore start */
	                    if (er)
	                        return results.emit('error', er);
	                    /* c8 ignore stop */
	                    if (follow && !didRealpaths) {
	                        const promises = [];
	                        for (const e of entries) {
	                            if (e.isSymbolicLink()) {
	                                promises.push(e
	                                    .realpath()
	                                    .then((r) => r?.isUnknown() ? r.lstat() : r));
	                            }
	                        }
	                        if (promises.length) {
	                            Promise.all(promises).then(() => onReaddir(null, entries, true));
	                            return;
	                        }
	                    }
	                    for (const e of entries) {
	                        if (e && (!filter || filter(e))) {
	                            if (!results.write(withFileTypes ? e : e.fullpath())) {
	                                paused = true;
	                            }
	                        }
	                    }
	                    processing--;
	                    for (const e of entries) {
	                        const r = e.realpathCached() || e;
	                        if (r.shouldWalk(dirs, walkFilter)) {
	                            queue.push(r);
	                        }
	                    }
	                    if (paused && !results.flowing) {
	                        results.once('drain', process);
	                    }
	                    else if (!sync) {
	                        process();
	                    }
	                };
	                // zalgo containment
	                let sync = true;
	                dir.readdirCB(onReaddir, true);
	                sync = false;
	            }
	        };
	        process();
	        return results;
	    }
	    streamSync(entry = this.cwd, opts = {}) {
	        if (typeof entry === 'string') {
	            entry = this.cwd.resolve(entry);
	        }
	        else if (!(entry instanceof PathBase)) {
	            opts = entry;
	            entry = this.cwd;
	        }
	        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;
	        const results = new minipass_1.Minipass({ objectMode: true });
	        const dirs = new Set();
	        if (!filter || filter(entry)) {
	            results.write(withFileTypes ? entry : entry.fullpath());
	        }
	        const queue = [entry];
	        let processing = 0;
	        const process = () => {
	            let paused = false;
	            while (!paused) {
	                const dir = queue.shift();
	                if (!dir) {
	                    if (processing === 0)
	                        results.end();
	                    return;
	                }
	                processing++;
	                dirs.add(dir);
	                const entries = dir.readdirSync();
	                for (const e of entries) {
	                    if (!filter || filter(e)) {
	                        if (!results.write(withFileTypes ? e : e.fullpath())) {
	                            paused = true;
	                        }
	                    }
	                }
	                processing--;
	                for (const e of entries) {
	                    let r = e;
	                    if (e.isSymbolicLink()) {
	                        if (!(follow && (r = e.realpathSync())))
	                            continue;
	                        if (r.isUnknown())
	                            r.lstatSync();
	                    }
	                    if (r.shouldWalk(dirs, walkFilter)) {
	                        queue.push(r);
	                    }
	                }
	            }
	            if (paused && !results.flowing)
	                results.once('drain', process);
	        };
	        process();
	        return results;
	    }
	    chdir(path = this.cwd) {
	        const oldCwd = this.cwd;
	        this.cwd = typeof path === 'string' ? this.cwd.resolve(path) : path;
	        this.cwd[setAsCwd](oldCwd);
	    }
	}
	commonjs.PathScurryBase = PathScurryBase;
	/**
	 * Windows implementation of {@link PathScurryBase}
	 *
	 * Defaults to case insensitve, uses `'\\'` to generate path strings.  Uses
	 * {@link PathWin32} for Path objects.
	 */
	class PathScurryWin32 extends PathScurryBase {
	    /**
	     * separator for generating path strings
	     */
	    sep = '\\';
	    constructor(cwd = process.cwd(), opts = {}) {
	        const { nocase = true } = opts;
	        super(cwd, node_path_1.win32, '\\', { ...opts, nocase });
	        this.nocase = nocase;
	        for (let p = this.cwd; p; p = p.parent) {
	            p.nocase = this.nocase;
	        }
	    }
	    /**
	     * @internal
	     */
	    parseRootPath(dir) {
	        // if the path starts with a single separator, it's not a UNC, and we'll
	        // just get separator as the root, and driveFromUNC will return \
	        // In that case, mount \ on the root from the cwd.
	        return node_path_1.win32.parse(dir).root.toUpperCase();
	    }
	    /**
	     * @internal
	     */
	    newRoot(fs) {
	        return new PathWin32(this.rootPath, IFDIR, undefined, this.roots, this.nocase, this.childrenCache(), { fs });
	    }
	    /**
	     * Return true if the provided path string is an absolute path
	     */
	    isAbsolute(p) {
	        return (p.startsWith('/') || p.startsWith('\\') || /^[a-z]:(\/|\\)/i.test(p));
	    }
	}
	commonjs.PathScurryWin32 = PathScurryWin32;
	/**
	 * {@link PathScurryBase} implementation for all posix systems other than Darwin.
	 *
	 * Defaults to case-sensitive matching, uses `'/'` to generate path strings.
	 *
	 * Uses {@link PathPosix} for Path objects.
	 */
	class PathScurryPosix extends PathScurryBase {
	    /**
	     * separator for generating path strings
	     */
	    sep = '/';
	    constructor(cwd = process.cwd(), opts = {}) {
	        const { nocase = false } = opts;
	        super(cwd, node_path_1.posix, '/', { ...opts, nocase });
	        this.nocase = nocase;
	    }
	    /**
	     * @internal
	     */
	    parseRootPath(_dir) {
	        return '/';
	    }
	    /**
	     * @internal
	     */
	    newRoot(fs) {
	        return new PathPosix(this.rootPath, IFDIR, undefined, this.roots, this.nocase, this.childrenCache(), { fs });
	    }
	    /**
	     * Return true if the provided path string is an absolute path
	     */
	    isAbsolute(p) {
	        return p.startsWith('/');
	    }
	}
	commonjs.PathScurryPosix = PathScurryPosix;
	/**
	 * {@link PathScurryBase} implementation for Darwin (macOS) systems.
	 *
	 * Defaults to case-insensitive matching, uses `'/'` for generating path
	 * strings.
	 *
	 * Uses {@link PathPosix} for Path objects.
	 */
	class PathScurryDarwin extends PathScurryPosix {
	    constructor(cwd = process.cwd(), opts = {}) {
	        const { nocase = true } = opts;
	        super(cwd, { ...opts, nocase });
	    }
	}
	commonjs.PathScurryDarwin = PathScurryDarwin;
	/**
	 * Default {@link PathBase} implementation for the current platform.
	 *
	 * {@link PathWin32} on Windows systems, {@link PathPosix} on all others.
	 */
	commonjs.Path = process.platform === 'win32' ? PathWin32 : PathPosix;
	/**
	 * Default {@link PathScurryBase} implementation for the current platform.
	 *
	 * {@link PathScurryWin32} on Windows systems, {@link PathScurryDarwin} on
	 * Darwin (macOS) systems, {@link PathScurryPosix} on all others.
	 */
	commonjs.PathScurry = process.platform === 'win32' ? PathScurryWin32
	    : process.platform === 'darwin' ? PathScurryDarwin
	        : PathScurryPosix;
	
	return commonjs;
}

var pattern = {};

var hasRequiredPattern;

function requirePattern () {
	if (hasRequiredPattern) return pattern;
	hasRequiredPattern = 1;
	// this is just a very light wrapper around 2 arrays with an offset index
	Object.defineProperty(pattern, "__esModule", { value: true });
	pattern.Pattern = void 0;
	const minimatch_1 = requireCommonjs$2();
	const isPatternList = (pl) => pl.length >= 1;
	const isGlobList = (gl) => gl.length >= 1;
	/**
	 * An immutable-ish view on an array of glob parts and their parsed
	 * results
	 */
	class Pattern {
	    #patternList;
	    #globList;
	    #index;
	    length;
	    #platform;
	    #rest;
	    #globString;
	    #isDrive;
	    #isUNC;
	    #isAbsolute;
	    #followGlobstar = true;
	    constructor(patternList, globList, index, platform) {
	        if (!isPatternList(patternList)) {
	            throw new TypeError('empty pattern list');
	        }
	        if (!isGlobList(globList)) {
	            throw new TypeError('empty glob list');
	        }
	        if (globList.length !== patternList.length) {
	            throw new TypeError('mismatched pattern list and glob list lengths');
	        }
	        this.length = patternList.length;
	        if (index < 0 || index >= this.length) {
	            throw new TypeError('index out of range');
	        }
	        this.#patternList = patternList;
	        this.#globList = globList;
	        this.#index = index;
	        this.#platform = platform;
	        // normalize root entries of absolute patterns on initial creation.
	        if (this.#index === 0) {
	            // c: => ['c:/']
	            // C:/ => ['C:/']
	            // C:/x => ['C:/', 'x']
	            // //host/share => ['//host/share/']
	            // //host/share/ => ['//host/share/']
	            // //host/share/x => ['//host/share/', 'x']
	            // /etc => ['/', 'etc']
	            // / => ['/']
	            if (this.isUNC()) {
	                // '' / '' / 'host' / 'share'
	                const [p0, p1, p2, p3, ...prest] = this.#patternList;
	                const [g0, g1, g2, g3, ...grest] = this.#globList;
	                if (prest[0] === '') {
	                    // ends in /
	                    prest.shift();
	                    grest.shift();
	                }
	                const p = [p0, p1, p2, p3, ''].join('/');
	                const g = [g0, g1, g2, g3, ''].join('/');
	                this.#patternList = [p, ...prest];
	                this.#globList = [g, ...grest];
	                this.length = this.#patternList.length;
	            }
	            else if (this.isDrive() || this.isAbsolute()) {
	                const [p1, ...prest] = this.#patternList;
	                const [g1, ...grest] = this.#globList;
	                if (prest[0] === '') {
	                    // ends in /
	                    prest.shift();
	                    grest.shift();
	                }
	                const p = p1 + '/';
	                const g = g1 + '/';
	                this.#patternList = [p, ...prest];
	                this.#globList = [g, ...grest];
	                this.length = this.#patternList.length;
	            }
	        }
	    }
	    /**
	     * The first entry in the parsed list of patterns
	     */
	    pattern() {
	        return this.#patternList[this.#index];
	    }
	    /**
	     * true of if pattern() returns a string
	     */
	    isString() {
	        return typeof this.#patternList[this.#index] === 'string';
	    }
	    /**
	     * true of if pattern() returns GLOBSTAR
	     */
	    isGlobstar() {
	        return this.#patternList[this.#index] === minimatch_1.GLOBSTAR;
	    }
	    /**
	     * true if pattern() returns a regexp
	     */
	    isRegExp() {
	        return this.#patternList[this.#index] instanceof RegExp;
	    }
	    /**
	     * The /-joined set of glob parts that make up this pattern
	     */
	    globString() {
	        return (this.#globString =
	            this.#globString ||
	                (this.#index === 0 ?
	                    this.isAbsolute() ?
	                        this.#globList[0] + this.#globList.slice(1).join('/')
	                        : this.#globList.join('/')
	                    : this.#globList.slice(this.#index).join('/')));
	    }
	    /**
	     * true if there are more pattern parts after this one
	     */
	    hasMore() {
	        return this.length > this.#index + 1;
	    }
	    /**
	     * The rest of the pattern after this part, or null if this is the end
	     */
	    rest() {
	        if (this.#rest !== undefined)
	            return this.#rest;
	        if (!this.hasMore())
	            return (this.#rest = null);
	        this.#rest = new Pattern(this.#patternList, this.#globList, this.#index + 1, this.#platform);
	        this.#rest.#isAbsolute = this.#isAbsolute;
	        this.#rest.#isUNC = this.#isUNC;
	        this.#rest.#isDrive = this.#isDrive;
	        return this.#rest;
	    }
	    /**
	     * true if the pattern represents a //unc/path/ on windows
	     */
	    isUNC() {
	        const pl = this.#patternList;
	        return this.#isUNC !== undefined ?
	            this.#isUNC
	            : (this.#isUNC =
	                this.#platform === 'win32' &&
	                    this.#index === 0 &&
	                    pl[0] === '' &&
	                    pl[1] === '' &&
	                    typeof pl[2] === 'string' &&
	                    !!pl[2] &&
	                    typeof pl[3] === 'string' &&
	                    !!pl[3]);
	    }
	    // pattern like C:/...
	    // split = ['C:', ...]
	    // XXX: would be nice to handle patterns like `c:*` to test the cwd
	    // in c: for *, but I don't know of a way to even figure out what that
	    // cwd is without actually chdir'ing into it?
	    /**
	     * True if the pattern starts with a drive letter on Windows
	     */
	    isDrive() {
	        const pl = this.#patternList;
	        return this.#isDrive !== undefined ?
	            this.#isDrive
	            : (this.#isDrive =
	                this.#platform === 'win32' &&
	                    this.#index === 0 &&
	                    this.length > 1 &&
	                    typeof pl[0] === 'string' &&
	                    /^[a-z]:$/i.test(pl[0]));
	    }
	    // pattern = '/' or '/...' or '/x/...'
	    // split = ['', ''] or ['', ...] or ['', 'x', ...]
	    // Drive and UNC both considered absolute on windows
	    /**
	     * True if the pattern is rooted on an absolute path
	     */
	    isAbsolute() {
	        const pl = this.#patternList;
	        return this.#isAbsolute !== undefined ?
	            this.#isAbsolute
	            : (this.#isAbsolute =
	                (pl[0] === '' && pl.length > 1) ||
	                    this.isDrive() ||
	                    this.isUNC());
	    }
	    /**
	     * consume the root of the pattern, and return it
	     */
	    root() {
	        const p = this.#patternList[0];
	        return (typeof p === 'string' && this.isAbsolute() && this.#index === 0) ?
	            p
	            : '';
	    }
	    /**
	     * Check to see if the current globstar pattern is allowed to follow
	     * a symbolic link.
	     */
	    checkFollowGlobstar() {
	        return !(this.#index === 0 ||
	            !this.isGlobstar() ||
	            !this.#followGlobstar);
	    }
	    /**
	     * Mark that the current globstar pattern is following a symbolic link
	     */
	    markFollowGlobstar() {
	        if (this.#index === 0 || !this.isGlobstar() || !this.#followGlobstar)
	            return false;
	        this.#followGlobstar = false;
	        return true;
	    }
	}
	pattern.Pattern = Pattern;
	
	return pattern;
}

var walker = {};

var ignore = {};

var hasRequiredIgnore;

function requireIgnore () {
	if (hasRequiredIgnore) return ignore;
	hasRequiredIgnore = 1;
	// give it a pattern, and it'll be able to tell you if
	// a given path should be ignored.
	// Ignoring a path ignores its children if the pattern ends in /**
	// Ignores are always parsed in dot:true mode
	Object.defineProperty(ignore, "__esModule", { value: true });
	ignore.Ignore = void 0;
	const minimatch_1 = requireCommonjs$2();
	const pattern_js_1 = requirePattern();
	const defaultPlatform = (typeof process === 'object' &&
	    process &&
	    typeof process.platform === 'string') ?
	    process.platform
	    : 'linux';
	/**
	 * Class used to process ignored patterns
	 */
	class Ignore {
	    relative;
	    relativeChildren;
	    absolute;
	    absoluteChildren;
	    platform;
	    mmopts;
	    constructor(ignored, { nobrace, nocase, noext, noglobstar, platform = defaultPlatform, }) {
	        this.relative = [];
	        this.absolute = [];
	        this.relativeChildren = [];
	        this.absoluteChildren = [];
	        this.platform = platform;
	        this.mmopts = {
	            dot: true,
	            nobrace,
	            nocase,
	            noext,
	            noglobstar,
	            optimizationLevel: 2,
	            platform,
	            nocomment: true,
	            nonegate: true,
	        };
	        for (const ign of ignored)
	            this.add(ign);
	    }
	    add(ign) {
	        // this is a little weird, but it gives us a clean set of optimized
	        // minimatch matchers, without getting tripped up if one of them
	        // ends in /** inside a brace section, and it's only inefficient at
	        // the start of the walk, not along it.
	        // It'd be nice if the Pattern class just had a .test() method, but
	        // handling globstars is a bit of a pita, and that code already lives
	        // in minimatch anyway.
	        // Another way would be if maybe Minimatch could take its set/globParts
	        // as an option, and then we could at least just use Pattern to test
	        // for absolute-ness.
	        // Yet another way, Minimatch could take an array of glob strings, and
	        // a cwd option, and do the right thing.
	        const mm = new minimatch_1.Minimatch(ign, this.mmopts);
	        for (let i = 0; i < mm.set.length; i++) {
	            const parsed = mm.set[i];
	            const globParts = mm.globParts[i];
	            /* c8 ignore start */
	            if (!parsed || !globParts) {
	                throw new Error('invalid pattern object');
	            }
	            // strip off leading ./ portions
	            // https://github.com/isaacs/node-glob/issues/570
	            while (parsed[0] === '.' && globParts[0] === '.') {
	                parsed.shift();
	                globParts.shift();
	            }
	            /* c8 ignore stop */
	            const p = new pattern_js_1.Pattern(parsed, globParts, 0, this.platform);
	            const m = new minimatch_1.Minimatch(p.globString(), this.mmopts);
	            const children = globParts[globParts.length - 1] === '**';
	            const absolute = p.isAbsolute();
	            if (absolute)
	                this.absolute.push(m);
	            else
	                this.relative.push(m);
	            if (children) {
	                if (absolute)
	                    this.absoluteChildren.push(m);
	                else
	                    this.relativeChildren.push(m);
	            }
	        }
	    }
	    ignored(p) {
	        const fullpath = p.fullpath();
	        const fullpaths = `${fullpath}/`;
	        const relative = p.relative() || '.';
	        const relatives = `${relative}/`;
	        for (const m of this.relative) {
	            if (m.match(relative) || m.match(relatives))
	                return true;
	        }
	        for (const m of this.absolute) {
	            if (m.match(fullpath) || m.match(fullpaths))
	                return true;
	        }
	        return false;
	    }
	    childrenIgnored(p) {
	        const fullpath = p.fullpath() + '/';
	        const relative = (p.relative() || '.') + '/';
	        for (const m of this.relativeChildren) {
	            if (m.match(relative))
	                return true;
	        }
	        for (const m of this.absoluteChildren) {
	            if (m.match(fullpath))
	                return true;
	        }
	        return false;
	    }
	}
	ignore.Ignore = Ignore;
	
	return ignore;
}

var processor = {};

var hasRequiredProcessor;

function requireProcessor () {
	if (hasRequiredProcessor) return processor;
	hasRequiredProcessor = 1;
	// synchronous utility for filtering entries and calculating subwalks
	Object.defineProperty(processor, "__esModule", { value: true });
	processor.Processor = processor.SubWalks = processor.MatchRecord = processor.HasWalkedCache = void 0;
	const minimatch_1 = requireCommonjs$2();
	/**
	 * A cache of which patterns have been processed for a given Path
	 */
	class HasWalkedCache {
	    store;
	    constructor(store = new Map()) {
	        this.store = store;
	    }
	    copy() {
	        return new HasWalkedCache(new Map(this.store));
	    }
	    hasWalked(target, pattern) {
	        return this.store.get(target.fullpath())?.has(pattern.globString());
	    }
	    storeWalked(target, pattern) {
	        const fullpath = target.fullpath();
	        const cached = this.store.get(fullpath);
	        if (cached)
	            cached.add(pattern.globString());
	        else
	            this.store.set(fullpath, new Set([pattern.globString()]));
	    }
	}
	processor.HasWalkedCache = HasWalkedCache;
	/**
	 * A record of which paths have been matched in a given walk step,
	 * and whether they only are considered a match if they are a directory,
	 * and whether their absolute or relative path should be returned.
	 */
	class MatchRecord {
	    store = new Map();
	    add(target, absolute, ifDir) {
	        const n = (absolute ? 2 : 0) | (ifDir ? 1 : 0);
	        const current = this.store.get(target);
	        this.store.set(target, current === undefined ? n : n & current);
	    }
	    // match, absolute, ifdir
	    entries() {
	        return [...this.store.entries()].map(([path, n]) => [
	            path,
	            !!(n & 2),
	            !!(n & 1),
	        ]);
	    }
	}
	processor.MatchRecord = MatchRecord;
	/**
	 * A collection of patterns that must be processed in a subsequent step
	 * for a given path.
	 */
	class SubWalks {
	    store = new Map();
	    add(target, pattern) {
	        if (!target.canReaddir()) {
	            return;
	        }
	        const subs = this.store.get(target);
	        if (subs) {
	            if (!subs.find(p => p.globString() === pattern.globString())) {
	                subs.push(pattern);
	            }
	        }
	        else
	            this.store.set(target, [pattern]);
	    }
	    get(target) {
	        const subs = this.store.get(target);
	        /* c8 ignore start */
	        if (!subs) {
	            throw new Error('attempting to walk unknown path');
	        }
	        /* c8 ignore stop */
	        return subs;
	    }
	    entries() {
	        return this.keys().map(k => [k, this.store.get(k)]);
	    }
	    keys() {
	        return [...this.store.keys()].filter(t => t.canReaddir());
	    }
	}
	processor.SubWalks = SubWalks;
	/**
	 * The class that processes patterns for a given path.
	 *
	 * Handles child entry filtering, and determining whether a path's
	 * directory contents must be read.
	 */
	class Processor {
	    hasWalkedCache;
	    matches = new MatchRecord();
	    subwalks = new SubWalks();
	    patterns;
	    follow;
	    dot;
	    opts;
	    constructor(opts, hasWalkedCache) {
	        this.opts = opts;
	        this.follow = !!opts.follow;
	        this.dot = !!opts.dot;
	        this.hasWalkedCache =
	            hasWalkedCache ? hasWalkedCache.copy() : new HasWalkedCache();
	    }
	    processPatterns(target, patterns) {
	        this.patterns = patterns;
	        const processingSet = patterns.map(p => [target, p]);
	        // map of paths to the magic-starting subwalks they need to walk
	        // first item in patterns is the filter
	        for (let [t, pattern] of processingSet) {
	            this.hasWalkedCache.storeWalked(t, pattern);
	            const root = pattern.root();
	            const absolute = pattern.isAbsolute() && this.opts.absolute !== false;
	            // start absolute patterns at root
	            if (root) {
	                t = t.resolve(root === '/' && this.opts.root !== undefined ?
	                    this.opts.root
	                    : root);
	                const rest = pattern.rest();
	                if (!rest) {
	                    this.matches.add(t, true, false);
	                    continue;
	                }
	                else {
	                    pattern = rest;
	                }
	            }
	            if (t.isENOENT())
	                continue;
	            let p;
	            let rest;
	            let changed = false;
	            while (typeof (p = pattern.pattern()) === 'string' &&
	                (rest = pattern.rest())) {
	                const c = t.resolve(p);
	                t = c;
	                pattern = rest;
	                changed = true;
	            }
	            p = pattern.pattern();
	            rest = pattern.rest();
	            if (changed) {
	                if (this.hasWalkedCache.hasWalked(t, pattern))
	                    continue;
	                this.hasWalkedCache.storeWalked(t, pattern);
	            }
	            // now we have either a final string for a known entry,
	            // more strings for an unknown entry,
	            // or a pattern starting with magic, mounted on t.
	            if (typeof p === 'string') {
	                // must not be final entry, otherwise we would have
	                // concatenated it earlier.
	                const ifDir = p === '..' || p === '' || p === '.';
	                this.matches.add(t.resolve(p), absolute, ifDir);
	                continue;
	            }
	            else if (p === minimatch_1.GLOBSTAR) {
	                // if no rest, match and subwalk pattern
	                // if rest, process rest and subwalk pattern
	                // if it's a symlink, but we didn't get here by way of a
	                // globstar match (meaning it's the first time THIS globstar
	                // has traversed a symlink), then we follow it. Otherwise, stop.
	                if (!t.isSymbolicLink() ||
	                    this.follow ||
	                    pattern.checkFollowGlobstar()) {
	                    this.subwalks.add(t, pattern);
	                }
	                const rp = rest?.pattern();
	                const rrest = rest?.rest();
	                if (!rest || ((rp === '' || rp === '.') && !rrest)) {
	                    // only HAS to be a dir if it ends in **/ or **/.
	                    // but ending in ** will match files as well.
	                    this.matches.add(t, absolute, rp === '' || rp === '.');
	                }
	                else {
	                    if (rp === '..') {
	                        // this would mean you're matching **/.. at the fs root,
	                        // and no thanks, I'm not gonna test that specific case.
	                        /* c8 ignore start */
	                        const tp = t.parent || t;
	                        /* c8 ignore stop */
	                        if (!rrest)
	                            this.matches.add(tp, absolute, true);
	                        else if (!this.hasWalkedCache.hasWalked(tp, rrest)) {
	                            this.subwalks.add(tp, rrest);
	                        }
	                    }
	                }
	            }
	            else if (p instanceof RegExp) {
	                this.subwalks.add(t, pattern);
	            }
	        }
	        return this;
	    }
	    subwalkTargets() {
	        return this.subwalks.keys();
	    }
	    child() {
	        return new Processor(this.opts, this.hasWalkedCache);
	    }
	    // return a new Processor containing the subwalks for each
	    // child entry, and a set of matches, and
	    // a hasWalkedCache that's a copy of this one
	    // then we're going to call
	    filterEntries(parent, entries) {
	        const patterns = this.subwalks.get(parent);
	        // put matches and entry walks into the results processor
	        const results = this.child();
	        for (const e of entries) {
	            for (const pattern of patterns) {
	                const absolute = pattern.isAbsolute();
	                const p = pattern.pattern();
	                const rest = pattern.rest();
	                if (p === minimatch_1.GLOBSTAR) {
	                    results.testGlobstar(e, pattern, rest, absolute);
	                }
	                else if (p instanceof RegExp) {
	                    results.testRegExp(e, p, rest, absolute);
	                }
	                else {
	                    results.testString(e, p, rest, absolute);
	                }
	            }
	        }
	        return results;
	    }
	    testGlobstar(e, pattern, rest, absolute) {
	        if (this.dot || !e.name.startsWith('.')) {
	            if (!pattern.hasMore()) {
	                this.matches.add(e, absolute, false);
	            }
	            if (e.canReaddir()) {
	                // if we're in follow mode or it's not a symlink, just keep
	                // testing the same pattern. If there's more after the globstar,
	                // then this symlink consumes the globstar. If not, then we can
	                // follow at most ONE symlink along the way, so we mark it, which
	                // also checks to ensure that it wasn't already marked.
	                if (this.follow || !e.isSymbolicLink()) {
	                    this.subwalks.add(e, pattern);
	                }
	                else if (e.isSymbolicLink()) {
	                    if (rest && pattern.checkFollowGlobstar()) {
	                        this.subwalks.add(e, rest);
	                    }
	                    else if (pattern.markFollowGlobstar()) {
	                        this.subwalks.add(e, pattern);
	                    }
	                }
	            }
	        }
	        // if the NEXT thing matches this entry, then also add
	        // the rest.
	        if (rest) {
	            const rp = rest.pattern();
	            if (typeof rp === 'string' &&
	                // dots and empty were handled already
	                rp !== '..' &&
	                rp !== '' &&
	                rp !== '.') {
	                this.testString(e, rp, rest.rest(), absolute);
	            }
	            else if (rp === '..') {
	                /* c8 ignore start */
	                const ep = e.parent || e;
	                /* c8 ignore stop */
	                this.subwalks.add(ep, rest);
	            }
	            else if (rp instanceof RegExp) {
	                this.testRegExp(e, rp, rest.rest(), absolute);
	            }
	        }
	    }
	    testRegExp(e, p, rest, absolute) {
	        if (!p.test(e.name))
	            return;
	        if (!rest) {
	            this.matches.add(e, absolute, false);
	        }
	        else {
	            this.subwalks.add(e, rest);
	        }
	    }
	    testString(e, p, rest, absolute) {
	        // should never happen?
	        if (!e.isNamed(p))
	            return;
	        if (!rest) {
	            this.matches.add(e, absolute, false);
	        }
	        else {
	            this.subwalks.add(e, rest);
	        }
	    }
	}
	processor.Processor = Processor;
	
	return processor;
}

var hasRequiredWalker;

function requireWalker () {
	if (hasRequiredWalker) return walker;
	hasRequiredWalker = 1;
	Object.defineProperty(walker, "__esModule", { value: true });
	walker.GlobStream = walker.GlobWalker = walker.GlobUtil = void 0;
	/**
	 * Single-use utility classes to provide functionality to the {@link Glob}
	 * methods.
	 *
	 * @module
	 */
	const minipass_1 = requireCommonjs$5();
	const ignore_js_1 = requireIgnore();
	const processor_js_1 = requireProcessor();
	const makeIgnore = (ignore, opts) => typeof ignore === 'string' ? new ignore_js_1.Ignore([ignore], opts)
	    : Array.isArray(ignore) ? new ignore_js_1.Ignore(ignore, opts)
	        : ignore;
	/**
	 * basic walking utilities that all the glob walker types use
	 */
	class GlobUtil {
	    path;
	    patterns;
	    opts;
	    seen = new Set();
	    paused = false;
	    aborted = false;
	    #onResume = [];
	    #ignore;
	    #sep;
	    signal;
	    maxDepth;
	    includeChildMatches;
	    constructor(patterns, path, opts) {
	        this.patterns = patterns;
	        this.path = path;
	        this.opts = opts;
	        this.#sep = !opts.posix && opts.platform === 'win32' ? '\\' : '/';
	        this.includeChildMatches = opts.includeChildMatches !== false;
	        if (opts.ignore || !this.includeChildMatches) {
	            this.#ignore = makeIgnore(opts.ignore ?? [], opts);
	            if (!this.includeChildMatches &&
	                typeof this.#ignore.add !== 'function') {
	                const m = 'cannot ignore child matches, ignore lacks add() method.';
	                throw new Error(m);
	            }
	        }
	        // ignore, always set with maxDepth, but it's optional on the
	        // GlobOptions type
	        /* c8 ignore start */
	        this.maxDepth = opts.maxDepth || Infinity;
	        /* c8 ignore stop */
	        if (opts.signal) {
	            this.signal = opts.signal;
	            this.signal.addEventListener('abort', () => {
	                this.#onResume.length = 0;
	            });
	        }
	    }
	    #ignored(path) {
	        return this.seen.has(path) || !!this.#ignore?.ignored?.(path);
	    }
	    #childrenIgnored(path) {
	        return !!this.#ignore?.childrenIgnored?.(path);
	    }
	    // backpressure mechanism
	    pause() {
	        this.paused = true;
	    }
	    resume() {
	        /* c8 ignore start */
	        if (this.signal?.aborted)
	            return;
	        /* c8 ignore stop */
	        this.paused = false;
	        let fn = undefined;
	        while (!this.paused && (fn = this.#onResume.shift())) {
	            fn();
	        }
	    }
	    onResume(fn) {
	        if (this.signal?.aborted)
	            return;
	        /* c8 ignore start */
	        if (!this.paused) {
	            fn();
	        }
	        else {
	            /* c8 ignore stop */
	            this.#onResume.push(fn);
	        }
	    }
	    // do the requisite realpath/stat checking, and return the path
	    // to add or undefined to filter it out.
	    async matchCheck(e, ifDir) {
	        if (ifDir && this.opts.nodir)
	            return undefined;
	        let rpc;
	        if (this.opts.realpath) {
	            rpc = e.realpathCached() || (await e.realpath());
	            if (!rpc)
	                return undefined;
	            e = rpc;
	        }
	        const needStat = e.isUnknown() || this.opts.stat;
	        const s = needStat ? await e.lstat() : e;
	        if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {
	            const target = await s.realpath();
	            /* c8 ignore start */
	            if (target && (target.isUnknown() || this.opts.stat)) {
	                await target.lstat();
	            }
	            /* c8 ignore stop */
	        }
	        return this.matchCheckTest(s, ifDir);
	    }
	    matchCheckTest(e, ifDir) {
	        return (e &&
	            (this.maxDepth === Infinity || e.depth() <= this.maxDepth) &&
	            (!ifDir || e.canReaddir()) &&
	            (!this.opts.nodir || !e.isDirectory()) &&
	            (!this.opts.nodir ||
	                !this.opts.follow ||
	                !e.isSymbolicLink() ||
	                !e.realpathCached()?.isDirectory()) &&
	            !this.#ignored(e)) ?
	            e
	            : undefined;
	    }
	    matchCheckSync(e, ifDir) {
	        if (ifDir && this.opts.nodir)
	            return undefined;
	        let rpc;
	        if (this.opts.realpath) {
	            rpc = e.realpathCached() || e.realpathSync();
	            if (!rpc)
	                return undefined;
	            e = rpc;
	        }
	        const needStat = e.isUnknown() || this.opts.stat;
	        const s = needStat ? e.lstatSync() : e;
	        if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {
	            const target = s.realpathSync();
	            if (target && (target?.isUnknown() || this.opts.stat)) {
	                target.lstatSync();
	            }
	        }
	        return this.matchCheckTest(s, ifDir);
	    }
	    matchFinish(e, absolute) {
	        if (this.#ignored(e))
	            return;
	        // we know we have an ignore if this is false, but TS doesn't
	        if (!this.includeChildMatches && this.#ignore?.add) {
	            const ign = `${e.relativePosix()}/**`;
	            this.#ignore.add(ign);
	        }
	        const abs = this.opts.absolute === undefined ? absolute : this.opts.absolute;
	        this.seen.add(e);
	        const mark = this.opts.mark && e.isDirectory() ? this.#sep : '';
	        // ok, we have what we need!
	        if (this.opts.withFileTypes) {
	            this.matchEmit(e);
	        }
	        else if (abs) {
	            const abs = this.opts.posix ? e.fullpathPosix() : e.fullpath();
	            this.matchEmit(abs + mark);
	        }
	        else {
	            const rel = this.opts.posix ? e.relativePosix() : e.relative();
	            const pre = this.opts.dotRelative && !rel.startsWith('..' + this.#sep) ?
	                '.' + this.#sep
	                : '';
	            this.matchEmit(!rel ? '.' + mark : pre + rel + mark);
	        }
	    }
	    async match(e, absolute, ifDir) {
	        const p = await this.matchCheck(e, ifDir);
	        if (p)
	            this.matchFinish(p, absolute);
	    }
	    matchSync(e, absolute, ifDir) {
	        const p = this.matchCheckSync(e, ifDir);
	        if (p)
	            this.matchFinish(p, absolute);
	    }
	    walkCB(target, patterns, cb) {
	        /* c8 ignore start */
	        if (this.signal?.aborted)
	            cb();
	        /* c8 ignore stop */
	        this.walkCB2(target, patterns, new processor_js_1.Processor(this.opts), cb);
	    }
	    walkCB2(target, patterns, processor, cb) {
	        if (this.#childrenIgnored(target))
	            return cb();
	        if (this.signal?.aborted)
	            cb();
	        if (this.paused) {
	            this.onResume(() => this.walkCB2(target, patterns, processor, cb));
	            return;
	        }
	        processor.processPatterns(target, patterns);
	        // done processing.  all of the above is sync, can be abstracted out.
	        // subwalks is a map of paths to the entry filters they need
	        // matches is a map of paths to [absolute, ifDir] tuples.
	        let tasks = 1;
	        const next = () => {
	            if (--tasks === 0)
	                cb();
	        };
	        for (const [m, absolute, ifDir] of processor.matches.entries()) {
	            if (this.#ignored(m))
	                continue;
	            tasks++;
	            this.match(m, absolute, ifDir).then(() => next());
	        }
	        for (const t of processor.subwalkTargets()) {
	            if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {
	                continue;
	            }
	            tasks++;
	            const childrenCached = t.readdirCached();
	            if (t.calledReaddir())
	                this.walkCB3(t, childrenCached, processor, next);
	            else {
	                t.readdirCB((_, entries) => this.walkCB3(t, entries, processor, next), true);
	            }
	        }
	        next();
	    }
	    walkCB3(target, entries, processor, cb) {
	        processor = processor.filterEntries(target, entries);
	        let tasks = 1;
	        const next = () => {
	            if (--tasks === 0)
	                cb();
	        };
	        for (const [m, absolute, ifDir] of processor.matches.entries()) {
	            if (this.#ignored(m))
	                continue;
	            tasks++;
	            this.match(m, absolute, ifDir).then(() => next());
	        }
	        for (const [target, patterns] of processor.subwalks.entries()) {
	            tasks++;
	            this.walkCB2(target, patterns, processor.child(), next);
	        }
	        next();
	    }
	    walkCBSync(target, patterns, cb) {
	        /* c8 ignore start */
	        if (this.signal?.aborted)
	            cb();
	        /* c8 ignore stop */
	        this.walkCB2Sync(target, patterns, new processor_js_1.Processor(this.opts), cb);
	    }
	    walkCB2Sync(target, patterns, processor, cb) {
	        if (this.#childrenIgnored(target))
	            return cb();
	        if (this.signal?.aborted)
	            cb();
	        if (this.paused) {
	            this.onResume(() => this.walkCB2Sync(target, patterns, processor, cb));
	            return;
	        }
	        processor.processPatterns(target, patterns);
	        // done processing.  all of the above is sync, can be abstracted out.
	        // subwalks is a map of paths to the entry filters they need
	        // matches is a map of paths to [absolute, ifDir] tuples.
	        let tasks = 1;
	        const next = () => {
	            if (--tasks === 0)
	                cb();
	        };
	        for (const [m, absolute, ifDir] of processor.matches.entries()) {
	            if (this.#ignored(m))
	                continue;
	            this.matchSync(m, absolute, ifDir);
	        }
	        for (const t of processor.subwalkTargets()) {
	            if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {
	                continue;
	            }
	            tasks++;
	            const children = t.readdirSync();
	            this.walkCB3Sync(t, children, processor, next);
	        }
	        next();
	    }
	    walkCB3Sync(target, entries, processor, cb) {
	        processor = processor.filterEntries(target, entries);
	        let tasks = 1;
	        const next = () => {
	            if (--tasks === 0)
	                cb();
	        };
	        for (const [m, absolute, ifDir] of processor.matches.entries()) {
	            if (this.#ignored(m))
	                continue;
	            this.matchSync(m, absolute, ifDir);
	        }
	        for (const [target, patterns] of processor.subwalks.entries()) {
	            tasks++;
	            this.walkCB2Sync(target, patterns, processor.child(), next);
	        }
	        next();
	    }
	}
	walker.GlobUtil = GlobUtil;
	class GlobWalker extends GlobUtil {
	    matches = new Set();
	    constructor(patterns, path, opts) {
	        super(patterns, path, opts);
	    }
	    matchEmit(e) {
	        this.matches.add(e);
	    }
	    async walk() {
	        if (this.signal?.aborted)
	            throw this.signal.reason;
	        if (this.path.isUnknown()) {
	            await this.path.lstat();
	        }
	        await new Promise((res, rej) => {
	            this.walkCB(this.path, this.patterns, () => {
	                if (this.signal?.aborted) {
	                    rej(this.signal.reason);
	                }
	                else {
	                    res(this.matches);
	                }
	            });
	        });
	        return this.matches;
	    }
	    walkSync() {
	        if (this.signal?.aborted)
	            throw this.signal.reason;
	        if (this.path.isUnknown()) {
	            this.path.lstatSync();
	        }
	        // nothing for the callback to do, because this never pauses
	        this.walkCBSync(this.path, this.patterns, () => {
	            if (this.signal?.aborted)
	                throw this.signal.reason;
	        });
	        return this.matches;
	    }
	}
	walker.GlobWalker = GlobWalker;
	class GlobStream extends GlobUtil {
	    results;
	    constructor(patterns, path, opts) {
	        super(patterns, path, opts);
	        this.results = new minipass_1.Minipass({
	            signal: this.signal,
	            objectMode: true,
	        });
	        this.results.on('drain', () => this.resume());
	        this.results.on('resume', () => this.resume());
	    }
	    matchEmit(e) {
	        this.results.write(e);
	        if (!this.results.flowing)
	            this.pause();
	    }
	    stream() {
	        const target = this.path;
	        if (target.isUnknown()) {
	            target.lstat().then(() => {
	                this.walkCB(target, this.patterns, () => this.results.end());
	            });
	        }
	        else {
	            this.walkCB(target, this.patterns, () => this.results.end());
	        }
	        return this.results;
	    }
	    streamSync() {
	        if (this.path.isUnknown()) {
	            this.path.lstatSync();
	        }
	        this.walkCBSync(this.path, this.patterns, () => this.results.end());
	        return this.results;
	    }
	}
	walker.GlobStream = GlobStream;
	
	return walker;
}

var hasRequiredGlob;

function requireGlob () {
	if (hasRequiredGlob) return glob;
	hasRequiredGlob = 1;
	Object.defineProperty(glob, "__esModule", { value: true });
	glob.Glob = void 0;
	const minimatch_1 = requireCommonjs$2();
	const node_url_1 = require$$0$2;
	const path_scurry_1 = requireCommonjs$1();
	const pattern_js_1 = requirePattern();
	const walker_js_1 = requireWalker();
	// if no process global, just call it linux.
	// so we default to case-sensitive, / separators
	const defaultPlatform = (typeof process === 'object' &&
	    process &&
	    typeof process.platform === 'string') ?
	    process.platform
	    : 'linux';
	/**
	 * An object that can perform glob pattern traversals.
	 */
	class Glob {
	    absolute;
	    cwd;
	    root;
	    dot;
	    dotRelative;
	    follow;
	    ignore;
	    magicalBraces;
	    mark;
	    matchBase;
	    maxDepth;
	    nobrace;
	    nocase;
	    nodir;
	    noext;
	    noglobstar;
	    pattern;
	    platform;
	    realpath;
	    scurry;
	    stat;
	    signal;
	    windowsPathsNoEscape;
	    withFileTypes;
	    includeChildMatches;
	    /**
	     * The options provided to the constructor.
	     */
	    opts;
	    /**
	     * An array of parsed immutable {@link Pattern} objects.
	     */
	    patterns;
	    /**
	     * All options are stored as properties on the `Glob` object.
	     *
	     * See {@link GlobOptions} for full options descriptions.
	     *
	     * Note that a previous `Glob` object can be passed as the
	     * `GlobOptions` to another `Glob` instantiation to re-use settings
	     * and caches with a new pattern.
	     *
	     * Traversal functions can be called multiple times to run the walk
	     * again.
	     */
	    constructor(pattern, opts) {
	        /* c8 ignore start */
	        if (!opts)
	            throw new TypeError('glob options required');
	        /* c8 ignore stop */
	        this.withFileTypes = !!opts.withFileTypes;
	        this.signal = opts.signal;
	        this.follow = !!opts.follow;
	        this.dot = !!opts.dot;
	        this.dotRelative = !!opts.dotRelative;
	        this.nodir = !!opts.nodir;
	        this.mark = !!opts.mark;
	        if (!opts.cwd) {
	            this.cwd = '';
	        }
	        else if (opts.cwd instanceof URL || opts.cwd.startsWith('file://')) {
	            opts.cwd = (0, node_url_1.fileURLToPath)(opts.cwd);
	        }
	        this.cwd = opts.cwd || '';
	        this.root = opts.root;
	        this.magicalBraces = !!opts.magicalBraces;
	        this.nobrace = !!opts.nobrace;
	        this.noext = !!opts.noext;
	        this.realpath = !!opts.realpath;
	        this.absolute = opts.absolute;
	        this.includeChildMatches = opts.includeChildMatches !== false;
	        this.noglobstar = !!opts.noglobstar;
	        this.matchBase = !!opts.matchBase;
	        this.maxDepth =
	            typeof opts.maxDepth === 'number' ? opts.maxDepth : Infinity;
	        this.stat = !!opts.stat;
	        this.ignore = opts.ignore;
	        if (this.withFileTypes && this.absolute !== undefined) {
	            throw new Error('cannot set absolute and withFileTypes:true');
	        }
	        if (typeof pattern === 'string') {
	            pattern = [pattern];
	        }
	        this.windowsPathsNoEscape =
	            !!opts.windowsPathsNoEscape ||
	                opts.allowWindowsEscape ===
	                    false;
	        if (this.windowsPathsNoEscape) {
	            pattern = pattern.map(p => p.replace(/\\/g, '/'));
	        }
	        if (this.matchBase) {
	            if (opts.noglobstar) {
	                throw new TypeError('base matching requires globstar');
	            }
	            pattern = pattern.map(p => (p.includes('/') ? p : `./**/${p}`));
	        }
	        this.pattern = pattern;
	        this.platform = opts.platform || defaultPlatform;
	        this.opts = { ...opts, platform: this.platform };
	        if (opts.scurry) {
	            this.scurry = opts.scurry;
	            if (opts.nocase !== undefined &&
	                opts.nocase !== opts.scurry.nocase) {
	                throw new Error('nocase option contradicts provided scurry option');
	            }
	        }
	        else {
	            const Scurry = opts.platform === 'win32' ? path_scurry_1.PathScurryWin32
	                : opts.platform === 'darwin' ? path_scurry_1.PathScurryDarwin
	                    : opts.platform ? path_scurry_1.PathScurryPosix
	                        : path_scurry_1.PathScurry;
	            this.scurry = new Scurry(this.cwd, {
	                nocase: opts.nocase,
	                fs: opts.fs,
	            });
	        }
	        this.nocase = this.scurry.nocase;
	        // If you do nocase:true on a case-sensitive file system, then
	        // we need to use regexps instead of strings for non-magic
	        // path portions, because statting `aBc` won't return results
	        // for the file `AbC` for example.
	        const nocaseMagicOnly = this.platform === 'darwin' || this.platform === 'win32';
	        const mmo = {
	            // default nocase based on platform
	            ...opts,
	            dot: this.dot,
	            matchBase: this.matchBase,
	            nobrace: this.nobrace,
	            nocase: this.nocase,
	            nocaseMagicOnly,
	            nocomment: true,
	            noext: this.noext,
	            nonegate: true,
	            optimizationLevel: 2,
	            platform: this.platform,
	            windowsPathsNoEscape: this.windowsPathsNoEscape,
	            debug: !!this.opts.debug,
	        };
	        const mms = this.pattern.map(p => new minimatch_1.Minimatch(p, mmo));
	        const [matchSet, globParts] = mms.reduce((set, m) => {
	            set[0].push(...m.set);
	            set[1].push(...m.globParts);
	            return set;
	        }, [[], []]);
	        this.patterns = matchSet.map((set, i) => {
	            const g = globParts[i];
	            /* c8 ignore start */
	            if (!g)
	                throw new Error('invalid pattern object');
	            /* c8 ignore stop */
	            return new pattern_js_1.Pattern(set, g, 0, this.platform);
	        });
	    }
	    async walk() {
	        // Walkers always return array of Path objects, so we just have to
	        // coerce them into the right shape.  It will have already called
	        // realpath() if the option was set to do so, so we know that's cached.
	        // start out knowing the cwd, at least
	        return [
	            ...(await new walker_js_1.GlobWalker(this.patterns, this.scurry.cwd, {
	                ...this.opts,
	                maxDepth: this.maxDepth !== Infinity ?
	                    this.maxDepth + this.scurry.cwd.depth()
	                    : Infinity,
	                platform: this.platform,
	                nocase: this.nocase,
	                includeChildMatches: this.includeChildMatches,
	            }).walk()),
	        ];
	    }
	    walkSync() {
	        return [
	            ...new walker_js_1.GlobWalker(this.patterns, this.scurry.cwd, {
	                ...this.opts,
	                maxDepth: this.maxDepth !== Infinity ?
	                    this.maxDepth + this.scurry.cwd.depth()
	                    : Infinity,
	                platform: this.platform,
	                nocase: this.nocase,
	                includeChildMatches: this.includeChildMatches,
	            }).walkSync(),
	        ];
	    }
	    stream() {
	        return new walker_js_1.GlobStream(this.patterns, this.scurry.cwd, {
	            ...this.opts,
	            maxDepth: this.maxDepth !== Infinity ?
	                this.maxDepth + this.scurry.cwd.depth()
	                : Infinity,
	            platform: this.platform,
	            nocase: this.nocase,
	            includeChildMatches: this.includeChildMatches,
	        }).stream();
	    }
	    streamSync() {
	        return new walker_js_1.GlobStream(this.patterns, this.scurry.cwd, {
	            ...this.opts,
	            maxDepth: this.maxDepth !== Infinity ?
	                this.maxDepth + this.scurry.cwd.depth()
	                : Infinity,
	            platform: this.platform,
	            nocase: this.nocase,
	            includeChildMatches: this.includeChildMatches,
	        }).streamSync();
	    }
	    /**
	     * Default sync iteration function. Returns a Generator that
	     * iterates over the results.
	     */
	    iterateSync() {
	        return this.streamSync()[Symbol.iterator]();
	    }
	    [Symbol.iterator]() {
	        return this.iterateSync();
	    }
	    /**
	     * Default async iteration function. Returns an AsyncGenerator that
	     * iterates over the results.
	     */
	    iterate() {
	        return this.stream()[Symbol.asyncIterator]();
	    }
	    [Symbol.asyncIterator]() {
	        return this.iterate();
	    }
	}
	glob.Glob = Glob;
	
	return glob;
}

var hasMagic = {};

var hasRequiredHasMagic;

function requireHasMagic () {
	if (hasRequiredHasMagic) return hasMagic;
	hasRequiredHasMagic = 1;
	Object.defineProperty(hasMagic, "__esModule", { value: true });
	hasMagic.hasMagic = void 0;
	const minimatch_1 = requireCommonjs$2();
	/**
	 * Return true if the patterns provided contain any magic glob characters,
	 * given the options provided.
	 *
	 * Brace expansion is not considered "magic" unless the `magicalBraces` option
	 * is set, as brace expansion just turns one string into an array of strings.
	 * So a pattern like `'x{a,b}y'` would return `false`, because `'xay'` and
	 * `'xby'` both do not contain any magic glob characters, and it's treated the
	 * same as if you had called it on `['xay', 'xby']`. When `magicalBraces:true`
	 * is in the options, brace expansion _is_ treated as a pattern having magic.
	 */
	const hasMagic$1 = (pattern, options = {}) => {
	    if (!Array.isArray(pattern)) {
	        pattern = [pattern];
	    }
	    for (const p of pattern) {
	        if (new minimatch_1.Minimatch(p, options).hasMagic())
	            return true;
	    }
	    return false;
	};
	hasMagic.hasMagic = hasMagic$1;
	
	return hasMagic;
}

var hasRequiredCommonjs;

function requireCommonjs () {
	if (hasRequiredCommonjs) return commonjs$2;
	hasRequiredCommonjs = 1;
	(function (exports) {
		Object.defineProperty(exports, "__esModule", { value: true });
		exports.glob = exports.sync = exports.iterate = exports.iterateSync = exports.stream = exports.streamSync = exports.Ignore = exports.hasMagic = exports.Glob = exports.unescape = exports.escape = void 0;
		exports.globStreamSync = globStreamSync;
		exports.globStream = globStream;
		exports.globSync = globSync;
		exports.globIterateSync = globIterateSync;
		exports.globIterate = globIterate;
		const minimatch_1 = requireCommonjs$2();
		const glob_js_1 = requireGlob();
		const has_magic_js_1 = requireHasMagic();
		var minimatch_2 = requireCommonjs$2();
		Object.defineProperty(exports, "escape", { enumerable: true, get: function () { return minimatch_2.escape; } });
		Object.defineProperty(exports, "unescape", { enumerable: true, get: function () { return minimatch_2.unescape; } });
		var glob_js_2 = requireGlob();
		Object.defineProperty(exports, "Glob", { enumerable: true, get: function () { return glob_js_2.Glob; } });
		var has_magic_js_2 = requireHasMagic();
		Object.defineProperty(exports, "hasMagic", { enumerable: true, get: function () { return has_magic_js_2.hasMagic; } });
		var ignore_js_1 = requireIgnore();
		Object.defineProperty(exports, "Ignore", { enumerable: true, get: function () { return ignore_js_1.Ignore; } });
		function globStreamSync(pattern, options = {}) {
		    return new glob_js_1.Glob(pattern, options).streamSync();
		}
		function globStream(pattern, options = {}) {
		    return new glob_js_1.Glob(pattern, options).stream();
		}
		function globSync(pattern, options = {}) {
		    return new glob_js_1.Glob(pattern, options).walkSync();
		}
		async function glob_(pattern, options = {}) {
		    return new glob_js_1.Glob(pattern, options).walk();
		}
		function globIterateSync(pattern, options = {}) {
		    return new glob_js_1.Glob(pattern, options).iterateSync();
		}
		function globIterate(pattern, options = {}) {
		    return new glob_js_1.Glob(pattern, options).iterate();
		}
		// aliases: glob.sync.stream() glob.stream.sync() glob.sync() etc
		exports.streamSync = globStreamSync;
		exports.stream = Object.assign(globStream, { sync: globStreamSync });
		exports.iterateSync = globIterateSync;
		exports.iterate = Object.assign(globIterate, {
		    sync: globIterateSync,
		});
		exports.sync = Object.assign(globSync, {
		    stream: globStreamSync,
		    iterate: globIterateSync,
		});
		exports.glob = Object.assign(glob_, {
		    glob: glob_,
		    globSync,
		    sync: exports.sync,
		    globStream,
		    stream: exports.stream,
		    globStreamSync,
		    streamSync: exports.streamSync,
		    globIterate,
		    iterate: exports.iterate,
		    globIterateSync,
		    iterateSync: exports.iterateSync,
		    Glob: glob_js_1.Glob,
		    hasMagic: has_magic_js_1.hasMagic,
		    escape: minimatch_1.escape,
		    unescape: minimatch_1.unescape,
		});
		exports.glob.glob = exports.glob;
		
	} (commonjs$2));
	return commonjs$2;
}

var cjs = {};

var posix = {};

var hasRequiredPosix;

function requirePosix () {
	if (hasRequiredPosix) return posix;
	hasRequiredPosix = 1;
	/**
	 * This is the Posix implementation of isexe, which uses the file
	 * mode and uid/gid values.
	 *
	 * @module
	 */
	Object.defineProperty(posix, "__esModule", { value: true });
	posix.sync = posix.isexe = void 0;
	const fs_1 = require$$0$3;
	const promises_1 = require$$0$4;
	/**
	 * Determine whether a path is executable according to the mode and
	 * current (or specified) user and group IDs.
	 */
	const isexe = async (path, options = {}) => {
	    const { ignoreErrors = false } = options;
	    try {
	        return checkStat(await (0, promises_1.stat)(path), options);
	    }
	    catch (e) {
	        const er = e;
	        if (ignoreErrors || er.code === 'EACCES')
	            return false;
	        throw er;
	    }
	};
	posix.isexe = isexe;
	/**
	 * Synchronously determine whether a path is executable according to
	 * the mode and current (or specified) user and group IDs.
	 */
	const sync = (path, options = {}) => {
	    const { ignoreErrors = false } = options;
	    try {
	        return checkStat((0, fs_1.statSync)(path), options);
	    }
	    catch (e) {
	        const er = e;
	        if (ignoreErrors || er.code === 'EACCES')
	            return false;
	        throw er;
	    }
	};
	posix.sync = sync;
	const checkStat = (stat, options) => stat.isFile() && checkMode(stat, options);
	const checkMode = (stat, options) => {
	    const myUid = options.uid ?? process.getuid?.();
	    const myGroups = options.groups ?? process.getgroups?.() ?? [];
	    const myGid = options.gid ?? process.getgid?.() ?? myGroups[0];
	    if (myUid === undefined || myGid === undefined) {
	        throw new Error('cannot get uid or gid');
	    }
	    const groups = new Set([myGid, ...myGroups]);
	    const mod = stat.mode;
	    const uid = stat.uid;
	    const gid = stat.gid;
	    const u = parseInt('100', 8);
	    const g = parseInt('010', 8);
	    const o = parseInt('001', 8);
	    const ug = u | g;
	    return !!(mod & o ||
	        (mod & g && groups.has(gid)) ||
	        (mod & u && uid === myUid) ||
	        (mod & ug && myUid === 0));
	};
	
	return posix;
}

var win32 = {};

var hasRequiredWin32;

function requireWin32 () {
	if (hasRequiredWin32) return win32;
	hasRequiredWin32 = 1;
	/**
	 * This is the Windows implementation of isexe, which uses the file
	 * extension and PATHEXT setting.
	 *
	 * @module
	 */
	Object.defineProperty(win32, "__esModule", { value: true });
	win32.sync = win32.isexe = void 0;
	const fs_1 = require$$0$3;
	const promises_1 = require$$0$4;
	/**
	 * Determine whether a path is executable based on the file extension
	 * and PATHEXT environment variable (or specified pathExt option)
	 */
	const isexe = async (path, options = {}) => {
	    const { ignoreErrors = false } = options;
	    try {
	        return checkStat(await (0, promises_1.stat)(path), path, options);
	    }
	    catch (e) {
	        const er = e;
	        if (ignoreErrors || er.code === 'EACCES')
	            return false;
	        throw er;
	    }
	};
	win32.isexe = isexe;
	/**
	 * Synchronously determine whether a path is executable based on the file
	 * extension and PATHEXT environment variable (or specified pathExt option)
	 */
	const sync = (path, options = {}) => {
	    const { ignoreErrors = false } = options;
	    try {
	        return checkStat((0, fs_1.statSync)(path), path, options);
	    }
	    catch (e) {
	        const er = e;
	        if (ignoreErrors || er.code === 'EACCES')
	            return false;
	        throw er;
	    }
	};
	win32.sync = sync;
	const checkPathExt = (path, options) => {
	    const { pathExt = process.env.PATHEXT || '' } = options;
	    const peSplit = pathExt.split(';');
	    if (peSplit.indexOf('') !== -1) {
	        return true;
	    }
	    for (let i = 0; i < peSplit.length; i++) {
	        const p = peSplit[i].toLowerCase();
	        const ext = path.substring(path.length - p.length).toLowerCase();
	        if (p && ext === p) {
	            return true;
	        }
	    }
	    return false;
	};
	const checkStat = (stat, path, options) => stat.isFile() && checkPathExt(path, options);
	
	return win32;
}

var options = {};

var hasRequiredOptions;

function requireOptions () {
	if (hasRequiredOptions) return options;
	hasRequiredOptions = 1;
	Object.defineProperty(options, "__esModule", { value: true });
	
	return options;
}

var hasRequiredCjs;

function requireCjs () {
	if (hasRequiredCjs) return cjs;
	hasRequiredCjs = 1;
	(function (exports) {
		var __createBinding = (cjs && cjs.__createBinding) || (Object.create ? (function(o, m, k, k2) {
		    if (k2 === undefined) k2 = k;
		    var desc = Object.getOwnPropertyDescriptor(m, k);
		    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
		      desc = { enumerable: true, get: function() { return m[k]; } };
		    }
		    Object.defineProperty(o, k2, desc);
		}) : (function(o, m, k, k2) {
		    if (k2 === undefined) k2 = k;
		    o[k2] = m[k];
		}));
		var __setModuleDefault = (cjs && cjs.__setModuleDefault) || (Object.create ? (function(o, v) {
		    Object.defineProperty(o, "default", { enumerable: true, value: v });
		}) : function(o, v) {
		    o["default"] = v;
		});
		var __importStar = (cjs && cjs.__importStar) || function (mod) {
		    if (mod && mod.__esModule) return mod;
		    var result = {};
		    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
		    __setModuleDefault(result, mod);
		    return result;
		};
		var __exportStar = (cjs && cjs.__exportStar) || function(m, exports) {
		    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
		};
		Object.defineProperty(exports, "__esModule", { value: true });
		exports.sync = exports.isexe = exports.posix = exports.win32 = void 0;
		const posix = __importStar(requirePosix());
		exports.posix = posix;
		const win32 = __importStar(requireWin32());
		exports.win32 = win32;
		__exportStar(requireOptions(), exports);
		const platform = process.env._ISEXE_TEST_PLATFORM_ || process.platform;
		const impl = platform === 'win32' ? win32 : posix;
		/**
		 * Determine whether a path is executable on the current platform.
		 */
		exports.isexe = impl.isexe;
		/**
		 * Synchronously determine whether a path is executable on the
		 * current platform.
		 */
		exports.sync = impl.sync;
		
	} (cjs));
	return cjs;
}

var lib$9;
var hasRequiredLib$9;

function requireLib$9 () {
	if (hasRequiredLib$9) return lib$9;
	hasRequiredLib$9 = 1;
	const { isexe, sync: isexeSync } = requireCjs();
	const { join, delimiter, sep, posix } = require$$0;

	const isWindows = process.platform === 'win32';

	// used to check for slashed in commands passed in. always checks for the posix
	// seperator on all platforms, and checks for the current separator when not on
	// a posix platform. don't use the isWindows check for this since that is mocked
	// in tests but we still need the code to actually work when called. that is also
	// why it is ignored from coverage.
	/* istanbul ignore next */
	const rSlash = new RegExp(`[${posix.sep}${sep === posix.sep ? '' : sep}]`.replace(/(\\)/g, '\\$1'));
	const rRel = new RegExp(`^\\.${rSlash.source}`);

	const getNotFoundError = (cmd) =>
	  Object.assign(new Error(`not found: ${cmd}`), { code: 'ENOENT' });

	const getPathInfo = (cmd, {
	  path: optPath = process.env.PATH,
	  pathExt: optPathExt = process.env.PATHEXT,
	  delimiter: optDelimiter = delimiter,
	}) => {
	  // If it has a slash, then we don't bother searching the pathenv.
	  // just check the file itself, and that's it.
	  const pathEnv = cmd.match(rSlash) ? [''] : [
	    // windows always checks the cwd first
	    ...(isWindows ? [process.cwd()] : []),
	    ...(optPath || /* istanbul ignore next: very unusual */ '').split(optDelimiter),
	  ];

	  if (isWindows) {
	    const pathExtExe = optPathExt ||
	      ['.EXE', '.CMD', '.BAT', '.COM'].join(optDelimiter);
	    const pathExt = pathExtExe.split(optDelimiter).flatMap((item) => [item, item.toLowerCase()]);
	    if (cmd.includes('.') && pathExt[0] !== '') {
	      pathExt.unshift('');
	    }
	    return { pathEnv, pathExt, pathExtExe }
	  }

	  return { pathEnv, pathExt: [''] }
	};

	const getPathPart = (raw, cmd) => {
	  const pathPart = /^".*"$/.test(raw) ? raw.slice(1, -1) : raw;
	  const prefix = !pathPart && rRel.test(cmd) ? cmd.slice(0, 2) : '';
	  return prefix + join(pathPart, cmd)
	};

	const which = async (cmd, opt = {}) => {
	  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt);
	  const found = [];

	  for (const envPart of pathEnv) {
	    const p = getPathPart(envPart, cmd);

	    for (const ext of pathExt) {
	      const withExt = p + ext;
	      const is = await isexe(withExt, { pathExt: pathExtExe, ignoreErrors: true });
	      if (is) {
	        if (!opt.all) {
	          return withExt
	        }
	        found.push(withExt);
	      }
	    }
	  }

	  if (opt.all && found.length) {
	    return found
	  }

	  if (opt.nothrow) {
	    return null
	  }

	  throw getNotFoundError(cmd)
	};

	const whichSync = (cmd, opt = {}) => {
	  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt);
	  const found = [];

	  for (const pathEnvPart of pathEnv) {
	    const p = getPathPart(pathEnvPart, cmd);

	    for (const ext of pathExt) {
	      const withExt = p + ext;
	      const is = isexeSync(withExt, { pathExt: pathExtExe, ignoreErrors: true });
	      if (is) {
	        if (!opt.all) {
	          return withExt
	        }
	        found.push(withExt);
	      }
	    }
	  }

	  if (opt.all && found.length) {
	    return found
	  }

	  if (opt.nothrow) {
	    return null
	  }

	  throw getNotFoundError(cmd)
	};

	lib$9 = which;
	which.sync = whichSync;
	return lib$9;
}

var _escape;
var hasRequired_escape;

function require_escape () {
	if (hasRequired_escape) return _escape;
	hasRequired_escape = 1;

	// eslint-disable-next-line max-len
	// this code adapted from: https://blogs.msdn.microsoft.com/twistylittlepassagesallalike/2011/04/23/everyone-quotes-command-line-arguments-the-wrong-way/
	const cmd = (input, doubleEscape) => {
	  if (!input.length) {
	    return '""'
	  }

	  let result;
	  if (!/[ \t\n\v"]/.test(input)) {
	    result = input;
	  } else {
	    result = '"';
	    for (let i = 0; i <= input.length; ++i) {
	      let slashCount = 0;
	      while (input[i] === '\\') {
	        ++i;
	        ++slashCount;
	      }

	      if (i === input.length) {
	        result += '\\'.repeat(slashCount * 2);
	        break
	      }

	      if (input[i] === '"') {
	        result += '\\'.repeat(slashCount * 2 + 1);
	        result += input[i];
	      } else {
	        result += '\\'.repeat(slashCount);
	        result += input[i];
	      }
	    }
	    result += '"';
	  }

	  // and finally, prefix shell meta chars with a ^
	  result = result.replace(/[ !%^&()<>|"]/g, '^$&');
	  if (doubleEscape) {
	    result = result.replace(/[ !%^&()<>|"]/g, '^$&');
	  }

	  return result
	};

	const sh = (input) => {
	  if (!input.length) {
	    return `''`
	  }

	  if (!/[\t\n\r "#$&'()*;<>?\\`|~]/.test(input)) {
	    return input
	  }

	  // replace single quotes with '\'' and wrap the whole result in a fresh set of quotes
	  const result = `'${input.replace(/'/g, `'\\''`)}'`
	    // if the input string already had single quotes around it, clean those up
	    .replace(/^(?:'')+(?!$)/, '')
	    .replace(/\\'''/g, `\\'`);

	  return result
	};

	_escape = {
	  cmd,
	  sh,
	};
	return _escape;
}

var lib$8;
var hasRequiredLib$8;

function requireLib$8 () {
	if (hasRequiredLib$8) return lib$8;
	hasRequiredLib$8 = 1;

	const { spawn } = require$$0$5;
	const os = require$$1$2;
	const which = requireLib$9();

	const escape = require_escape();

	// 'extra' object is for decorating the error a bit more
	const promiseSpawn = (cmd, args, opts = {}, extra = {}) => {
	  if (opts.shell) {
	    return spawnWithShell(cmd, args, opts, extra)
	  }

	  let resolve, reject;
	  const promise = new Promise((_resolve, _reject) => {
	    resolve = _resolve;
	    reject = _reject;
	  });

	  // Create error here so we have a more useful stack trace when rejecting
	  const closeError = new Error('command failed');

	  const stdout = [];
	  const stderr = [];

	  const getResult = (result) => ({
	    cmd,
	    args,
	    ...result,
	    ...stdioResult(stdout, stderr, opts),
	    ...extra,
	  });
	  const rejectWithOpts = (er, erOpts) => {
	    const resultError = getResult(erOpts);
	    reject(Object.assign(er, resultError));
	  };

	  const proc = spawn(cmd, args, opts);
	  promise.stdin = proc.stdin;
	  promise.process = proc;

	  proc.on('error', rejectWithOpts);

	  if (proc.stdout) {
	    proc.stdout.on('data', c => stdout.push(c));
	    proc.stdout.on('error', rejectWithOpts);
	  }

	  if (proc.stderr) {
	    proc.stderr.on('data', c => stderr.push(c));
	    proc.stderr.on('error', rejectWithOpts);
	  }

	  proc.on('close', (code, signal) => {
	    if (code || signal) {
	      rejectWithOpts(closeError, { code, signal });
	    } else {
	      resolve(getResult({ code, signal }));
	    }
	  });

	  return promise
	};

	const spawnWithShell = (cmd, args, opts, extra) => {
	  let command = opts.shell;
	  // if shell is set to true, we use a platform default. we can't let the core
	  // spawn method decide this for us because we need to know what shell is in use
	  // ahead of time so that we can escape arguments properly. we don't need coverage here.
	  if (command === true) {
	    // istanbul ignore next
	    command = process.platform === 'win32' ? process.env.ComSpec : 'sh';
	  }

	  const options = { ...opts, shell: false };
	  const realArgs = [];
	  let script = cmd;

	  // first, determine if we're in windows because if we are we need to know if we're
	  // running an .exe or a .cmd/.bat since the latter requires extra escaping
	  const isCmd = /(?:^|\\)cmd(?:\.exe)?$/i.test(command);
	  if (isCmd) {
	    let doubleEscape = false;

	    // find the actual command we're running
	    let initialCmd = '';
	    let insideQuotes = false;
	    for (let i = 0; i < cmd.length; ++i) {
	      const char = cmd.charAt(i);
	      if (char === ' ' && !insideQuotes) {
	        break
	      }

	      initialCmd += char;
	      if (char === '"' || char === "'") {
	        insideQuotes = !insideQuotes;
	      }
	    }

	    let pathToInitial;
	    try {
	      pathToInitial = which.sync(initialCmd, {
	        path: (options.env && findInObject(options.env, 'PATH')) || process.env.PATH,
	        pathext: (options.env && findInObject(options.env, 'PATHEXT')) || process.env.PATHEXT,
	      }).toLowerCase();
	    } catch (err) {
	      pathToInitial = initialCmd.toLowerCase();
	    }

	    doubleEscape = pathToInitial.endsWith('.cmd') || pathToInitial.endsWith('.bat');
	    for (const arg of args) {
	      script += ` ${escape.cmd(arg, doubleEscape)}`;
	    }
	    realArgs.push('/d', '/s', '/c', script);
	    options.windowsVerbatimArguments = true;
	  } else {
	    for (const arg of args) {
	      script += ` ${escape.sh(arg)}`;
	    }
	    realArgs.push('-c', script);
	  }

	  return promiseSpawn(command, realArgs, options, extra)
	};

	// open a file with the default application as defined by the user's OS
	const open = (_args, opts = {}, extra = {}) => {
	  const options = { ...opts, shell: true };
	  const args = [].concat(_args);

	  let platform = process.platform;
	  // process.platform === 'linux' may actually indicate WSL, if that's the case
	  // open the argument with sensible-browser which is pre-installed
	  // In WSL, set the default browser using, for example,
	  // export BROWSER="/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe"
	  // or
	  // export BROWSER="/mnt/c/Program Files (x86)/Microsoft/Edge/Application/msedge.exe"
	  // To permanently set the default browser, add the appropriate entry to your shell's
	  // RC file, e.g. .bashrc or .zshrc.
	  if (platform === 'linux' && os.release().toLowerCase().includes('microsoft')) {
	    platform = 'wsl';
	    if (!process.env.BROWSER) {
	      return Promise.reject(
	        new Error('Set the BROWSER environment variable to your desired browser.'))
	    }
	  }

	  let command = options.command;
	  if (!command) {
	    if (platform === 'win32') {
	      // spawnWithShell does not do the additional os.release() check, so we
	      // have to force the shell here to make sure we treat WSL as windows.
	      options.shell = process.env.ComSpec;
	      // also, the start command accepts a title so to make sure that we don't
	      // accidentally interpret the first arg as the title, we stick an empty
	      // string immediately after the start command
	      command = 'start ""';
	    } else if (platform === 'wsl') {
	      command = 'sensible-browser';
	    } else if (platform === 'darwin') {
	      command = 'open';
	    } else {
	      command = 'xdg-open';
	    }
	  }

	  return spawnWithShell(command, args, options, extra)
	};
	promiseSpawn.open = open;

	const isPipe = (stdio = 'pipe', fd) => {
	  if (stdio === 'pipe' || stdio === null) {
	    return true
	  }

	  if (Array.isArray(stdio)) {
	    return isPipe(stdio[fd], fd)
	  }

	  return false
	};

	const stdioResult = (stdout, stderr, { stdioString = true, stdio }) => {
	  const result = {
	    stdout: null,
	    stderr: null,
	  };

	  // stdio is [stdin, stdout, stderr]
	  if (isPipe(stdio, 1)) {
	    result.stdout = Buffer.concat(stdout);
	    if (stdioString) {
	      result.stdout = result.stdout.toString().trim();
	    }
	  }

	  if (isPipe(stdio, 2)) {
	    result.stderr = Buffer.concat(stderr);
	    if (stdioString) {
	      result.stderr = result.stderr.toString().trim();
	    }
	  }

	  return result
	};

	// case insensitive lookup in an object
	const findInObject = (obj, key) => {
	  key = key.toLowerCase();
	  for (const objKey of Object.keys(obj).sort()) {
	    if (objKey.toLowerCase() === key) {
	      return obj[objKey]
	    }
	  }
	};

	lib$8 = promiseSpawn;
	return lib$8;
}

var errors;
var hasRequiredErrors;

function requireErrors () {
	if (hasRequiredErrors) return errors;
	hasRequiredErrors = 1;
	const maxRetry = 3;

	class GitError extends Error {
	  shouldRetry () {
	    return false
	  }
	}

	class GitConnectionError extends GitError {
	  constructor () {
	    super('A git connection error occurred');
	  }

	  shouldRetry (number) {
	    return number < maxRetry
	  }
	}

	class GitPathspecError extends GitError {
	  constructor () {
	    super('The git reference could not be found');
	  }
	}

	class GitUnknownError extends GitError {
	  constructor () {
	    super('An unknown git error occurred');
	  }
	}

	errors = {
	  GitConnectionError,
	  GitPathspecError,
	  GitUnknownError,
	};
	return errors;
}

var makeError_1;
var hasRequiredMakeError;

function requireMakeError () {
	if (hasRequiredMakeError) return makeError_1;
	hasRequiredMakeError = 1;
	const {
	  GitConnectionError,
	  GitPathspecError,
	  GitUnknownError,
	} = requireErrors();

	const connectionErrorRe = new RegExp([
	  'remote error: Internal Server Error',
	  'The remote end hung up unexpectedly',
	  'Connection timed out',
	  'Operation timed out',
	  'Failed to connect to .* Timed out',
	  'Connection reset by peer',
	  'SSL_ERROR_SYSCALL',
	  'The requested URL returned error: 503',
	].join('|'));

	const missingPathspecRe = /pathspec .* did not match any file\(s\) known to git/;

	function makeError (er) {
	  const message = er.stderr;
	  let gitEr;
	  if (connectionErrorRe.test(message)) {
	    gitEr = new GitConnectionError(message);
	  } else if (missingPathspecRe.test(message)) {
	    gitEr = new GitPathspecError(message);
	  } else {
	    gitEr = new GitUnknownError(message);
	  }
	  return Object.assign(gitEr, er)
	}

	makeError_1 = makeError;
	return makeError_1;
}

var opts = {exports: {}};

var hasRequiredOpts;

function requireOpts () {
	if (hasRequiredOpts) return opts.exports;
	hasRequiredOpts = 1;
	const fs = require$$4;
	const os = require$$1$3;
	const path = require$$2$2;
	const ini = requireIni();

	const gitConfigPath = path.join(os.homedir(), '.gitconfig');

	let cachedConfig = null;

	// Function to load and cache the git config
	const loadGitConfig = () => {
	  if (cachedConfig === null) {
	    try {
	      cachedConfig = {};
	      if (fs.existsSync(gitConfigPath)) {
	        const configContent = fs.readFileSync(gitConfigPath, 'utf-8');
	        cachedConfig = ini.parse(configContent);
	      }
	    } catch (error) {
	      cachedConfig = {};
	    }
	  }
	  return cachedConfig
	};

	const checkGitConfigs = () => {
	  const config = loadGitConfig();
	  return {
	    sshCommandSetInConfig: config?.core?.sshCommand !== undefined,
	    askPassSetInConfig: config?.core?.askpass !== undefined,
	  }
	};

	const sshCommandSetInEnv = process.env.GIT_SSH_COMMAND !== undefined;
	const askPassSetInEnv = process.env.GIT_ASKPASS !== undefined;
	const { sshCommandSetInConfig, askPassSetInConfig } = checkGitConfigs();

	// Values we want to set if they're not already defined by the end user
	// This defaults to accepting new ssh host key fingerprints
	const finalGitEnv = {
	  ...(askPassSetInEnv || askPassSetInConfig ? {} : {
	    GIT_ASKPASS: 'echo',
	  }),
	  ...(sshCommandSetInEnv || sshCommandSetInConfig ? {} : {
	    GIT_SSH_COMMAND: 'ssh -oStrictHostKeyChecking=accept-new',
	  }),
	};

	opts.exports = (opts = {}) => ({
	  stdioString: true,
	  ...opts,
	  shell: false,
	  env: opts.env || { ...finalGitEnv, ...process.env },
	});

	// Export the loadGitConfig function for testing
	opts.exports.loadGitConfig = loadGitConfig;
	return opts.exports;
}

var which_1;
var hasRequiredWhich;

function requireWhich () {
	if (hasRequiredWhich) return which_1;
	hasRequiredWhich = 1;
	const which = requireLib$9();

	let gitPath;
	try {
	  gitPath = which.sync('git');
	} catch {
	  // ignore errors
	}

	which_1 = (opts = {}) => {
	  if (opts.git) {
	    return opts.git
	  }
	  if (!gitPath || opts.git === false) {
	    return Object.assign(new Error('No git binary found in $PATH'), { code: 'ENOGIT' })
	  }
	  return gitPath
	};
	return which_1;
}

var spawn_1;
var hasRequiredSpawn;

function requireSpawn () {
	if (hasRequiredSpawn) return spawn_1;
	hasRequiredSpawn = 1;
	const spawn = requireLib$8();
	const promiseRetry = requirePromiseRetry();
	const { log } = requireLib$d();
	const makeError = requireMakeError();
	const makeOpts = requireOpts();

	spawn_1 = (gitArgs, opts = {}) => {
	  const whichGit = requireWhich();
	  const gitPath = whichGit(opts);

	  if (gitPath instanceof Error) {
	    return Promise.reject(gitPath)
	  }

	  // undocumented option, mostly only here for tests
	  const args = opts.allowReplace || gitArgs[0] === '--no-replace-objects'
	    ? gitArgs
	    : ['--no-replace-objects', ...gitArgs];

	  let retryOpts = opts.retry;
	  if (retryOpts === null || retryOpts === undefined) {
	    retryOpts = {
	      retries: opts.fetchRetries || 2,
	      factor: opts.fetchRetryFactor || 10,
	      maxTimeout: opts.fetchRetryMaxtimeout || 60000,
	      minTimeout: opts.fetchRetryMintimeout || 1000,
	    };
	  }
	  return promiseRetry((retryFn, number) => {
	    if (number !== 1) {
	      log.silly('git', `Retrying git command: ${
	        args.join(' ')} attempt # ${number}`);
	    }

	    return spawn(gitPath, args, makeOpts(opts))
	      .catch(er => {
	        const gitError = makeError(er);
	        if (!gitError.shouldRetry(number)) {
	          throw gitError
	        }
	        retryFn(gitError);
	      })
	  }, retryOpts)
	};
	return spawn_1;
}

var linesToRevs;
var hasRequiredLinesToRevs;

function requireLinesToRevs () {
	if (hasRequiredLinesToRevs) return linesToRevs;
	hasRequiredLinesToRevs = 1;
	// turn an array of lines from `git ls-remote` into a thing
	// vaguely resembling a packument, where docs are a resolved ref

	const semver = requireSemver();

	linesToRevs = lines => finish(lines.reduce(linesToRevsReducer, {
	  versions: {},
	  'dist-tags': {},
	  refs: {},
	  shas: {},
	}));

	const finish = revs => distTags(shaList(peelTags(revs)));

	// We can check out shallow clones on specific SHAs if we have a ref
	const shaList = revs => {
	  Object.keys(revs.refs).forEach(ref => {
	    const doc = revs.refs[ref];
	    if (!revs.shas[doc.sha]) {
	      revs.shas[doc.sha] = [ref];
	    } else {
	      revs.shas[doc.sha].push(ref);
	    }
	  });
	  return revs
	};

	// Replace any tags with their ^{} counterparts, if those exist
	const peelTags = revs => {
	  Object.keys(revs.refs).filter(ref => ref.endsWith('^{}')).forEach(ref => {
	    const peeled = revs.refs[ref];
	    const unpeeled = revs.refs[ref.replace(/\^\{\}$/, '')];
	    if (unpeeled) {
	      unpeeled.sha = peeled.sha;
	      delete revs.refs[ref];
	    }
	  });
	  return revs
	};

	const distTags = revs => {
	  // not entirely sure what situations would result in an
	  // ichabod repo, but best to be careful in Sleepy Hollow anyway
	  const HEAD = revs.refs.HEAD || /* istanbul ignore next */ {};
	  const versions = Object.keys(revs.versions);
	  versions.forEach(v => {
	    // simulate a dist-tags with latest pointing at the
	    // 'latest' branch if one exists and is a version,
	    // or HEAD if not.
	    const ver = revs.versions[v];
	    if (revs.refs.latest && ver.sha === revs.refs.latest.sha) {
	      revs['dist-tags'].latest = v;
	    } else if (ver.sha === HEAD.sha) {
	      revs['dist-tags'].HEAD = v;
	      if (!revs.refs.latest) {
	        revs['dist-tags'].latest = v;
	      }
	    }
	  });
	  return revs
	};

	const refType = ref => {
	  if (ref.startsWith('refs/tags/')) {
	    return 'tag'
	  }
	  if (ref.startsWith('refs/heads/')) {
	    return 'branch'
	  }
	  if (ref.startsWith('refs/pull/')) {
	    return 'pull'
	  }
	  if (ref === 'HEAD') {
	    return 'head'
	  }
	  // Could be anything, ignore for now
	  /* istanbul ignore next */
	  return 'other'
	};

	// return the doc, or null if we should ignore it.
	const lineToRevDoc = line => {
	  const split = line.trim().split(/\s+/, 2);
	  if (split.length < 2) {
	    return null
	  }

	  const sha = split[0].trim();
	  const rawRef = split[1].trim();
	  const type = refType(rawRef);

	  if (type === 'tag') {
	    // refs/tags/foo^{} is the 'peeled tag', ie the commit
	    // that is tagged by refs/tags/foo they resolve to the same
	    // content, just different objects in git's data structure.
	    // But, we care about the thing the tag POINTS to, not the tag
	    // object itself, so we only look at the peeled tag refs, and
	    // ignore the pointer.
	    // For now, though, we have to save both, because some tags
	    // don't have peels, if they were not annotated.
	    const ref = rawRef.slice('refs/tags/'.length);
	    return { sha, ref, rawRef, type }
	  }

	  if (type === 'branch') {
	    const ref = rawRef.slice('refs/heads/'.length);
	    return { sha, ref, rawRef, type }
	  }

	  if (type === 'pull') {
	    // NB: merged pull requests installable with #pull/123/merge
	    // for the merged pr, or #pull/123 for the PR head
	    const ref = rawRef.slice('refs/'.length).replace(/\/head$/, '');
	    return { sha, ref, rawRef, type }
	  }

	  if (type === 'head') {
	    const ref = 'HEAD';
	    return { sha, ref, rawRef, type }
	  }

	  // at this point, all we can do is leave the ref un-munged
	  return { sha, ref: rawRef, rawRef, type }
	};

	const linesToRevsReducer = (revs, line) => {
	  const doc = lineToRevDoc(line);

	  if (!doc) {
	    return revs
	  }

	  revs.refs[doc.ref] = doc;
	  revs.refs[doc.rawRef] = doc;

	  if (doc.type === 'tag') {
	    // try to pull a semver value out of tags like `release-v1.2.3`
	    // which is a pretty common pattern.
	    const match = !doc.ref.endsWith('^{}') &&
	      doc.ref.match(/v?(\d+\.\d+\.\d+(?:[-+].+)?)$/);
	    if (match && semver.valid(match[1], true)) {
	      revs.versions[semver.clean(match[1], true)] = doc;
	    }
	  }

	  return revs
	};
	return linesToRevs;
}

var revs;
var hasRequiredRevs;

function requireRevs () {
	if (hasRequiredRevs) return revs;
	hasRequiredRevs = 1;
	const spawn = requireSpawn();
	const { LRUCache } = /*@__PURE__*/ requireCommonjs$4();
	const linesToRevs = requireLinesToRevs();

	const revsCache = new LRUCache({
	  max: 100,
	  ttl: 5 * 60 * 1000,
	});

	revs = async (repo, opts = {}) => {
	  if (!opts.noGitRevCache) {
	    const cached = revsCache.get(repo);
	    if (cached) {
	      return cached
	    }
	  }

	  const { stdout } = await spawn(['ls-remote', repo], opts);
	  const revs = linesToRevs(stdout.trim().split('\n'));
	  revsCache.set(repo, revs);
	  return revs
	};
	return revs;
}

var utils = {};

var hasRequiredUtils;

function requireUtils () {
	if (hasRequiredUtils) return utils;
	hasRequiredUtils = 1;
	const isWindows = opts => (opts.fakePlatform || process.platform) === 'win32';

	utils.isWindows = isWindows;
	return utils;
}

var npa = {exports: {}};

var hasRequiredNpa;

function requireNpa () {
	if (hasRequiredNpa) return npa.exports;
	hasRequiredNpa = 1;

	const isWindows = process.platform === 'win32';

	const { URL } = require$$0$2;
	// We need to use path/win32 so that we get consistent results in tests, but this also means we need to manually convert backslashes to forward slashes when generating file: urls with paths.
	const path = isWindows ? require$$1$4 : require$$2$2;
	const { homedir } = require$$1$3;
	const HostedGit = requireLib$a();
	const semver = requireSemver();
	const validatePackageName = requireLib$e();
	const { log } = requireLib$d();

	const hasSlashes = isWindows ? /\\|[/]/ : /[/]/;
	const isURL = /^(?:git[+])?[a-z]+:/i;
	const isGit = /^[^@]+@[^:.]+\.[^:]+:.+$/i;
	const isFileType = /[.](?:tgz|tar.gz|tar)$/i;
	const isPortNumber = /:[0-9]+(\/|$)/i;
	const isWindowsFile = /^(?:[.]|~[/]|[/\\]|[a-zA-Z]:)/;
	const isPosixFile = /^(?:[.]|~[/]|[/]|[a-zA-Z]:)/;
	const defaultRegistry = 'https://registry.npmjs.org';

	function npa$1 (arg, where) {
	  let name;
	  let spec;
	  if (typeof arg === 'object') {
	    if (arg instanceof Result && (!where || where === arg.where)) {
	      return arg
	    } else if (arg.name && arg.rawSpec) {
	      return npa$1.resolve(arg.name, arg.rawSpec, where || arg.where)
	    } else {
	      return npa$1(arg.raw, where || arg.where)
	    }
	  }
	  const nameEndsAt = arg.indexOf('@', 1); // Skip possible leading @
	  const namePart = nameEndsAt > 0 ? arg.slice(0, nameEndsAt) : arg;
	  if (isURL.test(arg)) {
	    spec = arg;
	  } else if (isGit.test(arg)) {
	    spec = `git+ssh://${arg}`;
	  // eslint-disable-next-line max-len
	  } else if (!namePart.startsWith('@') && (hasSlashes.test(namePart) || isFileType.test(namePart))) {
	    spec = arg;
	  } else if (nameEndsAt > 0) {
	    name = namePart;
	    spec = arg.slice(nameEndsAt + 1) || '*';
	  } else {
	    const valid = validatePackageName(arg);
	    if (valid.validForOldPackages) {
	      name = arg;
	      spec = '*';
	    } else {
	      spec = arg;
	    }
	  }
	  return resolve(name, spec, where, arg)
	}

	function isFileSpec (spec) {
	  if (!spec) {
	    return false
	  }
	  if (spec.toLowerCase().startsWith('file:')) {
	    return true
	  }
	  if (isWindows) {
	    return isWindowsFile.test(spec)
	  }
	  // We never hit this in windows tests, obviously
	  /* istanbul ignore next */
	  return isPosixFile.test(spec)
	}

	function isAliasSpec (spec) {
	  if (!spec) {
	    return false
	  }
	  return spec.toLowerCase().startsWith('npm:')
	}

	function resolve (name, spec, where, arg) {
	  const res = new Result({
	    raw: arg,
	    name: name,
	    rawSpec: spec,
	    fromArgument: arg != null,
	  });

	  if (name) {
	    res.name = name;
	  }

	  if (!where) {
	    where = process.cwd();
	  }

	  if (isFileSpec(spec)) {
	    return fromFile(res, where)
	  } else if (isAliasSpec(spec)) {
	    return fromAlias(res, where)
	  }

	  const hosted = HostedGit.fromUrl(spec, {
	    noGitPlus: true,
	    noCommittish: true,
	  });
	  if (hosted) {
	    return fromHostedGit(res, hosted)
	  } else if (spec && isURL.test(spec)) {
	    return fromURL(res)
	  } else if (spec && (hasSlashes.test(spec) || isFileType.test(spec))) {
	    return fromFile(res, where)
	  } else {
	    return fromRegistry(res)
	  }
	}

	function toPurl (arg, reg = defaultRegistry) {
	  const res = npa$1(arg);

	  if (res.type !== 'version') {
	    throw invalidPurlType(res.type, res.raw)
	  }

	  // URI-encode leading @ of scoped packages
	  let purl = 'pkg:npm/' + res.name.replace(/^@/, '%40') + '@' + res.rawSpec;
	  if (reg !== defaultRegistry) {
	    purl += '?repository_url=' + reg;
	  }

	  return purl
	}

	function invalidPackageName (name, valid, raw) {
	  // eslint-disable-next-line max-len
	  const err = new Error(`Invalid package name "${name}" of package "${raw}": ${valid.errors.join('; ')}.`);
	  err.code = 'EINVALIDPACKAGENAME';
	  return err
	}

	function invalidTagName (name, raw) {
	  // eslint-disable-next-line max-len
	  const err = new Error(`Invalid tag name "${name}" of package "${raw}": Tags may not have any characters that encodeURIComponent encodes.`);
	  err.code = 'EINVALIDTAGNAME';
	  return err
	}

	function invalidPurlType (type, raw) {
	  // eslint-disable-next-line max-len
	  const err = new Error(`Invalid type "${type}" of package "${raw}": Purl can only be generated for "version" types.`);
	  err.code = 'EINVALIDPURLTYPE';
	  return err
	}

	class Result {
	  constructor (opts) {
	    this.type = opts.type;
	    this.registry = opts.registry;
	    this.where = opts.where;
	    if (opts.raw == null) {
	      this.raw = opts.name ? `${opts.name}@${opts.rawSpec}` : opts.rawSpec;
	    } else {
	      this.raw = opts.raw;
	    }
	    this.name = undefined;
	    this.escapedName = undefined;
	    this.scope = undefined;
	    this.rawSpec = opts.rawSpec || '';
	    this.saveSpec = opts.saveSpec;
	    this.fetchSpec = opts.fetchSpec;
	    if (opts.name) {
	      this.setName(opts.name);
	    }
	    this.gitRange = opts.gitRange;
	    this.gitCommittish = opts.gitCommittish;
	    this.gitSubdir = opts.gitSubdir;
	    this.hosted = opts.hosted;
	  }

	  // TODO move this to a getter/setter in a semver major
	  setName (name) {
	    const valid = validatePackageName(name);
	    if (!valid.validForOldPackages) {
	      throw invalidPackageName(name, valid, this.raw)
	    }

	    this.name = name;
	    this.scope = name[0] === '@' ? name.slice(0, name.indexOf('/')) : undefined;
	    // scoped packages in couch must have slash url-encoded, e.g. @foo%2Fbar
	    this.escapedName = name.replace('/', '%2f');
	    return this
	  }

	  toString () {
	    const full = [];
	    if (this.name != null && this.name !== '') {
	      full.push(this.name);
	    }
	    const spec = this.saveSpec || this.fetchSpec || this.rawSpec;
	    if (spec != null && spec !== '') {
	      full.push(spec);
	    }
	    return full.length ? full.join('@') : this.raw
	  }

	  toJSON () {
	    const result = Object.assign({}, this);
	    delete result.hosted;
	    return result
	  }
	}

	// sets res.gitCommittish, res.gitRange, and res.gitSubdir
	function setGitAttrs (res, committish) {
	  if (!committish) {
	    res.gitCommittish = null;
	    return
	  }

	  // for each :: separated item:
	  for (const part of committish.split('::')) {
	    // if the item has no : the n it is a commit-ish
	    if (!part.includes(':')) {
	      if (res.gitRange) {
	        throw new Error('cannot override existing semver range with a committish')
	      }
	      if (res.gitCommittish) {
	        throw new Error('cannot override existing committish with a second committish')
	      }
	      res.gitCommittish = part;
	      continue
	    }
	    // split on name:value
	    const [name, value] = part.split(':');
	    // if name is semver do semver lookup of ref or tag
	    if (name === 'semver') {
	      if (res.gitCommittish) {
	        throw new Error('cannot override existing committish with a semver range')
	      }
	      if (res.gitRange) {
	        throw new Error('cannot override existing semver range with a second semver range')
	      }
	      res.gitRange = decodeURIComponent(value);
	      continue
	    }
	    if (name === 'path') {
	      if (res.gitSubdir) {
	        throw new Error('cannot override existing path with a second path')
	      }
	      res.gitSubdir = `/${value}`;
	      continue
	    }
	    log.warn('npm-package-arg', `ignoring unknown key "${name}"`);
	  }
	}

	// Taken from: EncodePathChars and lookup_table in src/node_url.cc
	// url.pathToFileURL only returns absolute references.  We can't use it to encode paths.
	// encodeURI mangles windows paths. We can't use it to encode paths.
	// Under the hood, url.pathToFileURL does a limited set of encoding, with an extra windows step, and then calls path.resolve.
	// The encoding node does without path.resolve is not available outside of the source, so we are recreating it here.
	const encodedPathChars = new Map([
	  ['\0', '%00'],
	  ['\t', '%09'],
	  ['\n', '%0A'],
	  ['\r', '%0D'],
	  [' ', '%20'],
	  ['"', '%22'],
	  ['#', '%23'],
	  ['%', '%25'],
	  ['?', '%3F'],
	  ['[', '%5B'],
	  ['\\', isWindows ? '/' : '%5C'],
	  [']', '%5D'],
	  ['^', '%5E'],
	  ['|', '%7C'],
	  ['~', '%7E'],
	]);

	function pathToFileURL (str) {
	  let result = '';
	  for (let i = 0; i < str.length; i++) {
	    result = `${result}${encodedPathChars.get(str[i]) ?? str[i]}`;
	  }
	  if (result.startsWith('file:')) {
	    return result
	  }
	  return `file:${result}`
	}

	function fromFile (res, where) {
	  res.type = isFileType.test(res.rawSpec) ? 'file' : 'directory';
	  res.where = where;

	  let rawSpec = pathToFileURL(res.rawSpec);

	  if (rawSpec.startsWith('file:/')) {
	    // XXX backwards compatibility lack of compliance with RFC 8089

	    // turn file://path into file:/path
	    if (/^file:\/\/[^/]/.test(rawSpec)) {
	      rawSpec = `file:/${rawSpec.slice(5)}`;
	    }

	    // turn file:/../path into file:../path
	    // for 1 or 3 leading slashes (2 is already ruled out from handling file:// explicitly above)
	    if (/^\/{1,3}\.\.?(\/|$)/.test(rawSpec.slice(5))) {
	      rawSpec = rawSpec.replace(/^file:\/{1,3}/, 'file:');
	    }
	  }

	  let resolvedUrl;
	  let specUrl;
	  try {
	    // always put the '/' on "where", or else file:foo from /path/to/bar goes to /path/to/foo, when we want it to be /path/to/bar/foo
	    resolvedUrl = new URL(rawSpec, `${pathToFileURL(path.resolve(where))}/`);
	    specUrl = new URL(rawSpec);
	  } catch (originalError) {
	    const er = new Error('Invalid file: URL, must comply with RFC 8089');
	    throw Object.assign(er, {
	      raw: res.rawSpec,
	      spec: res,
	      where,
	      originalError,
	    })
	  }

	  // turn /C:/blah into just C:/blah on windows
	  let specPath = decodeURIComponent(specUrl.pathname);
	  let resolvedPath = decodeURIComponent(resolvedUrl.pathname);
	  if (isWindows) {
	    specPath = specPath.replace(/^\/+([a-z]:\/)/i, '$1');
	    resolvedPath = resolvedPath.replace(/^\/+([a-z]:\/)/i, '$1');
	  }

	  // replace ~ with homedir, but keep the ~ in the saveSpec
	  // otherwise, make it relative to where param
	  if (/^\/~(\/|$)/.test(specPath)) {
	    res.saveSpec = `file:${specPath.substr(1)}`;
	    resolvedPath = path.resolve(homedir(), specPath.substr(3));
	  } else if (!path.isAbsolute(rawSpec.slice(5))) {
	    res.saveSpec = `file:${path.relative(where, resolvedPath)}`;
	  } else {
	    res.saveSpec = `file:${path.resolve(resolvedPath)}`;
	  }

	  res.fetchSpec = path.resolve(where, resolvedPath);
	  // re-normalize the slashes in saveSpec due to node:path/win32 behavior in windows
	  res.saveSpec = res.saveSpec.split('\\').join('/');
	  // Ignoring because this only happens in windows
	  /* istanbul ignore next */
	  if (res.saveSpec.startsWith('file://')) {
	    // normalization of \\win32\root paths can cause a double / which we don't want
	    res.saveSpec = `file:/${res.saveSpec.slice(7)}`;
	  }
	  return res
	}

	function fromHostedGit (res, hosted) {
	  res.type = 'git';
	  res.hosted = hosted;
	  res.saveSpec = hosted.toString({ noGitPlus: false, noCommittish: false });
	  res.fetchSpec = hosted.getDefaultRepresentation() === 'shortcut' ? null : hosted.toString();
	  setGitAttrs(res, hosted.committish);
	  return res
	}

	function unsupportedURLType (protocol, spec) {
	  const err = new Error(`Unsupported URL Type "${protocol}": ${spec}`);
	  err.code = 'EUNSUPPORTEDPROTOCOL';
	  return err
	}

	function fromURL (res) {
	  let rawSpec = res.rawSpec;
	  res.saveSpec = rawSpec;
	  if (rawSpec.startsWith('git+ssh:')) {
	    // git ssh specifiers are overloaded to also use scp-style git
	    // specifiers, so we have to parse those out and treat them special.
	    // They are NOT true URIs, so we can't hand them to URL.

	    // This regex looks for things that look like:
	    // git+ssh://git@my.custom.git.com:username/project.git#deadbeef
	    // ...and various combinations. The username in the beginning is *required*.
	    const matched = rawSpec.match(/^git\+ssh:\/\/([^:#]+:[^#]+(?:\.git)?)(?:#(.*))?$/i);
	    // Filter out all-number "usernames" which are really port numbers
	    // They can either be :1234 :1234/ or :1234/path but not :12abc
	    if (matched && !matched[1].match(isPortNumber)) {
	      res.type = 'git';
	      setGitAttrs(res, matched[2]);
	      res.fetchSpec = matched[1];
	      return res
	    }
	  } else if (rawSpec.startsWith('git+file://')) {
	    // URL can't handle windows paths
	    rawSpec = rawSpec.replace(/\\/g, '/');
	  }
	  const parsedUrl = new URL(rawSpec);
	  // check the protocol, and then see if it's git or not
	  switch (parsedUrl.protocol) {
	    case 'git:':
	    case 'git+http:':
	    case 'git+https:':
	    case 'git+rsync:':
	    case 'git+ftp:':
	    case 'git+file:':
	    case 'git+ssh:':
	      res.type = 'git';
	      setGitAttrs(res, parsedUrl.hash.slice(1));
	      if (parsedUrl.protocol === 'git+file:' && /^git\+file:\/\/[a-z]:/i.test(rawSpec)) {
	        // URL can't handle drive letters on windows file paths, the host can't contain a :
	        res.fetchSpec = `git+file://${parsedUrl.host.toLowerCase()}:${parsedUrl.pathname}`;
	      } else {
	        parsedUrl.hash = '';
	        res.fetchSpec = parsedUrl.toString();
	      }
	      if (res.fetchSpec.startsWith('git+')) {
	        res.fetchSpec = res.fetchSpec.slice(4);
	      }
	      break
	    case 'http:':
	    case 'https:':
	      res.type = 'remote';
	      res.fetchSpec = res.saveSpec;
	      break

	    default:
	      throw unsupportedURLType(parsedUrl.protocol, rawSpec)
	  }

	  return res
	}

	function fromAlias (res, where) {
	  const subSpec = npa$1(res.rawSpec.substr(4), where);
	  if (subSpec.type === 'alias') {
	    throw new Error('nested aliases not supported')
	  }

	  if (!subSpec.registry) {
	    throw new Error('aliases only work for registry deps')
	  }

	  if (!subSpec.name) {
	    throw new Error('aliases must have a name')
	  }

	  res.subSpec = subSpec;
	  res.registry = true;
	  res.type = 'alias';
	  res.saveSpec = null;
	  res.fetchSpec = null;
	  return res
	}

	function fromRegistry (res) {
	  res.registry = true;
	  const spec = res.rawSpec.trim();
	  // no save spec for registry components as we save based on the fetched
	  // version, not on the argument so this can't compute that.
	  res.saveSpec = null;
	  res.fetchSpec = spec;
	  const version = semver.valid(spec, true);
	  const range = semver.validRange(spec, true);
	  if (version) {
	    res.type = 'version';
	  } else if (range) {
	    res.type = 'range';
	  } else {
	    if (encodeURIComponent(spec) !== spec) {
	      throw invalidTagName(spec, res.raw)
	    }
	    res.type = 'tag';
	  }
	  return res
	}

	npa.exports = npa$1;
	npa.exports.resolve = resolve;
	npa.exports.toPurl = toPurl;
	npa.exports.Result = Result;
	return npa.exports;
}

var currentEnv;
var hasRequiredCurrentEnv;

function requireCurrentEnv () {
	if (hasRequiredCurrentEnv) return currentEnv;
	hasRequiredCurrentEnv = 1;
	const process = process$1;
	const nodeOs = require$$1$3;
	const fs = require$$4;

	function isMusl (file) {
	  return file.includes('libc.musl-') || file.includes('ld-musl-')
	}

	function os () {
	  return process.platform
	}

	function cpu () {
	  return process.arch
	}

	const LDD_PATH = '/usr/bin/ldd';
	function getFamilyFromFilesystem () {
	  try {
	    const content = fs.readFileSync(LDD_PATH, 'utf-8');
	    if (content.includes('musl')) {
	      return 'musl'
	    }
	    if (content.includes('GNU C Library')) {
	      return 'glibc'
	    }
	    return null
	  } catch {
	    return undefined
	  }
	}

	function getFamilyFromReport () {
	  const originalExclude = process.report.excludeNetwork;
	  process.report.excludeNetwork = true;
	  const report = process.report.getReport();
	  process.report.excludeNetwork = originalExclude;
	  if (report.header?.glibcVersionRuntime) {
	    family = 'glibc';
	  } else if (Array.isArray(report.sharedObjects) && report.sharedObjects.some(isMusl)) {
	    family = 'musl';
	  } else {
	    family = null;
	  }
	  return family
	}

	let family;
	function libc (osName) {
	  if (osName !== 'linux') {
	    return undefined
	  }
	  if (family === undefined) {
	    family = getFamilyFromFilesystem();
	    if (family === undefined) {
	      family = getFamilyFromReport();
	    }
	  }
	  return family
	}

	function devEngines (env = {}) {
	  const osName = env.os || os();
	  return {
	    cpu: {
	      name: env.cpu || cpu(),
	    },
	    libc: {
	      name: env.libc || libc(osName),
	    },
	    os: {
	      name: osName,
	      version: env.osVersion || nodeOs.release(),
	    },
	    packageManager: {
	      name: 'npm',
	      version: env.npmVersion,
	    },
	    runtime: {
	      name: 'node',
	      version: env.nodeVersion || process.version,
	    },
	  }
	}

	currentEnv = {
	  cpu,
	  libc,
	  os,
	  devEngines,
	};
	return currentEnv;
}

var devEngines;
var hasRequiredDevEngines;

function requireDevEngines () {
	if (hasRequiredDevEngines) return devEngines;
	hasRequiredDevEngines = 1;
	const satisfies = requireSatisfies();
	const validRange = requireValid$1();

	const recognizedOnFail = [
	  'ignore',
	  'warn',
	  'error',
	  'download',
	];

	const recognizedProperties = [
	  'name',
	  'version',
	  'onFail',
	];

	const recognizedEngines = [
	  'packageManager',
	  'runtime',
	  'cpu',
	  'libc',
	  'os',
	];

	/** checks a devEngine dependency */
	function checkDependency (wanted, current, opts) {
	  const { engine } = opts;

	  if ((typeof wanted !== 'object' || wanted === null) || Array.isArray(wanted)) {
	    throw new Error(`Invalid non-object value for "${engine}"`)
	  }

	  const properties = Object.keys(wanted);

	  for (const prop of properties) {
	    if (!recognizedProperties.includes(prop)) {
	      throw new Error(`Invalid property "${prop}" for "${engine}"`)
	    }
	  }

	  if (!properties.includes('name')) {
	    throw new Error(`Missing "name" property for "${engine}"`)
	  }

	  if (typeof wanted.name !== 'string') {
	    throw new Error(`Invalid non-string value for "name" within "${engine}"`)
	  }

	  if (typeof current.name !== 'string' || current.name === '') {
	    throw new Error(`Unable to determine "name" for "${engine}"`)
	  }

	  if (properties.includes('onFail')) {
	    if (typeof wanted.onFail !== 'string') {
	      throw new Error(`Invalid non-string value for "onFail" within "${engine}"`)
	    }
	    if (!recognizedOnFail.includes(wanted.onFail)) {
	      throw new Error(`Invalid onFail value "${wanted.onFail}" for "${engine}"`)
	    }
	  }

	  if (wanted.name !== current.name) {
	    return new Error(
	      `Invalid name "${wanted.name}" does not match "${current.name}" for "${engine}"`
	    )
	  }

	  if (properties.includes('version')) {
	    if (typeof wanted.version !== 'string') {
	      throw new Error(`Invalid non-string value for "version" within "${engine}"`)
	    }
	    if (typeof current.version !== 'string' || current.version === '') {
	      throw new Error(`Unable to determine "version" for "${engine}" "${wanted.name}"`)
	    }
	    if (validRange(wanted.version)) {
	      if (!satisfies(current.version, wanted.version, opts.semver)) {
	        return new Error(
	          // eslint-disable-next-line max-len
	          `Invalid semver version "${wanted.version}" does not match "${current.version}" for "${engine}"`
	        )
	      }
	    } else if (wanted.version !== current.version) {
	      return new Error(
	        `Invalid version "${wanted.version}" does not match "${current.version}" for "${engine}"`
	      )
	    }
	  }
	}

	/** checks devEngines package property and returns array of warnings / errors */
	function checkDevEngines (wanted, current = {}, opts = {}) {
	  if ((typeof wanted !== 'object' || wanted === null) || Array.isArray(wanted)) {
	    throw new Error(`Invalid non-object value for devEngines`)
	  }

	  const errors = [];

	  for (const engine of Object.keys(wanted)) {
	    if (!recognizedEngines.includes(engine)) {
	      throw new Error(`Invalid property "${engine}"`)
	    }
	    const dependencyAsAuthored = wanted[engine];
	    const dependencies = [dependencyAsAuthored].flat();
	    const currentEngine = current[engine] || {};

	    // this accounts for empty array eg { runtime: [] } and ignores it
	    if (dependencies.length === 0) {
	      continue
	    }

	    const depErrors = [];
	    for (const dep of dependencies) {
	      const result = checkDependency(dep, currentEngine, { ...opts, engine });
	      if (result) {
	        depErrors.push(result);
	      }
	    }

	    const invalid = depErrors.length === dependencies.length;

	    if (invalid) {
	      const lastDependency = dependencies[dependencies.length - 1];
	      let onFail = lastDependency.onFail || 'error';
	      if (onFail === 'download') {
	        onFail = 'error';
	      }

	      const err = Object.assign(new Error(`Invalid engine "${engine}"`), {
	        errors: depErrors,
	        engine,
	        isWarn: onFail === 'warn',
	        isError: onFail === 'error',
	        current: currentEngine,
	        required: dependencyAsAuthored,
	      });

	      errors.push(err);
	    }
	  }
	  return errors
	}

	devEngines = {
	  checkDevEngines,
	};
	return devEngines;
}

var lib$7;
var hasRequiredLib$7;

function requireLib$7 () {
	if (hasRequiredLib$7) return lib$7;
	hasRequiredLib$7 = 1;
	const semver = requireSemver();
	const currentEnv = requireCurrentEnv();
	const { checkDevEngines } = requireDevEngines();

	const checkEngine = (target, npmVer, nodeVer, force = false) => {
	  const nodev = force ? null : nodeVer;
	  const eng = target.engines;
	  const opt = { includePrerelease: true };
	  if (!eng) {
	    return
	  }

	  const nodeFail = nodev && eng.node && !semver.satisfies(nodev, eng.node, opt);
	  const npmFail = npmVer && eng.npm && !semver.satisfies(npmVer, eng.npm, opt);
	  if (nodeFail || npmFail) {
	    throw Object.assign(new Error('Unsupported engine'), {
	      pkgid: target._id,
	      current: { node: nodeVer, npm: npmVer },
	      required: eng,
	      code: 'EBADENGINE',
	    })
	  }
	};

	const checkPlatform = (target, force = false, environment = {}) => {
	  if (force) {
	    return
	  }

	  const os = environment.os || currentEnv.os();
	  const cpu = environment.cpu || currentEnv.cpu();
	  const libc = environment.libc || currentEnv.libc(os);

	  const osOk = target.os ? checkList(os, target.os) : true;
	  const cpuOk = target.cpu ? checkList(cpu, target.cpu) : true;
	  let libcOk = target.libc ? checkList(libc, target.libc) : true;
	  if (target.libc && !libc) {
	    libcOk = false;
	  }

	  if (!osOk || !cpuOk || !libcOk) {
	    throw Object.assign(new Error('Unsupported platform'), {
	      pkgid: target._id,
	      current: {
	        os,
	        cpu,
	        libc,
	      },
	      required: {
	        os: target.os,
	        cpu: target.cpu,
	        libc: target.libc,
	      },
	      code: 'EBADPLATFORM',
	    })
	  }
	};

	const checkList = (value, list) => {
	  if (typeof list === 'string') {
	    list = [list];
	  }
	  if (list.length === 1 && list[0] === 'any') {
	    return true
	  }
	  // match none of the negated values, and at least one of the
	  // non-negated values, if any are present.
	  let negated = 0;
	  let match = false;
	  for (const entry of list) {
	    const negate = entry.charAt(0) === '!';
	    const test = negate ? entry.slice(1) : entry;
	    if (negate) {
	      negated++;
	      if (value === test) {
	        return false
	      }
	    } else {
	      match = match || value === test;
	    }
	  }
	  return match || negated === list.length
	};

	lib$7 = {
	  checkEngine,
	  checkPlatform,
	  checkDevEngines,
	  currentEnv,
	};
	return lib$7;
}

var lib$6;
var hasRequiredLib$6;

function requireLib$6 () {
	if (hasRequiredLib$6) return lib$6;
	hasRequiredLib$6 = 1;
	// pass in a manifest with a 'bin' field here, and it'll turn it
	// into a properly santized bin object
	const { join, basename } = require$$0;

	const normalize = pkg =>
	  !pkg.bin ? removeBin(pkg)
	  : typeof pkg.bin === 'string' ? normalizeString(pkg)
	  : Array.isArray(pkg.bin) ? normalizeArray(pkg)
	  : typeof pkg.bin === 'object' ? normalizeObject(pkg)
	  : removeBin(pkg);

	const normalizeString = pkg => {
	  if (!pkg.name) {
	    return removeBin(pkg)
	  }
	  pkg.bin = { [pkg.name]: pkg.bin };
	  return normalizeObject(pkg)
	};

	const normalizeArray = pkg => {
	  pkg.bin = pkg.bin.reduce((acc, k) => {
	    acc[basename(k)] = k;
	    return acc
	  }, {});
	  return normalizeObject(pkg)
	};

	const removeBin = pkg => {
	  delete pkg.bin;
	  return pkg
	};

	const normalizeObject = pkg => {
	  const orig = pkg.bin;
	  const clean = {};
	  let hasBins = false;
	  Object.keys(orig).forEach(binKey => {
	    const base = join('/', basename(binKey.replace(/\\|:/g, '/'))).slice(1);

	    if (typeof orig[binKey] !== 'string' || !base) {
	      return
	    }

	    const binTarget = join('/', orig[binKey].replace(/\\/g, '/'))
	      .replace(/\\/g, '/').slice(1);

	    if (!binTarget) {
	      return
	    }

	    clean[base] = binTarget;
	    hasBins = true;
	  });

	  if (hasBins) {
	    pkg.bin = clean;
	  } else {
	    delete pkg.bin;
	  }

	  return pkg
	};

	lib$6 = normalize;
	return lib$6;
}

var lib$5;
var hasRequiredLib$5;

function requireLib$5 () {
	if (hasRequiredLib$5) return lib$5;
	hasRequiredLib$5 = 1;

	const npa = requireNpa();
	const semver = requireSemver();
	const { checkEngine } = requireLib$7();
	const normalizeBin = requireLib$6();

	const engineOk = (manifest, npmVersion, nodeVersion) => {
	  try {
	    checkEngine(manifest, npmVersion, nodeVersion);
	    return true
	  } catch (_) {
	    return false
	  }
	};

	const isBefore = (verTimes, ver, time) =>
	  !verTimes || !verTimes[ver] || Date.parse(verTimes[ver]) <= time;

	const avoidSemverOpt = { includePrerelease: true, loose: true };
	const shouldAvoid = (ver, avoid) =>
	  avoid && semver.satisfies(ver, avoid, avoidSemverOpt);

	const decorateAvoid = (result, avoid) =>
	  result && shouldAvoid(result.version, avoid)
	    ? { ...result, _shouldAvoid: true }
	    : result;

	const pickManifest = (packument, wanted, opts) => {
	  const {
	    defaultTag = 'latest',
	    before = null,
	    nodeVersion = process.version,
	    npmVersion = null,
	    includeStaged = false,
	    avoid = null,
	    avoidStrict = false,
	  } = opts;

	  const { name, time: verTimes } = packument;
	  const versions = packument.versions || {};

	  if (avoidStrict) {
	    const looseOpts = {
	      ...opts,
	      avoidStrict: false,
	    };

	    const result = pickManifest(packument, wanted, looseOpts);
	    if (!result || !result._shouldAvoid) {
	      return result
	    }

	    const caret = pickManifest(packument, `^${result.version}`, looseOpts);
	    if (!caret || !caret._shouldAvoid) {
	      return {
	        ...caret,
	        _outsideDependencyRange: true,
	        _isSemVerMajor: false,
	      }
	    }

	    const star = pickManifest(packument, '*', looseOpts);
	    if (!star || !star._shouldAvoid) {
	      return {
	        ...star,
	        _outsideDependencyRange: true,
	        _isSemVerMajor: true,
	      }
	    }

	    throw Object.assign(new Error(`No avoidable versions for ${name}`), {
	      code: 'ETARGET',
	      name,
	      wanted,
	      avoid,
	      before,
	      versions: Object.keys(versions),
	    })
	  }

	  const staged = (includeStaged && packument.stagedVersions &&
	    packument.stagedVersions.versions) || {};
	  const restricted = (packument.policyRestrictions &&
	    packument.policyRestrictions.versions) || {};

	  const time = before && verTimes ? +(new Date(before)) : Infinity;
	  const spec = npa.resolve(name, wanted || defaultTag);
	  const type = spec.type;
	  const distTags = packument['dist-tags'] || {};

	  if (type !== 'tag' && type !== 'version' && type !== 'range') {
	    throw new Error('Only tag, version, and range are supported')
	  }

	  // if the type is 'tag', and not just the implicit default, then it must
	  // be that exactly, or nothing else will do.
	  if (wanted && type === 'tag') {
	    const ver = distTags[wanted];
	    // if the version in the dist-tags is before the before date, then
	    // we use that.  Otherwise, we get the highest precedence version
	    // prior to the dist-tag.
	    if (isBefore(verTimes, ver, time)) {
	      return decorateAvoid(versions[ver] || staged[ver] || restricted[ver], avoid)
	    } else {
	      return pickManifest(packument, `<=${ver}`, opts)
	    }
	  }

	  // similarly, if a specific version, then only that version will do
	  if (wanted && type === 'version') {
	    const ver = semver.clean(wanted, { loose: true });
	    const mani = versions[ver] || staged[ver] || restricted[ver];
	    return isBefore(verTimes, ver, time) ? decorateAvoid(mani, avoid) : null
	  }

	  // ok, sort based on our heuristics, and pick the best fit
	  const range = type === 'range' ? wanted : '*';

	  // if the range is *, then we prefer the 'latest' if available
	  // but skip this if it should be avoided, in that case we have
	  // to try a little harder.
	  const defaultVer = distTags[defaultTag];
	  if (defaultVer &&
	      (range === '*' || semver.satisfies(defaultVer, range, { loose: true })) &&
	      !restricted[defaultVer] &&
	      !shouldAvoid(defaultVer, avoid)) {
	    const mani = versions[defaultVer];
	    const ok = mani &&
	      isBefore(verTimes, defaultVer, time) &&
	      engineOk(mani, npmVersion, nodeVersion) &&
	      !mani.deprecated &&
	      !staged[defaultVer];
	    if (ok) {
	      return mani
	    }
	  }

	  // ok, actually have to sort the list and take the winner
	  const allEntries = Object.entries(versions)
	    .concat(Object.entries(staged))
	    .concat(Object.entries(restricted))
	    .filter(([ver]) => isBefore(verTimes, ver, time));

	  if (!allEntries.length) {
	    throw Object.assign(new Error(`No versions available for ${name}`), {
	      code: 'ENOVERSIONS',
	      name,
	      type,
	      wanted,
	      before,
	      versions: Object.keys(versions),
	    })
	  }

	  const sortSemverOpt = { loose: true };
	  const entries = allEntries.filter(([ver]) =>
	    semver.satisfies(ver, range, { loose: true }))
	    .sort((a, b) => {
	      const [vera, mania] = a;
	      const [verb, manib] = b;
	      const notavoida = !shouldAvoid(vera, avoid);
	      const notavoidb = !shouldAvoid(verb, avoid);
	      const notrestra = !restricted[vera];
	      const notrestrb = !restricted[verb];
	      const notstagea = !staged[vera];
	      const notstageb = !staged[verb];
	      const notdepra = !mania.deprecated;
	      const notdeprb = !manib.deprecated;
	      const enginea = engineOk(mania, npmVersion, nodeVersion);
	      const engineb = engineOk(manib, npmVersion, nodeVersion);
	      // sort by:
	      // - not an avoided version
	      // - not restricted
	      // - not staged
	      // - not deprecated and engine ok
	      // - engine ok
	      // - not deprecated
	      // - semver
	      return (notavoidb - notavoida) ||
	        (notrestrb - notrestra) ||
	        (notstageb - notstagea) ||
	        ((notdeprb && engineb) - (notdepra && enginea)) ||
	        (engineb - enginea) ||
	        (notdeprb - notdepra) ||
	        semver.rcompare(vera, verb, sortSemverOpt)
	    });

	  return decorateAvoid(entries[0] && entries[0][1], avoid)
	};

	lib$5 = (packument, wanted, opts = {}) => {
	  const mani = pickManifest(packument, wanted, opts);
	  const picked = mani && normalizeBin(mani);
	  const policyRestrictions = packument.policyRestrictions;
	  const restricted = (policyRestrictions && policyRestrictions.versions) || {};

	  if (picked && !restricted[picked.version]) {
	    return picked
	  }

	  const { before = null, defaultTag = 'latest' } = opts;
	  const bstr = before ? new Date(before).toLocaleString() : '';
	  const { name } = packument;
	  const pckg = `${name}@${wanted}` +
	    (before ? ` with a date before ${bstr}` : '');

	  const isForbidden = picked && !!restricted[picked.version];
	  const polMsg = isForbidden ? policyRestrictions.message : '';

	  const msg = !isForbidden ? `No matching version found for ${pckg}.`
	    : `Could not download ${pckg} due to policy violations:\n${polMsg}`;

	  const code = isForbidden ? 'E403' : 'ETARGET';
	  throw Object.assign(new Error(msg), {
	    code,
	    type: npa.resolve(packument.name, wanted).type,
	    wanted,
	    versions: Object.keys(packument.versions ?? {}),
	    name,
	    distTags: packument['dist-tags'],
	    defaultTag,
	  })
	};
	return lib$5;
}

var clone_1;
var hasRequiredClone;

function requireClone () {
	if (hasRequiredClone) return clone_1;
	hasRequiredClone = 1;
	// The goal here is to minimize both git workload and
	// the number of refs we download over the network.
	//
	// Every method ends up with the checked out working dir
	// at the specified ref, and resolves with the git sha.

	// Only certain whitelisted hosts get shallow cloning.
	// Many hosts (including GHE) don't always support it.
	// A failed shallow fetch takes a LOT longer than a full
	// fetch in most cases, so we skip it entirely.
	// Set opts.gitShallow = true/false to force this behavior
	// one way or the other.
	const shallowHosts = new Set([
	  'github.com',
	  'gist.github.com',
	  'gitlab.com',
	  'bitbucket.com',
	  'bitbucket.org',
	]);
	// we have to use url.parse until we add the same shim that hosted-git-info has
	// to handle scp:// urls
	const { parse } = require$$0$1; // eslint-disable-line node/no-deprecated-api
	const path = require$$0;

	const getRevs = requireRevs();
	const spawn = requireSpawn();
	const { isWindows } = requireUtils();

	const pickManifest = requireLib$5();
	const fs = require$$0$4;

	clone_1 = (repo, ref = 'HEAD', target = null, opts = {}) =>
	  getRevs(repo, opts).then(revs => clone(
	    repo,
	    revs,
	    ref,
	    resolveRef(revs, ref, opts),
	    target || defaultTarget(repo, opts.cwd),
	    opts
	  ));

	const maybeShallow = (repo, opts) => {
	  if (opts.gitShallow === false || opts.gitShallow) {
	    return opts.gitShallow
	  }
	  return shallowHosts.has(parse(repo).host)
	};

	const defaultTarget = (repo, /* istanbul ignore next */ cwd = process.cwd()) =>
	  path.resolve(cwd, path.basename(repo.replace(/[/\\]?\.git$/, '')));

	const clone = (repo, revs, ref, revDoc, target, opts) => {
	  if (!revDoc) {
	    return unresolved(repo, ref, target, opts)
	  }
	  if (revDoc.sha === revs.refs.HEAD.sha) {
	    return plain(repo, revDoc, target, opts)
	  }
	  if (revDoc.type === 'tag' || revDoc.type === 'branch') {
	    return branch(repo, revDoc, target, opts)
	  }
	  return other(repo, revDoc, target, opts)
	};

	const resolveRef = (revs, ref, opts) => {
	  const { spec = {} } = opts;
	  ref = spec.gitCommittish || ref;
	  /* istanbul ignore next - will fail anyway, can't pull */
	  if (!revs) {
	    return null
	  }
	  if (spec.gitRange) {
	    return pickManifest(revs, spec.gitRange, opts)
	  }
	  if (!ref) {
	    return revs.refs.HEAD
	  }
	  if (revs.refs[ref]) {
	    return revs.refs[ref]
	  }
	  if (revs.shas[ref]) {
	    return revs.refs[revs.shas[ref][0]]
	  }
	  return null
	};

	// pull request or some other kind of advertised ref
	const other = (repo, revDoc, target, opts) => {
	  const shallow = maybeShallow(repo, opts);

	  const fetchOrigin = ['fetch', 'origin', revDoc.rawRef]
	    .concat(shallow ? ['--depth=1'] : []);

	  const git = (args) => spawn(args, { ...opts, cwd: target });
	  return fs.mkdir(target, { recursive: true })
	    .then(() => git(['init']))
	    .then(() => isWindows(opts)
	      ? git(['config', '--local', '--add', 'core.longpaths', 'true'])
	      : null)
	    .then(() => git(['remote', 'add', 'origin', repo]))
	    .then(() => git(fetchOrigin))
	    .then(() => git(['checkout', revDoc.sha]))
	    .then(() => updateSubmodules(target, opts))
	    .then(() => revDoc.sha)
	};

	// tag or branches.  use -b
	const branch = (repo, revDoc, target, opts) => {
	  const args = [
	    'clone',
	    '-b',
	    revDoc.ref,
	    repo,
	    target,
	    '--recurse-submodules',
	  ];
	  if (maybeShallow(repo, opts)) {
	    args.push('--depth=1');
	  }
	  if (isWindows(opts)) {
	    args.push('--config', 'core.longpaths=true');
	  }
	  return spawn(args, opts).then(() => revDoc.sha)
	};

	// just the head.  clone it
	const plain = (repo, revDoc, target, opts) => {
	  const args = [
	    'clone',
	    repo,
	    target,
	    '--recurse-submodules',
	  ];
	  if (maybeShallow(repo, opts)) {
	    args.push('--depth=1');
	  }
	  if (isWindows(opts)) {
	    args.push('--config', 'core.longpaths=true');
	  }
	  return spawn(args, opts).then(() => revDoc.sha)
	};

	const updateSubmodules = async (target, opts) => {
	  const hasSubmodules = await fs.stat(`${target}/.gitmodules`)
	    .then(() => true)
	    .catch(() => false);
	  if (!hasSubmodules) {
	    return null
	  }
	  return spawn([
	    'submodule',
	    'update',
	    '-q',
	    '--init',
	    '--recursive',
	  ], { ...opts, cwd: target })
	};

	const unresolved = (repo, ref, target, opts) => {
	  // can't do this one shallowly, because the ref isn't advertised
	  // but we can avoid checking out the working dir twice, at least
	  const lp = isWindows(opts) ? ['--config', 'core.longpaths=true'] : [];
	  const cloneArgs = ['clone', '--mirror', '-q', repo, target + '/.git'];
	  const git = (args) => spawn(args, { ...opts, cwd: target });
	  return fs.mkdir(target, { recursive: true })
	    .then(() => git(cloneArgs.concat(lp)))
	    .then(() => git(['init']))
	    .then(() => git(['checkout', ref]))
	    .then(() => updateSubmodules(target, opts))
	    .then(() => git(['rev-parse', '--revs-only', 'HEAD']))
	    .then(({ stdout }) => stdout.trim())
	};
	return clone_1;
}

var is;
var hasRequiredIs;

function requireIs () {
	if (hasRequiredIs) return is;
	hasRequiredIs = 1;
	// not an airtight indicator, but a good gut-check to even bother trying
	const { stat } = require$$0$4;
	is = ({ cwd = process.cwd() } = {}) =>
	  stat(cwd + '/.git').then(() => true, () => false);
	return is;
}

var find;
var hasRequiredFind;

function requireFind () {
	if (hasRequiredFind) return find;
	hasRequiredFind = 1;
	const is = requireIs();
	const { dirname } = require$$0;

	find = async ({ cwd = process.cwd(), root } = {}) => {
	  while (true) {
	    if (await is({ cwd })) {
	      return cwd
	    }
	    const next = dirname(cwd);
	    if (cwd === root || cwd === next) {
	      return null
	    }
	    cwd = next;
	  }
	};
	return find;
}

var isClean;
var hasRequiredIsClean;

function requireIsClean () {
	if (hasRequiredIsClean) return isClean;
	hasRequiredIsClean = 1;
	const spawn = requireSpawn();

	isClean = (opts = {}) =>
	  spawn(['status', '--porcelain=v1', '-uno'], opts)
	    .then(res => !res.stdout.trim().split(/\r?\n+/)
	      .map(l => l.trim()).filter(l => l).length);
	return isClean;
}

var lib$4;
var hasRequiredLib$4;

function requireLib$4 () {
	if (hasRequiredLib$4) return lib$4;
	hasRequiredLib$4 = 1;
	lib$4 = {
	  clone: requireClone(),
	  revs: requireRevs(),
	  spawn: requireSpawn(),
	  is: requireIs(),
	  find: requireFind(),
	  isClean: requireIsClean(),
	  errors: requireErrors(),
	};
	return lib$4;
}

const require$$1$1 = ["0BSD","3D-Slicer-1.0","AAL","ADSL","AFL-1.1","AFL-1.2","AFL-2.0","AFL-2.1","AFL-3.0","AGPL-1.0-only","AGPL-1.0-or-later","AGPL-3.0-only","AGPL-3.0-or-later","AMD-newlib","AMDPLPA","AML","AML-glslang","AMPAS","ANTLR-PD","ANTLR-PD-fallback","APAFML","APL-1.0","APSL-1.0","APSL-1.1","APSL-1.2","APSL-2.0","ASWF-Digital-Assets-1.0","ASWF-Digital-Assets-1.1","Abstyles","AdaCore-doc","Adobe-2006","Adobe-Display-PostScript","Adobe-Glyph","Adobe-Utopia","Afmparse","Aladdin","Apache-1.0","Apache-1.1","Apache-2.0","App-s2p","Arphic-1999","Artistic-1.0","Artistic-1.0-Perl","Artistic-1.0-cl8","Artistic-2.0","Artistic-dist","Aspell-RU","BSD-1-Clause","BSD-2-Clause","BSD-2-Clause-Darwin","BSD-2-Clause-Patent","BSD-2-Clause-Views","BSD-2-Clause-first-lines","BSD-2-Clause-pkgconf-disclaimer","BSD-3-Clause","BSD-3-Clause-Attribution","BSD-3-Clause-Clear","BSD-3-Clause-HP","BSD-3-Clause-LBNL","BSD-3-Clause-Modification","BSD-3-Clause-No-Military-License","BSD-3-Clause-No-Nuclear-License","BSD-3-Clause-No-Nuclear-License-2014","BSD-3-Clause-No-Nuclear-Warranty","BSD-3-Clause-Open-MPI","BSD-3-Clause-Sun","BSD-3-Clause-acpica","BSD-3-Clause-flex","BSD-4-Clause","BSD-4-Clause-Shortened","BSD-4-Clause-UC","BSD-4.3RENO","BSD-4.3TAHOE","BSD-Advertising-Acknowledgement","BSD-Attribution-HPND-disclaimer","BSD-Inferno-Nettverk","BSD-Protection","BSD-Source-Code","BSD-Source-beginning-file","BSD-Systemics","BSD-Systemics-W3Works","BSL-1.0","BUSL-1.1","Baekmuk","Bahyph","Barr","Beerware","BitTorrent-1.0","BitTorrent-1.1","Bitstream-Charter","Bitstream-Vera","BlueOak-1.0.0","Boehm-GC","Boehm-GC-without-fee","Borceux","Brian-Gladman-2-Clause","Brian-Gladman-3-Clause","C-UDA-1.0","CAL-1.0","CAL-1.0-Combined-Work-Exception","CATOSL-1.1","CC-BY-1.0","CC-BY-2.0","CC-BY-2.5","CC-BY-2.5-AU","CC-BY-3.0","CC-BY-3.0-AT","CC-BY-3.0-AU","CC-BY-3.0-DE","CC-BY-3.0-IGO","CC-BY-3.0-NL","CC-BY-3.0-US","CC-BY-4.0","CC-BY-NC-1.0","CC-BY-NC-2.0","CC-BY-NC-2.5","CC-BY-NC-3.0","CC-BY-NC-3.0-DE","CC-BY-NC-4.0","CC-BY-NC-ND-1.0","CC-BY-NC-ND-2.0","CC-BY-NC-ND-2.5","CC-BY-NC-ND-3.0","CC-BY-NC-ND-3.0-DE","CC-BY-NC-ND-3.0-IGO","CC-BY-NC-ND-4.0","CC-BY-NC-SA-1.0","CC-BY-NC-SA-2.0","CC-BY-NC-SA-2.0-DE","CC-BY-NC-SA-2.0-FR","CC-BY-NC-SA-2.0-UK","CC-BY-NC-SA-2.5","CC-BY-NC-SA-3.0","CC-BY-NC-SA-3.0-DE","CC-BY-NC-SA-3.0-IGO","CC-BY-NC-SA-4.0","CC-BY-ND-1.0","CC-BY-ND-2.0","CC-BY-ND-2.5","CC-BY-ND-3.0","CC-BY-ND-3.0-DE","CC-BY-ND-4.0","CC-BY-SA-1.0","CC-BY-SA-2.0","CC-BY-SA-2.0-UK","CC-BY-SA-2.1-JP","CC-BY-SA-2.5","CC-BY-SA-3.0","CC-BY-SA-3.0-AT","CC-BY-SA-3.0-DE","CC-BY-SA-3.0-IGO","CC-BY-SA-4.0","CC-PDDC","CC-PDM-1.0","CC-SA-1.0","CC0-1.0","CDDL-1.0","CDDL-1.1","CDL-1.0","CDLA-Permissive-1.0","CDLA-Permissive-2.0","CDLA-Sharing-1.0","CECILL-1.0","CECILL-1.1","CECILL-2.0","CECILL-2.1","CECILL-B","CECILL-C","CERN-OHL-1.1","CERN-OHL-1.2","CERN-OHL-P-2.0","CERN-OHL-S-2.0","CERN-OHL-W-2.0","CFITSIO","CMU-Mach","CMU-Mach-nodoc","CNRI-Jython","CNRI-Python","CNRI-Python-GPL-Compatible","COIL-1.0","CPAL-1.0","CPL-1.0","CPOL-1.02","CUA-OPL-1.0","Caldera","Caldera-no-preamble","Catharon","ClArtistic","Clips","Community-Spec-1.0","Condor-1.1","Cornell-Lossless-JPEG","Cronyx","Crossword","CryptoSwift","CrystalStacker","Cube","D-FSL-1.0","DEC-3-Clause","DL-DE-BY-2.0","DL-DE-ZERO-2.0","DOC","DRL-1.0","DRL-1.1","DSDP","DocBook-DTD","DocBook-Schema","DocBook-Stylesheet","DocBook-XML","Dotseqn","ECL-1.0","ECL-2.0","EFL-1.0","EFL-2.0","EPICS","EPL-1.0","EPL-2.0","EUDatagrid","EUPL-1.0","EUPL-1.1","EUPL-1.2","Elastic-2.0","Entessa","ErlPL-1.1","Eurosym","FBM","FDK-AAC","FSFAP","FSFAP-no-warranty-disclaimer","FSFUL","FSFULLR","FSFULLRSD","FSFULLRWD","FSL-1.1-ALv2","FSL-1.1-MIT","FTL","Fair","Ferguson-Twofish","Frameworx-1.0","FreeBSD-DOC","FreeImage","Furuseth","GCR-docs","GD","GFDL-1.1-invariants-only","GFDL-1.1-invariants-or-later","GFDL-1.1-no-invariants-only","GFDL-1.1-no-invariants-or-later","GFDL-1.1-only","GFDL-1.1-or-later","GFDL-1.2-invariants-only","GFDL-1.2-invariants-or-later","GFDL-1.2-no-invariants-only","GFDL-1.2-no-invariants-or-later","GFDL-1.2-only","GFDL-1.2-or-later","GFDL-1.3-invariants-only","GFDL-1.3-invariants-or-later","GFDL-1.3-no-invariants-only","GFDL-1.3-no-invariants-or-later","GFDL-1.3-only","GFDL-1.3-or-later","GL2PS","GLWTPL","GPL-1.0-only","GPL-1.0-or-later","GPL-2.0-only","GPL-2.0-or-later","GPL-3.0-only","GPL-3.0-or-later","Game-Programming-Gems","Giftware","Glide","Glulxe","Graphics-Gems","Gutmann","HDF5","HIDAPI","HP-1986","HP-1989","HPND","HPND-DEC","HPND-Fenneberg-Livingston","HPND-INRIA-IMAG","HPND-Intel","HPND-Kevlin-Henney","HPND-MIT-disclaimer","HPND-Markus-Kuhn","HPND-Netrek","HPND-Pbmplus","HPND-UC","HPND-UC-export-US","HPND-doc","HPND-doc-sell","HPND-export-US","HPND-export-US-acknowledgement","HPND-export-US-modify","HPND-export2-US","HPND-merchantability-variant","HPND-sell-MIT-disclaimer-xserver","HPND-sell-regexpr","HPND-sell-variant","HPND-sell-variant-MIT-disclaimer","HPND-sell-variant-MIT-disclaimer-rev","HTMLTIDY","HaskellReport","Hippocratic-2.1","IBM-pibs","ICU","IEC-Code-Components-EULA","IJG","IJG-short","IPA","IPL-1.0","ISC","ISC-Veillard","ImageMagick","Imlib2","Info-ZIP","Inner-Net-2.0","InnoSetup","Intel","Intel-ACPI","Interbase-1.0","JPL-image","JPNIC","JSON","Jam","JasPer-2.0","Kastrup","Kazlib","Knuth-CTAN","LAL-1.2","LAL-1.3","LGPL-2.0-only","LGPL-2.0-or-later","LGPL-2.1-only","LGPL-2.1-or-later","LGPL-3.0-only","LGPL-3.0-or-later","LGPLLR","LOOP","LPD-document","LPL-1.0","LPL-1.02","LPPL-1.0","LPPL-1.1","LPPL-1.2","LPPL-1.3a","LPPL-1.3c","LZMA-SDK-9.11-to-9.20","LZMA-SDK-9.22","Latex2e","Latex2e-translated-notice","Leptonica","LiLiQ-P-1.1","LiLiQ-R-1.1","LiLiQ-Rplus-1.1","Libpng","Linux-OpenIB","Linux-man-pages-1-para","Linux-man-pages-copyleft","Linux-man-pages-copyleft-2-para","Linux-man-pages-copyleft-var","Lucida-Bitmap-Fonts","MIPS","MIT","MIT-0","MIT-CMU","MIT-Click","MIT-Festival","MIT-Khronos-old","MIT-Modern-Variant","MIT-Wu","MIT-advertising","MIT-enna","MIT-feh","MIT-open-group","MIT-testregex","MITNFA","MMIXware","MPEG-SSG","MPL-1.0","MPL-1.1","MPL-2.0","MPL-2.0-no-copyleft-exception","MS-LPL","MS-PL","MS-RL","MTLL","Mackerras-3-Clause","Mackerras-3-Clause-acknowledgment","MakeIndex","Martin-Birgmeier","McPhee-slideshow","Minpack","MirOS","Motosoto","MulanPSL-1.0","MulanPSL-2.0","Multics","Mup","NAIST-2003","NASA-1.3","NBPL-1.0","NCBI-PD","NCGL-UK-2.0","NCL","NCSA","NGPL","NICTA-1.0","NIST-PD","NIST-PD-fallback","NIST-Software","NLOD-1.0","NLOD-2.0","NLPL","NOSL","NPL-1.0","NPL-1.1","NPOSL-3.0","NRL","NTIA-PD","NTP","NTP-0","Naumen","NetCDF","Newsletr","Nokia","Noweb","O-UDA-1.0","OAR","OCCT-PL","OCLC-2.0","ODC-By-1.0","ODbL-1.0","OFFIS","OFL-1.0","OFL-1.0-RFN","OFL-1.0-no-RFN","OFL-1.1","OFL-1.1-RFN","OFL-1.1-no-RFN","OGC-1.0","OGDL-Taiwan-1.0","OGL-Canada-2.0","OGL-UK-1.0","OGL-UK-2.0","OGL-UK-3.0","OGTSL","OLDAP-1.1","OLDAP-1.2","OLDAP-1.3","OLDAP-1.4","OLDAP-2.0","OLDAP-2.0.1","OLDAP-2.1","OLDAP-2.2","OLDAP-2.2.1","OLDAP-2.2.2","OLDAP-2.3","OLDAP-2.4","OLDAP-2.5","OLDAP-2.6","OLDAP-2.7","OLDAP-2.8","OLFL-1.3","OML","OPL-1.0","OPL-UK-3.0","OPUBL-1.0","OSET-PL-2.1","OSL-1.0","OSL-1.1","OSL-2.0","OSL-2.1","OSL-3.0","OpenPBS-2.3","OpenSSL","OpenSSL-standalone","OpenVision","PADL","PDDL-1.0","PHP-3.0","PHP-3.01","PPL","PSF-2.0","Parity-6.0.0","Parity-7.0.0","Pixar","Plexus","PolyForm-Noncommercial-1.0.0","PolyForm-Small-Business-1.0.0","PostgreSQL","Python-2.0","Python-2.0.1","QPL-1.0","QPL-1.0-INRIA-2004","Qhull","RHeCos-1.1","RPL-1.1","RPL-1.5","RPSL-1.0","RSA-MD","RSCPL","Rdisc","Ruby","Ruby-pty","SAX-PD","SAX-PD-2.0","SCEA","SGI-B-1.0","SGI-B-1.1","SGI-B-2.0","SGI-OpenGL","SGP4","SHL-0.5","SHL-0.51","SISSL","SISSL-1.2","SL","SMAIL-GPL","SMLNJ","SMPPL","SNIA","SOFA","SPL-1.0","SSH-OpenSSH","SSH-short","SSLeay-standalone","SSPL-1.0","SUL-1.0","SWL","Saxpath","SchemeReport","Sendmail","Sendmail-8.23","Sendmail-Open-Source-1.1","SimPL-2.0","Sleepycat","Soundex","Spencer-86","Spencer-94","Spencer-99","SugarCRM-1.1.3","Sun-PPP","Sun-PPP-2000","SunPro","Symlinks","TAPR-OHL-1.0","TCL","TCP-wrappers","TGPPL-1.0","TMate","TORQUE-1.1","TOSL","TPDL","TPL-1.0","TTWL","TTYP0","TU-Berlin-1.0","TU-Berlin-2.0","TermReadKey","ThirdEye","TrustedQSL","UCAR","UCL-1.0","UMich-Merit","UPL-1.0","URT-RLE","Ubuntu-font-1.0","Unicode-3.0","Unicode-DFS-2015","Unicode-DFS-2016","Unicode-TOU","UnixCrypt","Unlicense","Unlicense-libtelnet","Unlicense-libwhirlpool","VOSTROM","VSL-1.0","Vim","W3C","W3C-19980720","W3C-20150513","WTFPL","Watcom-1.0","Widget-Workshop","Wsuipa","X11","X11-distribute-modifications-variant","X11-swapped","XFree86-1.1","XSkat","Xdebug-1.03","Xerox","Xfig","Xnet","YPL-1.0","YPL-1.1","ZPL-1.1","ZPL-2.0","ZPL-2.1","Zed","Zeeff","Zend-2.0","Zimbra-1.3","Zimbra-1.4","Zlib","any-OSI","any-OSI-perl-modules","bcrypt-Solar-Designer","blessing","bzip2-1.0.6","check-cvs","checkmk","copyleft-next-0.3.0","copyleft-next-0.3.1","curl","cve-tou","diffmark","dtoa","dvipdfm","eGenix","etalab-2.0","fwlw","gSOAP-1.3b","generic-xts","gnuplot","gtkbook","hdparm","iMatix","jove","libpng-1.6.35","libpng-2.0","libselinux-1.0","libtiff","libutil-David-Nugent","lsof","magaz","mailprio","man2html","metamail","mpi-permissive","mpich2","mplus","ngrep","pkgconf","pnmstitch","psfrag","psutils","python-ldap","radvd","snprintf","softSurfer","ssh-keyscan","swrule","threeparttable","ulem","w3m","wwl","xinetd","xkeyboard-config-Zinoviev","xlock","xpp","xzoom","zlib-acknowledgement"];

const require$$1 = ["AGPL-1.0","AGPL-3.0","BSD-2-Clause-FreeBSD","BSD-2-Clause-NetBSD","GFDL-1.1","GFDL-1.2","GFDL-1.3","GPL-1.0","GPL-2.0","GPL-2.0-with-GCC-exception","GPL-2.0-with-autoconf-exception","GPL-2.0-with-bison-exception","GPL-2.0-with-classpath-exception","GPL-2.0-with-font-exception","GPL-3.0","GPL-3.0-with-GCC-exception","GPL-3.0-with-autoconf-exception","LGPL-2.0","LGPL-2.1","LGPL-3.0","Net-SNMP","Nunit","StandardML-NJ","bzip2-1.0.5","eCos-2.0","wxWindows"];

const require$$2 = ["389-exception","Asterisk-exception","Autoconf-exception-2.0","Autoconf-exception-3.0","Autoconf-exception-generic","Autoconf-exception-generic-3.0","Autoconf-exception-macro","Bison-exception-1.24","Bison-exception-2.2","Bootloader-exception","Classpath-exception-2.0","CLISP-exception-2.0","cryptsetup-OpenSSL-exception","DigiRule-FOSS-exception","eCos-exception-2.0","Fawkes-Runtime-exception","FLTK-exception","fmt-exception","Font-exception-2.0","freertos-exception-2.0","GCC-exception-2.0","GCC-exception-2.0-note","GCC-exception-3.1","Gmsh-exception","GNAT-exception","GNOME-examples-exception","GNU-compiler-exception","gnu-javamail-exception","GPL-3.0-interface-exception","GPL-3.0-linking-exception","GPL-3.0-linking-source-exception","GPL-CC-1.0","GStreamer-exception-2005","GStreamer-exception-2008","i2p-gpl-java-exception","KiCad-libraries-exception","LGPL-3.0-linking-exception","libpri-OpenH323-exception","Libtool-exception","Linux-syscall-note","LLGPL","LLVM-exception","LZMA-exception","mif-exception","OCaml-LGPL-linking-exception","OCCT-exception-1.0","OpenJDK-assembly-exception-1.0","openvpn-openssl-exception","PS-or-PDF-font-exception-20170817","QPL-1.0-INRIA-2004-exception","Qt-GPL-exception-1.0","Qt-LGPL-exception-1.1","Qwt-exception-1.0","SANE-exception","SHL-2.0","SHL-2.1","stunnel-exception","SWI-exception","Swift-exception","Texinfo-exception","u-boot-exception-2.0","UBDL-exception","Universal-FOSS-exception-1.0","vsftpd-openssl-exception","WxWindows-exception-3.1","x11vnc-openssl-exception"];

var scan;
var hasRequiredScan;

function requireScan () {
	if (hasRequiredScan) return scan;
	hasRequiredScan = 1;

	var licenses = []
	  .concat(require$$1$1)
	  .concat(require$$1);
	var exceptions = require$$2;

	scan = function (source) {
	  var index = 0;

	  function hasMore () {
	    return index < source.length
	  }

	  // `value` can be a regexp or a string.
	  // If it is recognized, the matching source string is returned and
	  // the index is incremented. Otherwise `undefined` is returned.
	  function read (value) {
	    if (value instanceof RegExp) {
	      var chars = source.slice(index);
	      var match = chars.match(value);
	      if (match) {
	        index += match[0].length;
	        return match[0]
	      }
	    } else {
	      if (source.indexOf(value, index) === index) {
	        index += value.length;
	        return value
	      }
	    }
	  }

	  function skipWhitespace () {
	    read(/[ ]*/);
	  }

	  function operator () {
	    var string;
	    var possibilities = ['WITH', 'AND', 'OR', '(', ')', ':', '+'];
	    for (var i = 0; i < possibilities.length; i++) {
	      string = read(possibilities[i]);
	      if (string) {
	        break
	      }
	    }

	    if (string === '+' && index > 1 && source[index - 2] === ' ') {
	      throw new Error('Space before `+`')
	    }

	    return string && {
	      type: 'OPERATOR',
	      string: string
	    }
	  }

	  function idstring () {
	    return read(/[A-Za-z0-9-.]+/)
	  }

	  function expectIdstring () {
	    var string = idstring();
	    if (!string) {
	      throw new Error('Expected idstring at offset ' + index)
	    }
	    return string
	  }

	  function documentRef () {
	    if (read('DocumentRef-')) {
	      var string = expectIdstring();
	      return { type: 'DOCUMENTREF', string: string }
	    }
	  }

	  function licenseRef () {
	    if (read('LicenseRef-')) {
	      var string = expectIdstring();
	      return { type: 'LICENSEREF', string: string }
	    }
	  }

	  function identifier () {
	    var begin = index;
	    var string = idstring();

	    if (licenses.indexOf(string) !== -1) {
	      return {
	        type: 'LICENSE',
	        string: string
	      }
	    } else if (exceptions.indexOf(string) !== -1) {
	      return {
	        type: 'EXCEPTION',
	        string: string
	      }
	    }

	    index = begin;
	  }

	  // Tries to read the next token. Returns `undefined` if no token is
	  // recognized.
	  function parseToken () {
	    // Ordering matters
	    return (
	      operator() ||
	      documentRef() ||
	      licenseRef() ||
	      identifier()
	    )
	  }

	  var tokens = [];
	  while (hasMore()) {
	    skipWhitespace();
	    if (!hasMore()) {
	      break
	    }

	    var token = parseToken();
	    if (!token) {
	      throw new Error('Unexpected `' + source[index] +
	                      '` at offset ' + index)
	    }

	    tokens.push(token);
	  }
	  return tokens
	};
	return scan;
}

var parse;
var hasRequiredParse;

function requireParse () {
	if (hasRequiredParse) return parse;
	hasRequiredParse = 1;

	// The ABNF grammar in the spec is totally ambiguous.
	//
	// This parser follows the operator precedence defined in the
	// `Order of Precedence and Parentheses` section.

	parse = function (tokens) {
	  var index = 0;

	  function hasMore () {
	    return index < tokens.length
	  }

	  function token () {
	    return hasMore() ? tokens[index] : null
	  }

	  function next () {
	    if (!hasMore()) {
	      throw new Error()
	    }
	    index++;
	  }

	  function parseOperator (operator) {
	    var t = token();
	    if (t && t.type === 'OPERATOR' && operator === t.string) {
	      next();
	      return t.string
	    }
	  }

	  function parseWith () {
	    if (parseOperator('WITH')) {
	      var t = token();
	      if (t && t.type === 'EXCEPTION') {
	        next();
	        return t.string
	      }
	      throw new Error('Expected exception after `WITH`')
	    }
	  }

	  function parseLicenseRef () {
	    // TODO: Actually, everything is concatenated into one string
	    // for backward-compatibility but it could be better to return
	    // a nice structure.
	    var begin = index;
	    var string = '';
	    var t = token();
	    if (t.type === 'DOCUMENTREF') {
	      next();
	      string += 'DocumentRef-' + t.string + ':';
	      if (!parseOperator(':')) {
	        throw new Error('Expected `:` after `DocumentRef-...`')
	      }
	    }
	    t = token();
	    if (t.type === 'LICENSEREF') {
	      next();
	      string += 'LicenseRef-' + t.string;
	      return { license: string }
	    }
	    index = begin;
	  }

	  function parseLicense () {
	    var t = token();
	    if (t && t.type === 'LICENSE') {
	      next();
	      var node = { license: t.string };
	      if (parseOperator('+')) {
	        node.plus = true;
	      }
	      var exception = parseWith();
	      if (exception) {
	        node.exception = exception;
	      }
	      return node
	    }
	  }

	  function parseParenthesizedExpression () {
	    var left = parseOperator('(');
	    if (!left) {
	      return
	    }

	    var expr = parseExpression();

	    if (!parseOperator(')')) {
	      throw new Error('Expected `)`')
	    }

	    return expr
	  }

	  function parseAtom () {
	    return (
	      parseParenthesizedExpression() ||
	      parseLicenseRef() ||
	      parseLicense()
	    )
	  }

	  function makeBinaryOpParser (operator, nextParser) {
	    return function parseBinaryOp () {
	      var left = nextParser();
	      if (!left) {
	        return
	      }

	      if (!parseOperator(operator)) {
	        return left
	      }

	      var right = parseBinaryOp();
	      if (!right) {
	        throw new Error('Expected expression')
	      }
	      return {
	        left: left,
	        conjunction: operator.toLowerCase(),
	        right: right
	      }
	    }
	  }

	  var parseAnd = makeBinaryOpParser('AND', parseAtom);
	  var parseExpression = makeBinaryOpParser('OR', parseAnd);

	  var node = parseExpression();
	  if (!node || hasMore()) {
	    throw new Error('Syntax error')
	  }
	  return node
	};
	return parse;
}

var spdxExpressionParse;
var hasRequiredSpdxExpressionParse;

function requireSpdxExpressionParse () {
	if (hasRequiredSpdxExpressionParse) return spdxExpressionParse;
	hasRequiredSpdxExpressionParse = 1;

	var scan = requireScan();
	var parse = requireParse();

	spdxExpressionParse = function (source) {
	  return parse(scan(source))
	};
	return spdxExpressionParse;
}

/*
Copyright spdx-correct.js contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

var spdxCorrect;
var hasRequiredSpdxCorrect;

function requireSpdxCorrect () {
	if (hasRequiredSpdxCorrect) return spdxCorrect;
	hasRequiredSpdxCorrect = 1;
	var parse = requireSpdxExpressionParse();
	var spdxLicenseIds = require$$1$1;

	function valid (string) {
	  try {
	    parse(string);
	    return true
	  } catch (error) {
	    return false
	  }
	}

	// Sorting function that orders the given array of transpositions such
	// that a transposition with the longer pattern comes before a transposition
	// with a shorter pattern. This is to prevent e.g. the transposition
	// ["General Public License", "GPL"] from matching to "Lesser General Public License"
	// before a longer and more accurate transposition ["Lesser General Public License", "LGPL"]
	// has a chance to be recognized.
	function sortTranspositions(a, b) {
	  var length = b[0].length - a[0].length;
	  if (length !== 0) return length
	  return a[0].toUpperCase().localeCompare(b[0].toUpperCase())
	}

	// Common transpositions of license identifier acronyms
	var transpositions = [
	  ['APGL', 'AGPL'],
	  ['Gpl', 'GPL'],
	  ['GLP', 'GPL'],
	  ['APL', 'Apache'],
	  ['ISD', 'ISC'],
	  ['GLP', 'GPL'],
	  ['IST', 'ISC'],
	  ['Claude', 'Clause'],
	  [' or later', '+'],
	  [' International', ''],
	  ['GNU', 'GPL'],
	  ['GUN', 'GPL'],
	  ['+', ''],
	  ['GNU GPL', 'GPL'],
	  ['GNU LGPL', 'LGPL'],
	  ['GNU/GPL', 'GPL'],
	  ['GNU GLP', 'GPL'],
	  ['GNU LESSER GENERAL PUBLIC LICENSE', 'LGPL'],
	  ['GNU Lesser General Public License', 'LGPL'],
	  ['GNU LESSER GENERAL PUBLIC LICENSE', 'LGPL-2.1'],
	  ['GNU Lesser General Public License', 'LGPL-2.1'],
	  ['LESSER GENERAL PUBLIC LICENSE', 'LGPL'],
	  ['Lesser General Public License', 'LGPL'],
	  ['LESSER GENERAL PUBLIC LICENSE', 'LGPL-2.1'],
	  ['Lesser General Public License', 'LGPL-2.1'],
	  ['GNU General Public License', 'GPL'],
	  ['Gnu public license', 'GPL'],
	  ['GNU Public License', 'GPL'],
	  ['GNU GENERAL PUBLIC LICENSE', 'GPL'],
	  ['MTI', 'MIT'],
	  ['Mozilla Public License', 'MPL'],
	  ['Universal Permissive License', 'UPL'],
	  ['WTH', 'WTF'],
	  ['WTFGPL', 'WTFPL'],
	  ['-License', '']
	].sort(sortTranspositions);

	var TRANSPOSED = 0;
	var CORRECT = 1;

	// Simple corrections to nearly valid identifiers.
	var transforms = [
	  // e.g. 'mit'
	  function (argument) {
	    return argument.toUpperCase()
	  },
	  // e.g. 'MIT '
	  function (argument) {
	    return argument.trim()
	  },
	  // e.g. 'M.I.T.'
	  function (argument) {
	    return argument.replace(/\./g, '')
	  },
	  // e.g. 'Apache- 2.0'
	  function (argument) {
	    return argument.replace(/\s+/g, '')
	  },
	  // e.g. 'CC BY 4.0''
	  function (argument) {
	    return argument.replace(/\s+/g, '-')
	  },
	  // e.g. 'LGPLv2.1'
	  function (argument) {
	    return argument.replace('v', '-')
	  },
	  // e.g. 'Apache 2.0'
	  function (argument) {
	    return argument.replace(/,?\s*(\d)/, '-$1')
	  },
	  // e.g. 'GPL 2'
	  function (argument) {
	    return argument.replace(/,?\s*(\d)/, '-$1.0')
	  },
	  // e.g. 'Apache Version 2.0'
	  function (argument) {
	    return argument
	      .replace(/,?\s*(V\.|v\.|V|v|Version|version)\s*(\d)/, '-$2')
	  },
	  // e.g. 'Apache Version 2'
	  function (argument) {
	    return argument
	      .replace(/,?\s*(V\.|v\.|V|v|Version|version)\s*(\d)/, '-$2.0')
	  },
	  // e.g. 'ZLIB'
	  function (argument) {
	    return argument[0].toUpperCase() + argument.slice(1)
	  },
	  // e.g. 'MPL/2.0'
	  function (argument) {
	    return argument.replace('/', '-')
	  },
	  // e.g. 'Apache 2'
	  function (argument) {
	    return argument
	      .replace(/\s*V\s*(\d)/, '-$1')
	      .replace(/(\d)$/, '$1.0')
	  },
	  // e.g. 'GPL-2.0', 'GPL-3.0'
	  function (argument) {
	    if (argument.indexOf('3.0') !== -1) {
	      return argument + '-or-later'
	    } else {
	      return argument + '-only'
	    }
	  },
	  // e.g. 'GPL-2.0-'
	  function (argument) {
	    return argument + 'only'
	  },
	  // e.g. 'GPL2'
	  function (argument) {
	    return argument.replace(/(\d)$/, '-$1.0')
	  },
	  // e.g. 'BSD 3'
	  function (argument) {
	    return argument.replace(/(-| )?(\d)$/, '-$2-Clause')
	  },
	  // e.g. 'BSD clause 3'
	  function (argument) {
	    return argument.replace(/(-| )clause(-| )(\d)/, '-$3-Clause')
	  },
	  // e.g. 'New BSD license'
	  function (argument) {
	    return argument.replace(/\b(Modified|New|Revised)(-| )?BSD((-| )License)?/i, 'BSD-3-Clause')
	  },
	  // e.g. 'Simplified BSD license'
	  function (argument) {
	    return argument.replace(/\bSimplified(-| )?BSD((-| )License)?/i, 'BSD-2-Clause')
	  },
	  // e.g. 'Free BSD license'
	  function (argument) {
	    return argument.replace(/\b(Free|Net)(-| )?BSD((-| )License)?/i, 'BSD-2-Clause-$1BSD')
	  },
	  // e.g. 'Clear BSD license'
	  function (argument) {
	    return argument.replace(/\bClear(-| )?BSD((-| )License)?/i, 'BSD-3-Clause-Clear')
	  },
	  // e.g. 'Old BSD License'
	  function (argument) {
	    return argument.replace(/\b(Old|Original)(-| )?BSD((-| )License)?/i, 'BSD-4-Clause')
	  },
	  // e.g. 'BY-NC-4.0'
	  function (argument) {
	    return 'CC-' + argument
	  },
	  // e.g. 'BY-NC'
	  function (argument) {
	    return 'CC-' + argument + '-4.0'
	  },
	  // e.g. 'Attribution-NonCommercial'
	  function (argument) {
	    return argument
	      .replace('Attribution', 'BY')
	      .replace('NonCommercial', 'NC')
	      .replace('NoDerivatives', 'ND')
	      .replace(/ (\d)/, '-$1')
	      .replace(/ ?International/, '')
	  },
	  // e.g. 'Attribution-NonCommercial'
	  function (argument) {
	    return 'CC-' +
	      argument
	        .replace('Attribution', 'BY')
	        .replace('NonCommercial', 'NC')
	        .replace('NoDerivatives', 'ND')
	        .replace(/ (\d)/, '-$1')
	        .replace(/ ?International/, '') +
	      '-4.0'
	  }
	];

	var licensesWithVersions = spdxLicenseIds
	  .map(function (id) {
	    var match = /^(.*)-\d+\.\d+$/.exec(id);
	    return match
	      ? [match[0], match[1]]
	      : [id, null]
	  })
	  .reduce(function (objectMap, item) {
	    var key = item[1];
	    objectMap[key] = objectMap[key] || [];
	    objectMap[key].push(item[0]);
	    return objectMap
	  }, {});

	var licensesWithOneVersion = Object.keys(licensesWithVersions)
	  .map(function makeEntries (key) {
	    return [key, licensesWithVersions[key]]
	  })
	  .filter(function identifySoleVersions (item) {
	    return (
	      // Licenses has just one valid version suffix.
	      item[1].length === 1 &&
	      item[0] !== null &&
	      // APL will be considered Apache, rather than APL-1.0
	      item[0] !== 'APL'
	    )
	  })
	  .map(function createLastResorts (item) {
	    return [item[0], item[1][0]]
	  });

	licensesWithVersions = undefined;

	// If all else fails, guess that strings containing certain substrings
	// meant to identify certain licenses.
	var lastResorts = [
	  ['UNLI', 'Unlicense'],
	  ['WTF', 'WTFPL'],
	  ['2 CLAUSE', 'BSD-2-Clause'],
	  ['2-CLAUSE', 'BSD-2-Clause'],
	  ['3 CLAUSE', 'BSD-3-Clause'],
	  ['3-CLAUSE', 'BSD-3-Clause'],
	  ['AFFERO', 'AGPL-3.0-or-later'],
	  ['AGPL', 'AGPL-3.0-or-later'],
	  ['APACHE', 'Apache-2.0'],
	  ['ARTISTIC', 'Artistic-2.0'],
	  ['Affero', 'AGPL-3.0-or-later'],
	  ['BEER', 'Beerware'],
	  ['BOOST', 'BSL-1.0'],
	  ['BSD', 'BSD-2-Clause'],
	  ['CDDL', 'CDDL-1.1'],
	  ['ECLIPSE', 'EPL-1.0'],
	  ['FUCK', 'WTFPL'],
	  ['GNU', 'GPL-3.0-or-later'],
	  ['LGPL', 'LGPL-3.0-or-later'],
	  ['GPLV1', 'GPL-1.0-only'],
	  ['GPL-1', 'GPL-1.0-only'],
	  ['GPLV2', 'GPL-2.0-only'],
	  ['GPL-2', 'GPL-2.0-only'],
	  ['GPL', 'GPL-3.0-or-later'],
	  ['MIT +NO-FALSE-ATTRIBS', 'MITNFA'],
	  ['MIT', 'MIT'],
	  ['MPL', 'MPL-2.0'],
	  ['X11', 'X11'],
	  ['ZLIB', 'Zlib']
	].concat(licensesWithOneVersion).sort(sortTranspositions);

	var SUBSTRING = 0;
	var IDENTIFIER = 1;

	var validTransformation = function (identifier) {
	  for (var i = 0; i < transforms.length; i++) {
	    var transformed = transforms[i](identifier).trim();
	    if (transformed !== identifier && valid(transformed)) {
	      return transformed
	    }
	  }
	  return null
	};

	var validLastResort = function (identifier) {
	  var upperCased = identifier.toUpperCase();
	  for (var i = 0; i < lastResorts.length; i++) {
	    var lastResort = lastResorts[i];
	    if (upperCased.indexOf(lastResort[SUBSTRING]) > -1) {
	      return lastResort[IDENTIFIER]
	    }
	  }
	  return null
	};

	var anyCorrection = function (identifier, check) {
	  for (var i = 0; i < transpositions.length; i++) {
	    var transposition = transpositions[i];
	    var transposed = transposition[TRANSPOSED];
	    if (identifier.indexOf(transposed) > -1) {
	      var corrected = identifier.replace(
	        transposed,
	        transposition[CORRECT]
	      );
	      var checked = check(corrected);
	      if (checked !== null) {
	        return checked
	      }
	    }
	  }
	  return null
	};

	spdxCorrect = function (identifier, options) {
	  options = options || {};
	  var upgrade = options.upgrade === undefined ? true : !!options.upgrade;
	  function postprocess (value) {
	    return upgrade ? upgradeGPLs(value) : value
	  }
	  var validArugment = (
	    typeof identifier === 'string' &&
	    identifier.trim().length !== 0
	  );
	  if (!validArugment) {
	    throw Error('Invalid argument. Expected non-empty string.')
	  }
	  identifier = identifier.trim();
	  if (valid(identifier)) {
	    return postprocess(identifier)
	  }
	  var noPlus = identifier.replace(/\+$/, '').trim();
	  if (valid(noPlus)) {
	    return postprocess(noPlus)
	  }
	  var transformed = validTransformation(identifier);
	  if (transformed !== null) {
	    return postprocess(transformed)
	  }
	  transformed = anyCorrection(identifier, function (argument) {
	    if (valid(argument)) {
	      return argument
	    }
	    return validTransformation(argument)
	  });
	  if (transformed !== null) {
	    return postprocess(transformed)
	  }
	  transformed = validLastResort(identifier);
	  if (transformed !== null) {
	    return postprocess(transformed)
	  }
	  transformed = anyCorrection(identifier, validLastResort);
	  if (transformed !== null) {
	    return postprocess(transformed)
	  }
	  return null
	};

	function upgradeGPLs (value) {
	  if ([
	    'GPL-1.0', 'LGPL-1.0', 'AGPL-1.0',
	    'GPL-2.0', 'LGPL-2.0', 'AGPL-2.0',
	    'LGPL-2.1'
	  ].indexOf(value) !== -1) {
	    return value + '-only'
	  } else if ([
	    'GPL-1.0+', 'GPL-2.0+', 'GPL-3.0+',
	    'LGPL-2.0+', 'LGPL-2.1+', 'LGPL-3.0+',
	    'AGPL-1.0+', 'AGPL-3.0+'
	  ].indexOf(value) !== -1) {
	    return value.replace(/\+$/, '-or-later')
	  } else if (['GPL-3.0', 'LGPL-3.0', 'AGPL-3.0'].indexOf(value) !== -1) {
	    return value + '-or-later'
	  } else {
	    return value
	  }
	}
	return spdxCorrect;
}

var validateNpmPackageLicense;
var hasRequiredValidateNpmPackageLicense;

function requireValidateNpmPackageLicense () {
	if (hasRequiredValidateNpmPackageLicense) return validateNpmPackageLicense;
	hasRequiredValidateNpmPackageLicense = 1;
	var parse = requireSpdxExpressionParse();
	var correct = requireSpdxCorrect();

	var genericWarning = (
	  'license should be ' +
	  'a valid SPDX license expression (without "LicenseRef"), ' +
	  '"UNLICENSED", or ' +
	  '"SEE LICENSE IN <filename>"'
	);

	var fileReferenceRE = /^SEE LICEN[CS]E IN (.+)$/;

	function startsWith(prefix, string) {
	  return string.slice(0, prefix.length) === prefix;
	}

	function usesLicenseRef(ast) {
	  if (ast.hasOwnProperty('license')) {
	    var license = ast.license;
	    return (
	      startsWith('LicenseRef', license) ||
	      startsWith('DocumentRef', license)
	    );
	  } else {
	    return (
	      usesLicenseRef(ast.left) ||
	      usesLicenseRef(ast.right)
	    );
	  }
	}

	validateNpmPackageLicense = function(argument) {
	  var ast;

	  try {
	    ast = parse(argument);
	  } catch (e) {
	    var match;
	    if (
	      argument === 'UNLICENSED' ||
	      argument === 'UNLICENCED'
	    ) {
	      return {
	        validForOldPackages: true,
	        validForNewPackages: true,
	        unlicensed: true
	      };
	    } else if (match = fileReferenceRE.exec(argument)) {
	      return {
	        validForOldPackages: true,
	        validForNewPackages: true,
	        inFile: match[1]
	      };
	    } else {
	      var result = {
	        validForOldPackages: false,
	        validForNewPackages: false,
	        warnings: [genericWarning]
	      };
	      if (argument.trim().length !== 0) {
	        var corrected = correct(argument);
	        if (corrected) {
	          result.warnings.push(
	            'license is similar to the valid expression "' + corrected + '"'
	          );
	        }
	      }
	      return result;
	    }
	  }

	  if (usesLicenseRef(ast)) {
	    return {
	      validForNewPackages: false,
	      validForOldPackages: false,
	      spdx: true,
	      warnings: [genericWarning]
	    };
	  } else {
	    return {
	      validForNewPackages: true,
	      validForOldPackages: true,
	      spdx: true
	    };
	  }
	};
	return validateNpmPackageLicense;
}

var normalizeData_1;
var hasRequiredNormalizeData;

function requireNormalizeData () {
	if (hasRequiredNormalizeData) return normalizeData_1;
	hasRequiredNormalizeData = 1;
	// Originally normalize-package-data

	const url = require$$0$2;
	const hostedGitInfo = requireLib$a();
	const validateLicense = requireValidateNpmPackageLicense();

	const typos = {
	  dependancies: 'dependencies',
	  dependecies: 'dependencies',
	  depdenencies: 'dependencies',
	  devEependencies: 'devDependencies',
	  depends: 'dependencies',
	  'dev-dependencies': 'devDependencies',
	  devDependences: 'devDependencies',
	  devDepenencies: 'devDependencies',
	  devdependencies: 'devDependencies',
	  repostitory: 'repository',
	  repo: 'repository',
	  prefereGlobal: 'preferGlobal',
	  hompage: 'homepage',
	  hampage: 'homepage',
	  autohr: 'author',
	  autor: 'author',
	  contributers: 'contributors',
	  publicationConfig: 'publishConfig',
	  script: 'scripts',
	};

	const isEmail = str => str.includes('@') && (str.indexOf('@') < str.lastIndexOf('.'));

	// Extracts description from contents of a readme file in markdown format
	function extractDescription (description) {
	  // the first block of text before the first heading that isn't the first line heading
	  const lines = description.trim().split('\n');
	  let start = 0;
	  // skip initial empty lines and lines that start with #
	  while (lines[start]?.trim().match(/^(#|$)/)) {
	    start++;
	  }
	  let end = start + 1;
	  // keep going till we get to the end or an empty line
	  while (end < lines.length && lines[end].trim()) {
	    end++;
	  }
	  return lines.slice(start, end).join(' ').trim()
	}

	function stringifyPerson (person) {
	  if (typeof person !== 'string') {
	    const name = person.name || '';
	    const u = person.url || person.web;
	    const wrappedUrl = u ? (' (' + u + ')') : '';
	    const e = person.email || person.mail;
	    const wrappedEmail = e ? (' <' + e + '>') : '';
	    person = name + wrappedEmail + wrappedUrl;
	  }
	  const matchedName = person.match(/^([^(<]+)/);
	  const matchedUrl = person.match(/\(([^()]+)\)/);
	  const matchedEmail = person.match(/<([^<>]+)>/);
	  const parsed = {};
	  if (matchedName?.[0].trim()) {
	    parsed.name = matchedName[0].trim();
	  }
	  if (matchedEmail) {
	    parsed.email = matchedEmail[1];
	  }
	  if (matchedUrl) {
	    parsed.url = matchedUrl[1];
	  }
	  return parsed
	}

	function normalizeData (data, changes) {
	  // fixDescriptionField
	  if (data.description && typeof data.description !== 'string') {
	    changes?.push(`'description' field should be a string`);
	    delete data.description;
	  }
	  if (data.readme && !data.description && data.readme !== 'ERROR: No README data found!') {
	    data.description = extractDescription(data.readme);
	  }
	  if (data.description === undefined) {
	    delete data.description;
	  }
	  if (!data.description) {
	    changes?.push('No description');
	  }

	  // fixModulesField
	  if (data.modules) {
	    changes?.push(`modules field is deprecated`);
	    delete data.modules;
	  }

	  // fixFilesField
	  const files = data.files;
	  if (files && !Array.isArray(files)) {
	    changes?.push(`Invalid 'files' member`);
	    delete data.files;
	  } else if (data.files) {
	    data.files = data.files.filter(function (file) {
	      if (!file || typeof file !== 'string') {
	        changes?.push(`Invalid filename in 'files' list: ${file}`);
	        return false
	      } else {
	        return true
	      }
	    });
	  }

	  // fixManField
	  if (data.man && typeof data.man === 'string') {
	    data.man = [data.man];
	  }

	  // fixBugsField
	  if (!data.bugs && data.repository?.url) {
	    const hosted = hostedGitInfo.fromUrl(data.repository.url);
	    if (hosted && hosted.bugs()) {
	      data.bugs = { url: hosted.bugs() };
	    }
	  } else if (data.bugs) {
	    if (typeof data.bugs === 'string') {
	      if (isEmail(data.bugs)) {
	        data.bugs = { email: data.bugs };
	        /* eslint-disable-next-line node/no-deprecated-api */
	      } else if (url.parse(data.bugs).protocol) {
	        data.bugs = { url: data.bugs };
	      } else {
	        changes?.push(`Bug string field must be url, email, or {email,url}`);
	      }
	    } else {
	      for (const k in data.bugs) {
	        if (['web', 'name'].includes(k)) {
	          changes?.push(`bugs['${k}'] should probably be bugs['url'].`);
	          data.bugs.url = data.bugs[k];
	          delete data.bugs[k];
	        }
	      }
	      const oldBugs = data.bugs;
	      data.bugs = {};
	      if (oldBugs.url) {
	        /* eslint-disable-next-line node/no-deprecated-api */
	        if (typeof (oldBugs.url) === 'string' && url.parse(oldBugs.url).protocol) {
	          data.bugs.url = oldBugs.url;
	        } else {
	          changes?.push('bugs.url field must be a string url. Deleted.');
	        }
	      }
	      if (oldBugs.email) {
	        if (typeof (oldBugs.email) === 'string' && isEmail(oldBugs.email)) {
	          data.bugs.email = oldBugs.email;
	        } else {
	          changes?.push('bugs.email field must be a string email. Deleted.');
	        }
	      }
	    }
	    if (!data.bugs.email && !data.bugs.url) {
	      delete data.bugs;
	      changes?.push('Normalized value of bugs field is an empty object. Deleted.');
	    }
	  }
	  // fixKeywordsField
	  if (typeof data.keywords === 'string') {
	    data.keywords = data.keywords.split(/,\s+/);
	  }
	  if (data.keywords && !Array.isArray(data.keywords)) {
	    delete data.keywords;
	    changes?.push(`keywords should be an array of strings`);
	  } else if (data.keywords) {
	    data.keywords = data.keywords.filter(function (kw) {
	      if (typeof kw !== 'string' || !kw) {
	        changes?.push(`keywords should be an array of strings`);
	        return false
	      } else {
	        return true
	      }
	    });
	  }
	  // fixBundleDependenciesField
	  const bdd = 'bundledDependencies';
	  const bd = 'bundleDependencies';
	  if (data[bdd] && !data[bd]) {
	    data[bd] = data[bdd];
	    delete data[bdd];
	  }
	  if (data[bd] && !Array.isArray(data[bd])) {
	    changes?.push(`Invalid 'bundleDependencies' list. Must be array of package names`);
	    delete data[bd];
	  } else if (data[bd]) {
	    data[bd] = data[bd].filter(function (filtered) {
	      if (!filtered || typeof filtered !== 'string') {
	        changes?.push(`Invalid bundleDependencies member: ${filtered}`);
	        return false
	      } else {
	        if (!data.dependencies) {
	          data.dependencies = {};
	        }
	        if (!Object.prototype.hasOwnProperty.call(data.dependencies, filtered)) {
	          changes?.push(`Non-dependency in bundleDependencies: ${filtered}`);
	          data.dependencies[filtered] = '*';
	        }
	        return true
	      }
	    });
	  }
	  // fixHomepageField
	  if (!data.homepage && data.repository && data.repository.url) {
	    const hosted = hostedGitInfo.fromUrl(data.repository.url);
	    if (hosted) {
	      data.homepage = hosted.docs();
	    }
	  }
	  if (data.homepage) {
	    if (typeof data.homepage !== 'string') {
	      changes?.push('homepage field must be a string url. Deleted.');
	      delete data.homepage;
	    } else {
	      /* eslint-disable-next-line node/no-deprecated-api */
	      if (!url.parse(data.homepage).protocol) {
	        data.homepage = 'http://' + data.homepage;
	      }
	    }
	  }
	  // fixReadmeField
	  if (!data.readme) {
	    changes?.push('No README data');
	    data.readme = 'ERROR: No README data found!';
	  }
	  // fixLicenseField
	  const license = data.license || data.licence;
	  if (!license) {
	    changes?.push('No license field.');
	  } else if (typeof (license) !== 'string' || license.length < 1 || license.trim() === '') {
	    changes?.push('license should be a valid SPDX license expression');
	  } else if (!validateLicense(license).validForNewPackages) {
	    changes?.push('license should be a valid SPDX license expression');
	  }
	  // fixPeople
	  if (data.author) {
	    data.author = stringifyPerson(data.author);
	  }
	  ['maintainers', 'contributors'].forEach(function (set) {
	    if (!Array.isArray(data[set])) {
	      return
	    }
	    data[set] = data[set].map(stringifyPerson);
	  });
	  // fixTypos
	  for (const d in typos) {
	    if (Object.prototype.hasOwnProperty.call(data, d)) {
	      changes?.push(`${d} should probably be ${typos[d]}.`);
	    }
	  }
	}

	normalizeData_1 = { normalizeData };
	return normalizeData_1;
}

var normalize_1;
var hasRequiredNormalize;

function requireNormalize () {
	if (hasRequiredNormalize) return normalize_1;
	hasRequiredNormalize = 1;
	const valid = requireValid();
	const clean = requireClean();
	const fs = require$$5;
	const path = require$$2$2;
	const { log } = requireLib$d();
	const moduleBuiltin = require$$5$1;

	/**
	 * @type {import('hosted-git-info')}
	 */
	let _hostedGitInfo;
	function lazyHostedGitInfo () {
	  if (!_hostedGitInfo) {
	    _hostedGitInfo = requireLib$a();
	  }
	  return _hostedGitInfo
	}

	/**
	 * @type {import('glob').glob}
	 */
	let _glob;
	function lazyLoadGlob () {
	  if (!_glob) {
	    _glob = requireCommonjs().glob;
	  }
	  return _glob
	}

	// used to be npm-normalize-package-bin
	function normalizePackageBin (pkg, changes) {
	  if (pkg.bin) {
	    if (typeof pkg.bin === 'string' && pkg.name) {
	      changes?.push('"bin" was converted to an object');
	      pkg.bin = { [pkg.name]: pkg.bin };
	    } else if (Array.isArray(pkg.bin)) {
	      changes?.push('"bin" was converted to an object');
	      pkg.bin = pkg.bin.reduce((acc, k) => {
	        acc[path.basename(k)] = k;
	        return acc
	      }, {});
	    }
	    if (typeof pkg.bin === 'object') {
	      for (const binKey in pkg.bin) {
	        if (typeof pkg.bin[binKey] !== 'string') {
	          delete pkg.bin[binKey];
	          changes?.push(`removed invalid "bin[${binKey}]"`);
	          continue
	        }
	        const base = path.basename(secureAndUnixifyPath(binKey));
	        if (!base) {
	          delete pkg.bin[binKey];
	          changes?.push(`removed invalid "bin[${binKey}]"`);
	          continue
	        }

	        const binTarget = secureAndUnixifyPath(pkg.bin[binKey]);

	        if (!binTarget) {
	          delete pkg.bin[binKey];
	          changes?.push(`removed invalid "bin[${binKey}]"`);
	          continue
	        }

	        if (base !== binKey) {
	          delete pkg.bin[binKey];
	          changes?.push(`"bin[${binKey}]" was renamed to "bin[${base}]"`);
	        }
	        if (binTarget !== pkg.bin[binKey]) {
	          changes?.push(`"bin[${base}]" script name was cleaned`);
	        }
	        pkg.bin[base] = binTarget;
	      }

	      if (Object.keys(pkg.bin).length === 0) {
	        changes?.push('empty "bin" was removed');
	        delete pkg.bin;
	      }

	      return pkg
	    }
	  }
	  delete pkg.bin;
	}

	function normalizePackageMan (pkg, changes) {
	  if (pkg.man) {
	    const mans = [];
	    for (const man of (Array.isArray(pkg.man) ? pkg.man : [pkg.man])) {
	      if (typeof man !== 'string') {
	        changes?.push(`removed invalid "man [${man}]"`);
	      } else {
	        mans.push(secureAndUnixifyPath(man));
	      }
	    }

	    if (!mans.length) {
	      changes?.push('empty "man" was removed');
	    } else {
	      pkg.man = mans;
	      return pkg
	    }
	  }
	  delete pkg.man;
	}

	function isCorrectlyEncodedName (spec) {
	  return !spec.match(/[/@\s+%:]/) &&
	    spec === encodeURIComponent(spec)
	}

	function isValidScopedPackageName (spec) {
	  if (spec.charAt(0) !== '@') {
	    return false
	  }

	  const rest = spec.slice(1).split('/');
	  if (rest.length !== 2) {
	    return false
	  }

	  return rest[0] && rest[1] &&
	    rest[0] === encodeURIComponent(rest[0]) &&
	    rest[1] === encodeURIComponent(rest[1])
	}

	function unixifyPath (ref) {
	  return ref.replace(/\\|:/g, '/')
	}

	function secureAndUnixifyPath (ref) {
	  const secured = unixifyPath(path.join('.', path.join('/', unixifyPath(ref))));
	  return secured.startsWith('./') ? '' : secured
	}

	// We don't want the `changes` array in here by default because this is a hot
	// path for parsing packuments during install.  So the calling method passes it
	// in if it wants to track changes.
	const normalize = async (pkg, { strict, steps, root, changes, allowLegacyCase }) => {
	  if (!pkg.content) {
	    throw new Error('Can not normalize without content')
	  }
	  const data = pkg.content;
	  const scripts = data.scripts || {};
	  const pkgId = `${data.name ?? ''}@${data.version ?? ''}`;

	  // name and version are load bearing so we have to clean them up first
	  if (steps.includes('fixName') || steps.includes('fixNameField') || steps.includes('normalizeData')) {
	    if (!data.name && !strict) {
	      changes?.push('Missing "name" field was set to an empty string');
	      data.name = '';
	    } else {
	      if (typeof data.name !== 'string') {
	        throw new Error('name field must be a string.')
	      }
	      if (!strict) {
	        const name = data.name.trim();
	        if (data.name !== name) {
	          changes?.push(`Whitespace was trimmed from "name"`);
	          data.name = name;
	        }
	      }

	      if (data.name.startsWith('.') ||
	        !(isValidScopedPackageName(data.name) || isCorrectlyEncodedName(data.name)) ||
	        (strict && (!allowLegacyCase) && data.name !== data.name.toLowerCase()) ||
	        data.name.toLowerCase() === 'node_modules' ||
	        data.name.toLowerCase() === 'favicon.ico') {
	        throw new Error('Invalid name: ' + JSON.stringify(data.name))
	      }
	    }
	  }

	  if (steps.includes('fixName')) {
	    // Check for conflicts with builtin modules
	    if (moduleBuiltin.builtinModules.includes(data.name)) {
	      log.warn('package-json', pkgId, `Package name "${data.name}" conflicts with a Node.js built-in module name`);
	    }
	  }

	  if (steps.includes('fixVersionField') || steps.includes('normalizeData')) {
	    // allow "loose" semver 1.0 versions in non-strict mode
	    // enforce strict semver 2.0 compliance in strict mode
	    const loose = !strict;
	    if (!data.version) {
	      data.version = '';
	    } else {
	      if (!valid(data.version, loose)) {
	        throw new Error(`Invalid version: "${data.version}"`)
	      }
	      const version = clean(data.version, loose);
	      if (version !== data.version) {
	        changes?.push(`"version" was cleaned and set to "${version}"`);
	        data.version = version;
	      }
	    }
	  }
	  // remove attributes that start with "_"
	  if (steps.includes('_attributes')) {
	    for (const key in data) {
	      if (key.startsWith('_')) {
	        changes?.push(`"${key}" was removed`);
	        delete pkg.content[key];
	      }
	    }
	  }

	  // build the "_id" attribute
	  if (steps.includes('_id')) {
	    if (data.name && data.version) {
	      changes?.push(`"_id" was set to ${pkgId}`);
	      data._id = pkgId;
	    }
	  }

	  // fix bundledDependencies typo
	  // normalize bundleDependencies
	  if (steps.includes('bundledDependencies')) {
	    if (data.bundleDependencies === undefined && data.bundledDependencies !== undefined) {
	      data.bundleDependencies = data.bundledDependencies;
	    }
	    changes?.push(`Deleted incorrect "bundledDependencies"`);
	    delete data.bundledDependencies;
	  }
	  // expand "bundleDependencies: true or translate from object"
	  if (steps.includes('bundleDependencies')) {
	    const bd = data.bundleDependencies;
	    if (bd === false && !steps.includes('bundleDependenciesDeleteFalse')) {
	      changes?.push(`"bundleDependencies" was changed from "false" to "[]"`);
	      data.bundleDependencies = [];
	    } else if (bd === true) {
	      changes?.push(`"bundleDependencies" was auto-populated from "dependencies"`);
	      data.bundleDependencies = Object.keys(data.dependencies || {});
	    } else if (bd && typeof bd === 'object') {
	      if (!Array.isArray(bd)) {
	        changes?.push(`"bundleDependencies" was changed from an object to an array`);
	        data.bundleDependencies = Object.keys(bd);
	      }
	    } else if ('bundleDependencies' in data) {
	      changes?.push(`"bundleDependencies" was removed`);
	      delete data.bundleDependencies;
	    }
	  }

	  // it was once common practice to list deps both in optionalDependencies and
	  // in dependencies, to support npm versions that did not know about
	  // optionalDependencies.  This is no longer a relevant need, so duplicating
	  // the deps in two places is unnecessary and excessive.
	  if (steps.includes('optionalDedupe')) {
	    if (data.dependencies &&
	      data.optionalDependencies && typeof data.optionalDependencies === 'object') {
	      for (const name in data.optionalDependencies) {
	        changes?.push(`optionalDependencies."${name}" was removed`);
	        delete data.dependencies[name];
	      }
	      if (!Object.keys(data.dependencies).length) {
	        changes?.push(`Empty "optionalDependencies" was removed`);
	        delete data.dependencies;
	      }
	    }
	  }

	  // add "install" attribute if any "*.gyp" files exist
	  if (steps.includes('gypfile')) {
	    if (!scripts.install && !scripts.preinstall && data.gypfile !== false) {
	      const files = await lazyLoadGlob()('*.gyp', { cwd: pkg.path });
	      if (files.length) {
	        scripts.install = 'node-gyp rebuild';
	        data.scripts = scripts;
	        data.gypfile = true;
	        changes?.push(`"scripts.install" was set to "node-gyp rebuild"`);
	        changes?.push(`"gypfile" was set to "true"`);
	      }
	    }
	  }

	  // add "start" attribute if "server.js" exists
	  if (steps.includes('serverjs') && !scripts.start) {
	    try {
	      await fs.access(path.join(pkg.path, 'server.js'));
	      scripts.start = 'node server.js';
	      data.scripts = scripts;
	      changes?.push('"scripts.start" was set to "node server.js"');
	    } catch {
	      // do nothing
	    }
	  }

	  // strip "node_modules/.bin" from scripts entries
	  // remove invalid scripts entries (non-strings)
	  if ((steps.includes('scripts') || steps.includes('scriptpath')) && data.scripts !== undefined) {
	    const spre = /^(\.[/\\])?node_modules[/\\].bin[\\/]/;
	    if (typeof data.scripts === 'object') {
	      for (const name in data.scripts) {
	        if (typeof data.scripts[name] !== 'string') {
	          delete data.scripts[name];
	          changes?.push(`Invalid scripts."${name}" was removed`);
	        } else if (steps.includes('scriptpath') && spre.test(data.scripts[name])) {
	          data.scripts[name] = data.scripts[name].replace(spre, '');
	          changes?.push(`scripts entry "${name}" was fixed to remove node_modules/.bin reference`);
	        }
	      }
	    } else {
	      changes?.push(`Removed invalid "scripts"`);
	      delete data.scripts;
	    }
	  }

	  if (steps.includes('funding')) {
	    if (data.funding && typeof data.funding === 'string') {
	      data.funding = { url: data.funding };
	      changes?.push(`"funding" was changed to an object with a url attribute`);
	    }
	  }

	  // populate "authors" attribute
	  if (steps.includes('authors') && !data.contributors) {
	    try {
	      const authorData = await fs.readFile(path.join(pkg.path, 'AUTHORS'), 'utf8');
	      const authors = authorData.split(/\r?\n/g)
	        .map(line => line.replace(/^\s*#.*$/, '').trim())
	        .filter(line => line);
	      data.contributors = authors;
	      changes?.push('"contributors" was auto-populated with the contents of the "AUTHORS" file');
	    } catch {
	      // do nothing
	    }
	  }

	  // populate "readme" attribute
	  if (steps.includes('readme') && !data.readme) {
	    const mdre = /\.m?a?r?k?d?o?w?n?$/i;
	    const files = await lazyLoadGlob()('{README,README.*}', {
	      cwd: pkg.path,
	      nocase: true,
	      mark: true,
	    });
	    let readmeFile;
	    for (const file of files) {
	      // don't accept directories.
	      if (!file.endsWith(path.sep)) {
	        if (file.match(mdre)) {
	          readmeFile = file;
	          break
	        }
	        if (file.endsWith('README')) {
	          readmeFile = file;
	        }
	      }
	    }
	    if (readmeFile) {
	      const readmeData = await fs.readFile(path.join(pkg.path, readmeFile), 'utf8');
	      data.readme = readmeData;
	      data.readmeFilename = readmeFile;
	      changes?.push(`"readme" was set to the contents of ${readmeFile}`);
	      changes?.push(`"readmeFilename" was set to ${readmeFile}`);
	    }
	    if (!data.readme) {
	      data.readme = 'ERROR: No README data found!';
	    }
	  }

	  // expand directories.man
	  if (steps.includes('mans')) {
	    if (data.directories?.man && !data.man) {
	      const manDir = secureAndUnixifyPath(data.directories.man);
	      const cwd = path.resolve(pkg.path, manDir);
	      const files = await lazyLoadGlob()('**/*.[0-9]', { cwd });
	      data.man = files.map(man =>
	        path.relative(pkg.path, path.join(cwd, man)).split(path.sep).join('/')
	      );
	    }
	    normalizePackageMan(data, changes);
	  }

	  if (steps.includes('bin') || steps.includes('binDir') || steps.includes('binRefs')) {
	    normalizePackageBin(data, changes);
	  }

	  // expand "directories.bin"
	  if (steps.includes('binDir') && data.directories?.bin && !data.bin) {
	    const binsDir = path.resolve(pkg.path, secureAndUnixifyPath(data.directories.bin));
	    const bins = await lazyLoadGlob()('**', { cwd: binsDir });
	    data.bin = bins.reduce((acc, binFile) => {
	      if (binFile && !binFile.startsWith('.')) {
	        const binName = path.basename(binFile);
	        acc[binName] = path.join(data.directories.bin, binFile);
	      }
	      return acc
	    }, {});
	    // *sigh*
	    normalizePackageBin(data, changes);
	  }

	  // populate "gitHead" attribute
	  if (steps.includes('gitHead') && !data.gitHead) {
	    const git = requireLib$4();
	    const gitRoot = await git.find({ cwd: pkg.path, root });
	    let head;
	    if (gitRoot) {
	      try {
	        head = await fs.readFile(path.resolve(gitRoot, '.git/HEAD'), 'utf8');
	      } catch (err) {
	      // do nothing
	      }
	    }
	    let headData;
	    if (head) {
	      if (head.startsWith('ref: ')) {
	        const headRef = head.replace(/^ref: /, '').trim();
	        const headFile = path.resolve(gitRoot, '.git', headRef);
	        try {
	          headData = await fs.readFile(headFile, 'utf8');
	          headData = headData.replace(/^ref: /, '').trim();
	        } catch (err) {
	          // do nothing
	        }
	        if (!headData) {
	          const packFile = path.resolve(gitRoot, '.git/packed-refs');
	          try {
	            let refs = await fs.readFile(packFile, 'utf8');
	            if (refs) {
	              refs = refs.split('\n');
	              for (let i = 0; i < refs.length; i++) {
	                const match = refs[i].match(/^([0-9a-f]{40}) (.+)$/);
	                if (match && match[2].trim() === headRef) {
	                  headData = match[1];
	                  break
	                }
	              }
	            }
	          } catch {
	            // do nothing
	          }
	        }
	      } else {
	        headData = head.trim();
	      }
	    }
	    if (headData) {
	      data.gitHead = headData;
	    }
	  }

	  // populate "types" attribute
	  if (steps.includes('fillTypes')) {
	    const index = data.main || 'index.js';

	    if (typeof index !== 'string') {
	      throw new TypeError('The "main" attribute must be of type string.')
	    }

	    // TODO exports is much more complicated than this in verbose format
	    // We need to support for instance

	    // "exports": {
	    //   ".": [
	    //     {
	    //       "default": "./lib/npm.js"
	    //     },
	    //     "./lib/npm.js"
	    //   ],
	    //   "./package.json": "./package.json"
	    // },
	    // as well as conditional exports

	    // if (data.exports && typeof data.exports === 'string') {
	    //   index = data.exports
	    // }

	    // if (data.exports && data.exports['.']) {
	    //   index = data.exports['.']
	    //   if (typeof index !== 'string') {
	    //   }
	    // }
	    const extless = path.join(path.dirname(index), path.basename(index, path.extname(index)));
	    const dts = `./${extless}.d.ts`;
	    const hasDTSFields = 'types' in data || 'typings' in data;
	    if (!hasDTSFields) {
	      try {
	        await fs.access(path.join(pkg.path, dts));
	        data.types = dts.split(path.sep).join('/');
	      } catch {
	        // do nothing
	      }
	    }
	  }

	  // "normalizeData" from "read-package-json", which was just a call through to
	  // "normalize-package-data".  We only call the "fixer" functions because
	  // outside of that it was also clobbering _id (which we already conditionally
	  // do) and also adding the gypfile script (which we also already
	  // conditionally do)

	  // Some steps are isolated so we can do a limited subset of these in `fix`
	  if (steps.includes('fixRepositoryField') || steps.includes('normalizeData')) {
	    if (data.repositories) {
	      changes?.push(`"repository" was set to the first entry in "repositories" (${data.repository})`);
	      data.repository = data.repositories[0];
	    }
	    if (data.repository) {
	      if (typeof data.repository === 'string') {
	        changes?.push('"repository" was changed from a string to an object');
	        data.repository = {
	          type: 'git',
	          url: data.repository,
	        };
	      }
	      if (data.repository.url) {
	        const hosted = lazyHostedGitInfo().fromUrl(data.repository.url);
	        let r;
	        if (hosted) {
	          if (hosted.getDefaultRepresentation() === 'shortcut') {
	            r = hosted.https();
	          } else {
	            r = hosted.toString();
	          }
	          if (r !== data.repository.url) {
	            changes?.push(`"repository.url" was normalized to "${r}"`);
	            data.repository.url = r;
	          }
	        }
	      }
	    }
	  }

	  if (steps.includes('fixDependencies') || steps.includes('normalizeData')) {
	    // peerDependencies?
	    // devDependencies is meaningless here, it's ignored on an installed package
	    for (const type of ['dependencies', 'devDependencies', 'optionalDependencies']) {
	      if (data[type]) {
	        let secondWarning = true;
	        if (typeof data[type] === 'string') {
	          changes?.push(`"${type}" was converted from a string into an object`);
	          data[type] = data[type].trim().split(/[\n\r\s\t ,]+/);
	          secondWarning = false;
	        }
	        if (Array.isArray(data[type])) {
	          if (secondWarning) {
	            changes?.push(`"${type}" was converted from an array into an object`);
	          }
	          const o = {};
	          for (const d of data[type]) {
	            if (typeof d === 'string') {
	              const dep = d.trim().split(/(:?[@\s><=])/);
	              const dn = dep.shift();
	              const dv = dep.join('').replace(/^@/, '').trim();
	              o[dn] = dv;
	            }
	          }
	          data[type] = o;
	        }
	      }
	    }
	    // normalize-package-data used to put optional dependencies BACK into
	    // dependencies here, we no longer do this

	    for (const deps of ['dependencies', 'devDependencies']) {
	      if (deps in data) {
	        if (!data[deps] || typeof data[deps] !== 'object') {
	          changes?.push(`Removed invalid "${deps}"`);
	          delete data[deps];
	        } else {
	          for (const d in data[deps]) {
	            const r = data[deps][d];
	            if (typeof r !== 'string') {
	              changes?.push(`Removed invalid "${deps}.${d}"`);
	              delete data[deps][d];
	            }
	            const hosted = lazyHostedGitInfo().fromUrl(data[deps][d])?.toString();
	            if (hosted && hosted !== data[deps][d]) {
	              changes?.push(`Normalized git reference to "${deps}.${d}"`);
	              data[deps][d] = hosted.toString();
	            }
	          }
	        }
	      }
	    }
	  }

	  // TODO some of this is duplicated in other steps here, a future breaking change may be able to remove the duplicates involved in this step
	  if (steps.includes('normalizeData')) {
	    const { normalizeData } = requireNormalizeData();
	    normalizeData(data, changes);
	  }

	  // Warn if the bin references don't point to anything.  This might be better
	  // in normalize-package-data if it had access to the file path.
	  if (steps.includes('binRefs') && data.bin instanceof Object) {
	    for (const key in data.bin) {
	      try {
	        await fs.access(path.resolve(pkg.path, data.bin[key]));
	      } catch {
	        log.warn('package-json', pkgId, `No bin file found at ${data.bin[key]}`);
	        // XXX: should a future breaking change delete bin entries that cannot be accessed?
	      }
	    }
	  }
	};

	normalize_1 = normalize;
	return normalize_1;
}

var readPackage_1;
var hasRequiredReadPackage;

function requireReadPackage () {
	if (hasRequiredReadPackage) return readPackage_1;
	hasRequiredReadPackage = 1;
	// This is JUST the code needed to open a package.json file and parse it.
	// It's isolated out so that code needing to parse a package.json file can do so in the same way as this module does, without needing to require the whole module, or needing to require the underlying parsing library.

	const { readFile } = require$$0$4;
	const parseJSON = requireLib$b();

	async function read (filename) {
	  try {
	    const data = await readFile(filename, 'utf8');
	    return data
	  } catch (err) {
	    err.message = `Could not read package.json: ${err}`;
	    throw err
	  }
	}

	function parse (data) {
	  try {
	    const content = parseJSON(data);
	    return content
	  } catch (err) {
	    err.message = `Invalid package.json: ${err}`;
	    throw err
	  }
	}

	// This is what most external libs will use.
	// PackageJson will call read and parse separately
	async function readPackage (filename) {
	  const data = await read(filename);
	  const content = parse(data);
	  return content
	}

	readPackage_1 = {
	  read,
	  parse,
	  readPackage,
	};
	return readPackage_1;
}

/**
 * arbitrary sort order for package.json largely pulled from:
 * https://github.com/keithamus/sort-package-json/blob/main/defaultRules.md
 *
 * cross checked with:
 * https://github.com/npm/types/blob/main/types/index.d.ts#L104
 * https://docs.npmjs.com/cli/configuring-npm/package-json
 */

var sort;
var hasRequiredSort;

function requireSort () {
	if (hasRequiredSort) return sort;
	hasRequiredSort = 1;
	function packageSort (json) {
	  const {
	    name,
	    version,
	    private: isPrivate,
	    description,
	    keywords,
	    homepage,
	    bugs,
	    repository,
	    funding,
	    license,
	    author,
	    maintainers,
	    contributors,
	    type,
	    imports,
	    exports,
	    main,
	    browser,
	    types,
	    bin,
	    man,
	    directories,
	    files,
	    workspaces,
	    scripts,
	    config,
	    dependencies,
	    devDependencies,
	    peerDependencies,
	    peerDependenciesMeta,
	    optionalDependencies,
	    bundledDependencies,
	    bundleDependencies,
	    engines,
	    os,
	    cpu,
	    publishConfig,
	    devEngines,
	    licenses,
	    overrides,
	    ...rest
	  } = json;

	  return {
	    ...(typeof name !== 'undefined' ? { name } : {}),
	    ...(typeof version !== 'undefined' ? { version } : {}),
	    ...(typeof isPrivate !== 'undefined' ? { private: isPrivate } : {}),
	    ...(typeof description !== 'undefined' ? { description } : {}),
	    ...(typeof keywords !== 'undefined' ? { keywords } : {}),
	    ...(typeof homepage !== 'undefined' ? { homepage } : {}),
	    ...(typeof bugs !== 'undefined' ? { bugs } : {}),
	    ...(typeof repository !== 'undefined' ? { repository } : {}),
	    ...(typeof funding !== 'undefined' ? { funding } : {}),
	    ...(typeof license !== 'undefined' ? { license } : {}),
	    ...(typeof author !== 'undefined' ? { author } : {}),
	    ...(typeof maintainers !== 'undefined' ? { maintainers } : {}),
	    ...(typeof contributors !== 'undefined' ? { contributors } : {}),
	    ...(typeof type !== 'undefined' ? { type } : {}),
	    ...(typeof imports !== 'undefined' ? { imports } : {}),
	    ...(typeof exports !== 'undefined' ? { exports } : {}),
	    ...(typeof main !== 'undefined' ? { main } : {}),
	    ...(typeof browser !== 'undefined' ? { browser } : {}),
	    ...(typeof types !== 'undefined' ? { types } : {}),
	    ...(typeof bin !== 'undefined' ? { bin } : {}),
	    ...(typeof man !== 'undefined' ? { man } : {}),
	    ...(typeof directories !== 'undefined' ? { directories } : {}),
	    ...(typeof files !== 'undefined' ? { files } : {}),
	    ...(typeof workspaces !== 'undefined' ? { workspaces } : {}),
	    ...(typeof scripts !== 'undefined' ? { scripts } : {}),
	    ...(typeof config !== 'undefined' ? { config } : {}),
	    ...(typeof dependencies !== 'undefined' ? { dependencies } : {}),
	    ...(typeof devDependencies !== 'undefined' ? { devDependencies } : {}),
	    ...(typeof peerDependencies !== 'undefined' ? { peerDependencies } : {}),
	    ...(typeof peerDependenciesMeta !== 'undefined' ? { peerDependenciesMeta } : {}),
	    ...(typeof optionalDependencies !== 'undefined' ? { optionalDependencies } : {}),
	    ...(typeof bundledDependencies !== 'undefined' ? { bundledDependencies } : {}),
	    ...(typeof bundleDependencies !== 'undefined' ? { bundleDependencies } : {}),
	    ...(typeof engines !== 'undefined' ? { engines } : {}),
	    ...(typeof os !== 'undefined' ? { os } : {}),
	    ...(typeof cpu !== 'undefined' ? { cpu } : {}),
	    ...(typeof publishConfig !== 'undefined' ? { publishConfig } : {}),
	    ...(typeof devEngines !== 'undefined' ? { devEngines } : {}),
	    ...(typeof licenses !== 'undefined' ? { licenses } : {}),
	    ...(typeof overrides !== 'undefined' ? { overrides } : {}),
	    ...rest,
	  }
	}

	sort = {
	  packageSort,
	};
	return sort;
}

var lib$3;
var hasRequiredLib$3;

function requireLib$3 () {
	if (hasRequiredLib$3) return lib$3;
	hasRequiredLib$3 = 1;
	const { readFile, writeFile } = require$$5;
	const { resolve } = require$$2$2;
	const parseJSON = requireLib$b();

	const updateDeps = requireUpdateDependencies();
	const updateScripts = requireUpdateScripts();
	const updateWorkspaces = requireUpdateWorkspaces();
	const normalize = requireNormalize();
	const { read, parse } = requireReadPackage();
	const { packageSort } = requireSort();

	// a list of handy specialized helper functions that take
	// care of special cases that are handled by the npm cli
	const knownSteps = new Set([
	  updateDeps,
	  updateScripts,
	  updateWorkspaces,
	]);

	// list of all keys that are handled by "knownSteps" helpers
	const knownKeys = new Set([
	  ...updateDeps.knownKeys,
	  'scripts',
	  'workspaces',
	]);

	class PackageJson {
	  static normalizeSteps = Object.freeze([
	    '_id',
	    '_attributes',
	    'bundledDependencies',
	    'bundleDependencies',
	    'optionalDedupe',
	    'scripts',
	    'funding',
	    'bin',
	  ])

	  // npm pkg fix
	  static fixSteps = Object.freeze([
	    'binRefs',
	    'bundleDependencies',
	    'bundleDependenciesFalse',
	    'fixName',
	    'fixNameField',
	    'fixVersionField',
	    'fixRepositoryField',
	    'fixDependencies',
	    'devDependencies',
	    'scriptpath',
	  ])

	  static prepareSteps = Object.freeze([
	    '_id',
	    '_attributes',
	    'bundledDependencies',
	    'bundleDependencies',
	    'bundleDependenciesDeleteFalse',
	    'gypfile',
	    'serverjs',
	    'scriptpath',
	    'authors',
	    'readme',
	    'mans',
	    'binDir',
	    'gitHead',
	    'fillTypes',
	    'normalizeData',
	    'binRefs',
	  ])

	  // create a new empty package.json, so we can save at the given path even
	  // though we didn't start from a parsed file
	  static async create (path, opts = {}) {
	    const p = new PackageJson();
	    await p.create(path);
	    if (opts.data) {
	      return p.update(opts.data)
	    }
	    return p
	  }

	  // Loads a package.json at given path and JSON parses
	  static async load (path, opts = {}) {
	    const p = new PackageJson();
	    // Avoid try/catch if we aren't going to create
	    if (!opts.create) {
	      return p.load(path)
	    }

	    try {
	      return await p.load(path)
	    } catch (err) {
	      if (!err.message.startsWith('Could not read package.json')) {
	        throw err
	      }
	      return await p.create(path)
	    }
	  }

	  // npm pkg fix
	  static async fix (path, opts) {
	    const p = new PackageJson();
	    await p.load(path, true);
	    return p.fix(opts)
	  }

	  // read-package-json compatible behavior
	  static async prepare (path, opts) {
	    const p = new PackageJson();
	    await p.load(path, true);
	    return p.prepare(opts)
	  }

	  // read-package-json-fast compatible behavior
	  static async normalize (path, opts) {
	    const p = new PackageJson();
	    await p.load(path);
	    return p.normalize(opts)
	  }

	  #path
	  #manifest
	  #readFileContent = ''
	  #canSave = true

	  // Load content from given path
	  async load (path, parseIndex) {
	    this.#path = path;
	    let parseErr;
	    try {
	      this.#readFileContent = await read(this.filename);
	    } catch (err) {
	      if (!parseIndex) {
	        throw err
	      }
	      parseErr = err;
	    }

	    if (parseErr) {
	      const indexFile = resolve(this.path, 'index.js');
	      let indexFileContent;
	      try {
	        indexFileContent = await readFile(indexFile, 'utf8');
	      } catch (err) {
	        throw parseErr
	      }
	      try {
	        this.fromComment(indexFileContent);
	      } catch (err) {
	        throw parseErr
	      }
	      // This wasn't a package.json so prevent saving
	      this.#canSave = false;
	      return this
	    }

	    return this.fromJSON(this.#readFileContent)
	  }

	  // Load data from a JSON string/buffer
	  fromJSON (data) {
	    this.#manifest = parse(data);
	    return this
	  }

	  fromContent (data) {
	    this.#manifest = data;
	    this.#canSave = false;
	    return this
	  }

	  // Load data from a comment
	  // /**package { "name": "foo", "version": "1.2.3", ... } **/
	  fromComment (data) {
	    data = data.split(/^\/\*\*package(?:\s|$)/m);

	    if (data.length < 2) {
	      throw new Error('File has no package in comments')
	    }
	    data = data[1];
	    data = data.split(/\*\*\/$/m);

	    if (data.length < 2) {
	      throw new Error('File has no package in comments')
	    }
	    data = data[0];
	    data = data.replace(/^\s*\*/mg, '');

	    this.#manifest = parseJSON(data);
	    return this
	  }

	  get content () {
	    return this.#manifest
	  }

	  get path () {
	    return this.#path
	  }

	  get filename () {
	    if (this.path) {
	      return resolve(this.path, 'package.json')
	    }
	    return undefined
	  }

	  create (path) {
	    this.#path = path;
	    this.#manifest = {};
	    return this
	  }

	  // This should be the ONLY way to set content in the manifest
	  update (content) {
	    if (!this.content) {
	      throw new Error('Can not update without content.  Please `load` or `create`')
	    }

	    for (const step of knownSteps) {
	      this.#manifest = step({ content, originalContent: this.content });
	    }

	    // unknown properties will just be overwitten
	    for (const [key, value] of Object.entries(content)) {
	      if (!knownKeys.has(key)) {
	        this.content[key] = value;
	      }
	    }

	    return this
	  }

	  async save ({ sort } = {}) {
	    if (!this.#canSave) {
	      throw new Error('No package.json to save to')
	    }
	    const {
	      [Symbol.for('indent')]: indent,
	      [Symbol.for('newline')]: newline,
	      ...rest
	    } = this.content;

	    const format = indent === undefined ? '  ' : indent;
	    const eol = newline === undefined ? '\n' : newline;

	    const content = sort ? packageSort(rest) : rest;

	    const fileContent = `${
	      JSON.stringify(content, null, format)
	    }\n`
	      .replace(/\n/g, eol);

	    if (fileContent.trim() !== this.#readFileContent.trim()) {
	      const written = await writeFile(this.filename, fileContent);
	      this.#readFileContent = fileContent;
	      return written
	    }
	  }

	  async normalize (opts = {}) {
	    if (!opts.steps) {
	      opts.steps = this.constructor.normalizeSteps;
	    }
	    await normalize(this, opts);
	    return this
	  }

	  async prepare (opts = {}) {
	    if (!opts.steps) {
	      opts.steps = this.constructor.prepareSteps;
	    }
	    await normalize(this, opts);
	    return this
	  }

	  async fix (opts = {}) {
	    // This one is not overridable
	    opts.steps = this.constructor.fixSteps;
	    await normalize(this, opts);
	    return this
	  }
	}

	lib$3 = PackageJson;
	return lib$3;
}

var lib$2;
var hasRequiredLib$2;

function requireLib$2 () {
	if (hasRequiredLib$2) return lib$2;
	hasRequiredLib$2 = 1;
	const { basename, dirname } = require$$0;

	const getName = (parent, base) =>
	  parent.charAt(0) === '@' ? `${parent}/${base}` : base;

	lib$2 = dir => dir ? getName(basename(dirname(dir)), basename(dir))
	  : false;
	return lib$2;
}

var lib$1;
var hasRequiredLib$1;

function requireLib$1 () {
	if (hasRequiredLib$1) return lib$1;
	hasRequiredLib$1 = 1;
	const path = require$$0;

	const getName = requireLib$2();
	const { minimatch } = requireCommonjs$2();
	const pkgJson = requireLib$3();
	const { glob } = requireCommonjs();

	function appendNegatedPatterns (allPatterns) {
	  const patterns = [];
	  const negatedPatterns = [];
	  for (let pattern of allPatterns) {
	    const excl = pattern.match(/^!+/);
	    if (excl) {
	      pattern = pattern.slice(excl[0].length);
	    }

	    // strip off any / or ./ from the start of the pattern.  /foo => foo
	    pattern = pattern.replace(/^\.?\/+/, '');

	    // an odd number of ! means a negated pattern.  !!foo ==> foo
	    const negate = excl && excl[0].length % 2 === 1;
	    if (negate) {
	      negatedPatterns.push(pattern);
	    } else {
	      // remove negated patterns that appeared before this pattern to avoid
	      // ignoring paths that were matched afterwards
	      // e.g: ['packages/**', '!packages/b/**', 'packages/b/a']
	      // in the above list, the last pattern overrides the negated pattern
	      // right before it. In effect, the above list would become:
	      // ['packages/**', 'packages/b/a']
	      // The order matters here which is why we must do it inside the loop
	      // as opposed to doing it all together at the end.
	      for (let i = 0; i < negatedPatterns.length; ++i) {
	        const negatedPattern = negatedPatterns[i];
	        if (minimatch(pattern, negatedPattern)) {
	          negatedPatterns.splice(i, 1);
	        }
	      }
	      patterns.push(pattern);
	    }
	  }

	  // use the negated patterns to eagerly remove all the patterns that
	  // can be removed to avoid unnecessary crawling
	  for (const negated of negatedPatterns) {
	    for (const pattern of minimatch.match(patterns, negated)) {
	      patterns.splice(patterns.indexOf(pattern), 1);
	    }
	  }
	  return { patterns, negatedPatterns }
	}

	function getPatterns (workspaces) {
	  const workspacesDeclaration =
	    Array.isArray(workspaces.packages)
	      ? workspaces.packages
	      : workspaces;

	  if (!Array.isArray(workspacesDeclaration)) {
	    throw getError({
	      message: 'workspaces config expects an Array',
	      code: 'EWORKSPACESCONFIG',
	    })
	  }

	  return appendNegatedPatterns(workspacesDeclaration)
	}

	function getPackageName (pkg, pathname) {
	  return pkg.name || getName(pathname)
	}

	// make sure glob pattern only matches folders
	function getGlobPattern (pattern) {
	  pattern = pattern.replace(/\\/g, '/');
	  return pattern.endsWith('/')
	    ? pattern
	    : `${pattern}/`
	}

	function getError ({ Type = TypeError, message, code }) {
	  return Object.assign(new Type(message), { code })
	}

	function reverseResultMap (map) {
	  return new Map(Array.from(map, item => item.reverse()))
	}

	async function mapWorkspaces (opts = {}) {
	  if (!opts || !opts.pkg) {
	    throw getError({
	      message: 'mapWorkspaces missing pkg info',
	      code: 'EMAPWORKSPACESPKG',
	    })
	  }
	  if (!opts.cwd) {
	    opts.cwd = process.cwd();
	  }

	  const { workspaces = [] } = opts.pkg;
	  const { patterns, negatedPatterns } = getPatterns(workspaces);
	  const results = new Map();

	  if (!patterns.length && !negatedPatterns.length) {
	    return results
	  }

	  const seen = new Map();
	  const getGlobOpts = () => ({
	    ...opts,
	    ignore: [
	      ...opts.ignore || [],
	      '**/node_modules/**',
	      // just ignore the negated patterns to avoid unnecessary crawling
	      ...negatedPatterns,
	    ],
	  });

	  let matches = await glob(patterns.map((p) => getGlobPattern(p)), getGlobOpts());
	  // preserves glob@8 behavior
	  matches = matches.sort((a, b) => a.localeCompare(b, 'en'));

	  // we must preserve the order of results according to the given list of
	  // workspace patterns
	  const orderedMatches = [];
	  for (const pattern of patterns) {
	    orderedMatches.push(...matches.filter((m) => {
	      return minimatch(m, pattern, { partial: true, windowsPathsNoEscape: true })
	    }));
	  }

	  for (const match of orderedMatches) {
	    let pkg;
	    try {
	      pkg = await pkgJson.normalize(path.join(opts.cwd, match));
	    } catch (err) {
	      if (err.code === 'ENOENT' || err.code === 'ENOTDIR') {
	        continue
	      } else {
	        throw err
	      }
	    }

	    const name = getPackageName(pkg.content, pkg.path);

	    let seenPackagePathnames = seen.get(name);
	    if (!seenPackagePathnames) {
	      seenPackagePathnames = new Set();
	      seen.set(name, seenPackagePathnames);
	    }
	    seenPackagePathnames.add(pkg.path);
	  }

	  const errorMessageArray = ['must not have multiple workspaces with the same name'];
	  for (const [packageName, seenPackagePathnames] of seen) {
	    if (seenPackagePathnames.size > 1) {
	      addDuplicateErrorMessages(errorMessageArray, packageName, seenPackagePathnames);
	    } else {
	      results.set(packageName, seenPackagePathnames.values().next().value);
	    }
	  }

	  if (errorMessageArray.length > 1) {
	    throw getError({
	      Type: Error,
	      message: errorMessageArray.join('\n'),
	      code: 'EDUPLICATEWORKSPACE',
	    })
	  }

	  return results
	}

	function addDuplicateErrorMessages (messageArray, packageName, packagePathnames) {
	  messageArray.push(
	    `package '${packageName}' has conflicts in the following paths:`
	  );

	  for (const packagePathname of packagePathnames) {
	    messageArray.push(
	      '    ' + packagePathname
	    );
	  }
	}

	mapWorkspaces.virtual = function (opts = {}) {
	  if (!opts || !opts.lockfile) {
	    throw getError({
	      message: 'mapWorkspaces.virtual missing lockfile info',
	      code: 'EMAPWORKSPACESLOCKFILE',
	    })
	  }
	  if (!opts.cwd) {
	    opts.cwd = process.cwd();
	  }

	  const { packages = {} } = opts.lockfile;
	  const { workspaces = [] } = packages[''] || {};
	  // uses a pathname-keyed map in order to negate the exact items
	  const results = new Map();
	  const { patterns, negatedPatterns } = getPatterns(workspaces);
	  if (!patterns.length && !negatedPatterns.length) {
	    return results
	  }
	  negatedPatterns.push('**/node_modules/**');

	  const packageKeys = Object.keys(packages);
	  for (const pattern of negatedPatterns) {
	    for (const packageKey of minimatch.match(packageKeys, pattern)) {
	      packageKeys.splice(packageKeys.indexOf(packageKey), 1);
	    }
	  }

	  for (const pattern of patterns) {
	    for (const packageKey of minimatch.match(packageKeys, pattern)) {
	      const packagePathname = path.join(opts.cwd, packageKey);
	      const name = getPackageName(packages[packageKey], packagePathname);
	      results.set(packagePathname, name);
	    }
	  }

	  // Invert pathname-keyed to a proper name-to-pathnames Map
	  return reverseResultMap(results)
	};

	lib$1 = mapWorkspaces;
	return lib$1;
}

var lib;
var hasRequiredLib;

function requireLib () {
	if (hasRequiredLib) return lib;
	hasRequiredLib = 1;
	// TODO: set the scope config from package.json or explicit cli config
	const { walkUp } = requireCommonjs$3();
	const ini = requireIni();
	const nopt = requireNopt();
	const { log, time } = requireLib$d();

	const { resolve, dirname, join } = require$$2$2;
	const { homedir } = require$$1$3;
	const {
	  readFile,
	  writeFile,
	  chmod,
	  unlink,
	  stat,
	  mkdir,
	} = require$$5;

	// TODO global-prefix and local-prefix are set by lib/set-envs.js.  This may not be the best way to persist those, if we even want to persist them (see set-envs.js)
	const internalEnv = [
	  'npm-version',
	  'global-prefix',
	  'local-prefix',
	];

	const fileExists = (...p) => stat(resolve(...p))
	  .then((st) => st.isFile())
	  .catch(() => false);

	const dirExists = (...p) => stat(resolve(...p))
	  .then((st) => st.isDirectory())
	  .catch(() => false);

	const hasOwnProperty = (obj, key) =>
	  Object.prototype.hasOwnProperty.call(obj, key);

	const typeDefs = requireTypeDefs();
	const nerfDart = requireNerfDart();
	const envReplace = requireEnvReplace();
	const parseField = requireParseField();
	const setEnvs = requireSetEnvs();

	// types that can be saved back to
	const confFileTypes = new Set([
	  'global',
	  'user',
	  'project',
	]);

	const confTypes = new Set([
	  'default',
	  'builtin',
	  ...confFileTypes,
	  'env',
	  'cli',
	]);

	class Config {
	  #loaded = false
	  #flatten
	  // populated the first time we flatten the object
	  #flatOptions = null

	  static get typeDefs () {
	    return typeDefs
	  }

	  constructor ({
	    definitions,
	    shorthands,
	    flatten,
	    nerfDarts = [],
	    npmPath,

	    // options just to override in tests, mostly
	    env = process.env,
	    argv = process.argv,
	    platform = process.platform,
	    execPath = process.execPath,
	    cwd = process.cwd(),
	    excludeNpmCwd = false,
	  }) {
	    this.nerfDarts = nerfDarts;
	    this.definitions = definitions;
	    // turn the definitions into nopt's weirdo syntax
	    const types = {};
	    const defaults = {};
	    this.deprecated = {};
	    for (const [key, def] of Object.entries(definitions)) {
	      defaults[key] = def.default;
	      types[key] = def.type;
	      if (def.deprecated) {
	        this.deprecated[key] = def.deprecated.trim().replace(/\n +/, '\n');
	      }
	    }

	    this.#flatten = flatten;
	    this.types = types;
	    this.shorthands = shorthands;
	    this.defaults = defaults;

	    this.npmPath = npmPath;
	    this.npmBin = join(this.npmPath, 'bin/npm-cli.js');
	    this.argv = argv;
	    this.env = env;
	    this.execPath = execPath;
	    this.platform = platform;
	    this.cwd = cwd;
	    this.excludeNpmCwd = excludeNpmCwd;

	    // set when we load configs
	    this.globalPrefix = null;
	    this.localPrefix = null;
	    this.localPackage = null;

	    // defaults to env.HOME, but will always be *something*
	    this.home = null;

	    // set up the prototype chain of config objects
	    const wheres = [...confTypes];
	    this.data = new Map();
	    let parent = null;
	    for (const where of wheres) {
	      this.data.set(where, parent = new ConfigData(parent));
	    }

	    this.data.set = () => {
	      throw new Error('cannot change internal config data structure')
	    };
	    this.data.delete = () => {
	      throw new Error('cannot change internal config data structure')
	    };

	    this.sources = new Map([]);

	    this.list = [];
	    for (const { data } of this.data.values()) {
	      this.list.unshift(data);
	    }
	    Object.freeze(this.list);

	    this.#loaded = false;
	  }

	  get loaded () {
	    return this.#loaded
	  }

	  get prefix () {
	    return this.#get('global') ? this.globalPrefix : this.localPrefix
	  }

	  // return the location where key is found.
	  find (key) {
	    if (!this.loaded) {
	      throw new Error('call config.load() before reading values')
	    }

	    // have to look in reverse order
	    const entries = [...this.data.entries()];
	    for (let i = entries.length - 1; i > -1; i--) {
	      const [where, { data }] = entries[i];
	      if (hasOwnProperty(data, key)) {
	        return where
	      }
	    }
	    return null
	  }

	  get (key, where) {
	    if (!this.loaded) {
	      throw new Error('call config.load() before reading values')
	    }
	    return this.#get(key, where)
	  }

	  // we need to get values sometimes, so use this internal one to do so
	  // while in the process of loading.
	  #get (key, where = null) {
	    if (where !== null && !confTypes.has(where)) {
	      throw new Error('invalid config location param: ' + where)
	    }
	    const { data } = this.data.get(where || 'cli');
	    return where === null || hasOwnProperty(data, key) ? data[key] : undefined
	  }

	  set (key, val, where = 'cli') {
	    if (!this.loaded) {
	      throw new Error('call config.load() before setting values')
	    }
	    if (!confTypes.has(where)) {
	      throw new Error('invalid config location param: ' + where)
	    }
	    this.#checkDeprecated(key);
	    const { data, raw } = this.data.get(where);
	    data[key] = val;
	    if (['global', 'user', 'project'].includes(where)) {
	      raw[key] = val;
	    }

	    // this is now dirty, the next call to this.valid will have to check it
	    this.data.get(where)[_valid] = null;

	    // the flat options are invalidated, regenerate next time they're needed
	    this.#flatOptions = null;
	  }

	  get flat () {
	    if (this.#flatOptions) {
	      return this.#flatOptions
	    }

	    // create the object for flat options passed to deps
	    const timeEnd = time.start('config:load:flatten');
	    this.#flatOptions = {};
	    // walk from least priority to highest
	    for (const { data } of this.data.values()) {
	      this.#flatten(data, this.#flatOptions);
	    }
	    this.#flatOptions.nodeBin = this.execPath;
	    this.#flatOptions.npmBin = this.npmBin;
	    timeEnd();

	    return this.#flatOptions
	  }

	  delete (key, where = 'cli') {
	    if (!this.loaded) {
	      throw new Error('call config.load() before deleting values')
	    }
	    if (!confTypes.has(where)) {
	      throw new Error('invalid config location param: ' + where)
	    }
	    const { data, raw } = this.data.get(where);
	    delete data[key];
	    if (['global', 'user', 'project'].includes(where)) {
	      delete raw[key];
	    }
	  }

	  async load () {
	    if (this.loaded) {
	      throw new Error('attempting to load npm config multiple times')
	    }

	    // first load the defaults, which sets the global prefix
	    this.loadDefaults();

	    // next load the builtin config, as this sets new effective defaults
	    await this.loadBuiltinConfig();

	    // cli and env are not async, and can set the prefix, relevant to project
	    this.loadCLI();
	    this.loadEnv();

	    // next project config, which can affect userconfig location
	    await this.loadProjectConfig();

	    // then user config, which can affect globalconfig location
	    await this.loadUserConfig();

	    // last but not least, global config file
	    await this.loadGlobalConfig();

	    // set this before calling setEnvs, so that we don't have to share
	    // private attributes, as that module also does a bunch of get operations
	    this.#loaded = true;

	    // set proper globalPrefix now that everything is loaded
	    this.globalPrefix = this.get('prefix');

	    this.setEnvs();
	  }

	  loadDefaults () {
	    this.loadGlobalPrefix();
	    this.loadHome();

	    const defaultsObject = {
	      ...this.defaults,
	      prefix: this.globalPrefix,
	    };

	    try {
	      // This does not have an actual definition because this is not user defineable
	      defaultsObject['npm-version'] = commonjsRequire(join(this.npmPath, 'package.json')).version;
	    } catch {
	      // in some weird state where the passed in npmPath does not have a package.json
	      // this will never happen in npm, but is guarded here in case this is consumed
	      // in other ways + tests
	    }

	    this.#loadObject(defaultsObject, 'default', 'default values');

	    const { data } = this.data.get('default');

	    // if the prefix is set on cli, env, or userconfig, then we need to
	    // default the globalconfig file to that location, instead of the default
	    // global prefix.  It's weird that `npm get globalconfig --prefix=/foo`
	    // returns `/foo/etc/npmrc`, but better to not change it at this point.
	    // define a custom getter, but turn into a normal prop
	    // if we set it.  otherwise it can't be set on child objects
	    Object.defineProperty(data, 'globalconfig', {
	      get: () => resolve(this.#get('prefix'), 'etc/npmrc'),
	      set (value) {
	        Object.defineProperty(data, 'globalconfig', {
	          value,
	          configurable: true,
	          writable: true,
	          enumerable: true,
	        });
	      },
	      configurable: true,
	      enumerable: true,
	    });
	  }

	  loadHome () {
	    this.home = this.env.HOME || homedir();
	  }

	  loadGlobalPrefix () {
	    if (this.globalPrefix) {
	      throw new Error('cannot load default global prefix more than once')
	    }

	    if (this.env.PREFIX) {
	      this.globalPrefix = this.env.PREFIX;
	    } else if (this.platform === 'win32') {
	      // c:\node\node.exe --> prefix=c:\node\
	      this.globalPrefix = dirname(this.execPath);
	    } else {
	      // /usr/local/bin/node --> prefix=/usr/local
	      this.globalPrefix = dirname(dirname(this.execPath));

	      // destdir only is respected on Unix
	      if (this.env.DESTDIR) {
	        this.globalPrefix = join(this.env.DESTDIR, this.globalPrefix);
	      }
	    }
	  }

	  loadEnv () {
	    const conf = Object.create(null);
	    for (const [envKey, envVal] of Object.entries(this.env)) {
	      if (!/^npm_config_/i.test(envKey) || envVal === '') {
	        continue
	      }
	      let key = envKey.slice('npm_config_'.length);
	      if (!key.startsWith('//')) { // don't normalize nerf-darted keys
	        key = key.replace(/(?!^)_/g, '-') // don't replace _ at the start of the key
	          .toLowerCase();
	      }
	      conf[key] = envVal;
	    }
	    this.#loadObject(conf, 'env', 'environment');
	  }

	  loadCLI () {
	    for (const s of Object.keys(this.shorthands)) {
	      if (s.length > 1 && this.argv.includes(`-${s}`)) {
	        log.warn(`-${s} is not a valid single-hyphen cli flag and will be removed in the future`);
	      }
	    }
	    nopt.invalidHandler = (k, val, type) =>
	      this.invalidHandler(k, val, type, 'command line options', 'cli');
	    nopt.unknownHandler = this.unknownHandler;
	    nopt.abbrevHandler = this.abbrevHandler;
	    const conf = nopt(this.types, this.shorthands, this.argv);
	    nopt.invalidHandler = null;
	    nopt.unknownHandler = null;
	    this.parsedArgv = conf.argv;
	    delete conf.argv;
	    this.#loadObject(conf, 'cli', 'command line options');
	  }

	  get valid () {
	    for (const [where, { valid }] of this.data.entries()) {
	      if (valid === false || valid === null && !this.validate(where)) {
	        return false
	      }
	    }
	    return true
	  }

	  validate (where) {
	    if (!where) {
	      let valid = true;
	      const authProblems = [];

	      for (const entryWhere of this.data.keys()) {
	        // no need to validate our defaults, we know they're fine
	        // cli was already validated when parsed the first time
	        if (entryWhere === 'default' || entryWhere === 'builtin' || entryWhere === 'cli') {
	          continue
	        }
	        const ret = this.validate(entryWhere);
	        valid = valid && ret;

	        if (['global', 'user', 'project'].includes(entryWhere)) {
	          // after validating everything else, we look for old auth configs we no longer support
	          // if these keys are found, we build up a list of them and the appropriate action and
	          // attach it as context on the thrown error

	          // first, keys that should be removed
	          for (const key of ['_authtoken', '-authtoken']) {
	            if (this.get(key, entryWhere)) {
	              authProblems.push({ action: 'delete', key, where: entryWhere });
	            }
	          }

	          // NOTE we pull registry without restricting to the current 'where' because we want to
	          // suggest scoping things to the registry they would be applied to, which is the default
	          // regardless of where it was defined
	          const nerfedReg = nerfDart(this.get('registry'));
	          // keys that should be nerfed but currently are not
	          for (const key of ['_auth', '_authToken', 'username', '_password']) {
	            if (this.get(key, entryWhere)) {
	              // username and _password must both exist in the same file to be recognized correctly
	              if (key === 'username' && !this.get('_password', entryWhere)) {
	                authProblems.push({ action: 'delete', key, where: entryWhere });
	              } else if (key === '_password' && !this.get('username', entryWhere)) {
	                authProblems.push({ action: 'delete', key, where: entryWhere });
	              } else {
	                authProblems.push({
	                  action: 'rename',
	                  from: key,
	                  to: `${nerfedReg}:${key}`,
	                  where: entryWhere,
	                });
	              }
	            }
	          }
	        }
	      }

	      if (authProblems.length) {
	        const { ErrInvalidAuth } = requireErrors$1();
	        throw new ErrInvalidAuth(authProblems)
	      }

	      return valid
	    } else {
	      const obj = this.data.get(where);
	      obj[_valid] = true;

	      nopt.invalidHandler = (k, val, type) =>
	        this.invalidHandler(k, val, type, obj.source, where);

	      nopt.clean(obj.data, this.types, typeDefs);

	      nopt.invalidHandler = null;
	      return obj[_valid]
	    }
	  }

	  // fixes problems identified by validate(), accepts the 'problems' property from a thrown
	  // ErrInvalidAuth to avoid having to check everything again
	  repair (problems) {
	    if (!problems) {
	      try {
	        this.validate();
	      } catch (err) {
	        // coverage skipped here because we don't need to test re-throwing an error
	        // istanbul ignore next
	        if (err.code !== 'ERR_INVALID_AUTH') {
	          throw err
	        }

	        problems = err.problems;
	      } finally {
	        if (!problems) {
	          problems = [];
	        }
	      }
	    }

	    for (const problem of problems) {
	      // coverage disabled for else branch because it doesn't do anything and shouldn't
	      // istanbul ignore else
	      if (problem.action === 'delete') {
	        this.delete(problem.key, problem.where);
	      } else if (problem.action === 'rename') {
	        const raw = this.data.get(problem.where).raw?.[problem.from];
	        const calculated = this.get(problem.from, problem.where);
	        this.set(problem.to, raw || calculated, problem.where);
	        this.delete(problem.from, problem.where);
	      }
	    }
	  }

	  // Returns true if the value is coming directly from the source defined
	  // in default definitions, if the current value for the key config is
	  // coming from any other different source, returns false
	  isDefault (key) {
	    const [defaultType, ...types] = [...confTypes];
	    const defaultData = this.data.get(defaultType).data;

	    return hasOwnProperty(defaultData, key)
	      && types.every(type => {
	        const typeData = this.data.get(type).data;
	        return !hasOwnProperty(typeData, key)
	      })
	  }

	  invalidHandler (k, val, type, source, where) {
	    const typeDescription = requireTypeDescription();
	    log.warn(
	      'invalid config',
	      k + '=' + JSON.stringify(val),
	      `set in ${source}`
	    );
	    this.data.get(where)[_valid] = false;

	    if (Array.isArray(type)) {
	      if (type.includes(typeDefs.url.type)) {
	        type = typeDefs.url.type;
	      } else {
	        /* istanbul ignore if - no actual configs matching this, but
	         * path types SHOULD be handled this way, like URLs, for the
	         * same reason */
	        if (type.includes(typeDefs.path.type)) {
	          type = typeDefs.path.type;
	        }
	      }
	    }

	    const typeDesc = typeDescription(type);
	    const mustBe = typeDesc
	      .filter(m => m !== undefined && m !== Array);
	    const msg = 'Must be' + this.#getOneOfKeywords(mustBe, typeDesc);
	    const desc = mustBe.length === 1 ? mustBe[0]
	      : [...new Set(mustBe.map(n => typeof n === 'string' ? n : JSON.stringify(n)))].join(', ');
	    log.warn('invalid config', msg, desc);
	  }

	  abbrevHandler (short, long) {
	    log.warn(`Expanding --${short} to --${long}. This will stop working in the next major version of npm.`);
	  }

	  unknownHandler (key, next) {
	    if (next) {
	      log.warn(`"${next}" is being parsed as a normal command line argument.`);
	    }
	  }

	  #getOneOfKeywords (mustBe, typeDesc) {
	    let keyword;
	    if (mustBe.length === 1 && typeDesc.includes(Array)) {
	      keyword = ' one or more';
	    } else if (mustBe.length > 1 && typeDesc.includes(Array)) {
	      keyword = ' one or more of:';
	    } else if (mustBe.length > 1) {
	      keyword = ' one of:';
	    } else {
	      keyword = '';
	    }
	    return keyword
	  }

	  #loadObject (obj, where, source, er = null) {
	    // obj is the raw data read from the file
	    const conf = this.data.get(where);
	    if (conf.source) {
	      const m = `double-loading "${where}" configs from ${source}, ` +
	        `previously loaded from ${conf.source}`;
	      throw new Error(m)
	    }

	    if (this.sources.has(source)) {
	      const m = `double-loading config "${source}" as "${where}", ` +
	        `previously loaded as "${this.sources.get(source)}"`;
	      throw new Error(m)
	    }

	    conf.source = source;
	    this.sources.set(source, where);
	    if (er) {
	      conf.loadError = er;
	      if (er.code !== 'ENOENT') {
	        log.verbose('config', `error loading ${where} config`, er);
	      }
	    } else {
	      conf.raw = obj;
	      for (const [key, value] of Object.entries(obj)) {
	        const k = envReplace(key, this.env);
	        const v = this.parseField(value, k);
	        if (where !== 'default') {
	          this.#checkDeprecated(k);
	          if (this.definitions[key]?.exclusive) {
	            for (const exclusive of this.definitions[key].exclusive) {
	              if (!this.isDefault(exclusive)) {
	                throw new TypeError(`--${key} can not be provided when using --${exclusive}`)
	              }
	            }
	          }
	        }
	        if (where !== 'default' || key === 'npm-version') {
	          this.checkUnknown(where, key);
	        }
	        conf.data[k] = v;
	      }
	    }
	  }

	  checkUnknown (where, key) {
	    if (!this.definitions[key]) {
	      if (internalEnv.includes(key)) {
	        return
	      }
	      if (!key.includes(':')) {
	        log.warn(`Unknown ${where} config "${where === 'cli' ? '--' : ''}${key}". This will stop working in the next major version of npm.`);
	        return
	      }
	      const baseKey = key.split(':').pop();
	      if (!this.definitions[baseKey] && !this.nerfDarts.includes(baseKey)) {
	        log.warn(`Unknown ${where} config "${baseKey}" (${key}). This will stop working in the next major version of npm.`);
	      }
	    }
	  }

	  #checkDeprecated (key) {
	    if (this.deprecated[key]) {
	      log.warn('config', key, this.deprecated[key]);
	    }
	  }

	  // Parse a field, coercing it to the best type available.
	  parseField (f, key, listElement = false) {
	    return parseField(f, key, this, listElement)
	  }

	  async #loadFile (file, type) {
	    // only catch the error from readFile, not from the loadObject call
	    log.silly('config', `load:file:${file}`);
	    await readFile(file, 'utf8').then(
	      data => {
	        const parsedConfig = ini.parse(data);
	        if (type === 'project' && parsedConfig.prefix) {
	          // Log error if prefix is mentioned in project .npmrc
	          /* eslint-disable-next-line max-len */
	          log.error('config', `prefix cannot be changed from project config: ${file}.`);
	        }
	        return this.#loadObject(parsedConfig, type, file)
	      },
	      er => this.#loadObject(null, type, file, er)
	    );
	  }

	  loadBuiltinConfig () {
	    return this.#loadFile(resolve(this.npmPath, 'npmrc'), 'builtin')
	  }

	  async loadProjectConfig () {
	    // the localPrefix can be set by the CLI config, but otherwise is
	    // found by walking up the folder tree. either way, we load it before
	    // we return to make sure localPrefix is set
	    await this.loadLocalPrefix();

	    // if we have not detected a local package json yet, try now that we
	    // have a local prefix
	    if (this.localPackage == null) {
	      this.localPackage = await fileExists(this.localPrefix, 'package.json');
	    }

	    if (this.#get('global') === true || this.#get('location') === 'global') {
	      this.data.get('project').source = '(global mode enabled, ignored)';
	      this.sources.set(this.data.get('project').source, 'project');
	      return
	    }

	    const projectFile = resolve(this.localPrefix, '.npmrc');
	    // if we're in the ~ directory, and there happens to be a node_modules
	    // folder (which is not TOO uncommon, it turns out), then we can end
	    // up loading the "project" config where the "userconfig" will be,
	    // which causes some calamaties.  So, we only load project config if
	    // it doesn't match what the userconfig will be.
	    if (projectFile !== this.#get('userconfig')) {
	      return this.#loadFile(projectFile, 'project')
	    } else {
	      this.data.get('project').source = '(same as "user" config, ignored)';
	      this.sources.set(this.data.get('project').source, 'project');
	    }
	  }

	  async loadLocalPrefix () {
	    const cliPrefix = this.#get('prefix', 'cli');
	    if (cliPrefix) {
	      this.localPrefix = cliPrefix;
	      return
	    }

	    const cliWorkspaces = this.#get('workspaces', 'cli');
	    const isGlobal = this.#get('global') || this.#get('location') === 'global';

	    for (const p of walkUp(this.cwd)) {
	      // HACK: this is an option set in tests to stop the local prefix from being set
	      // on tests that are created inside the npm repo
	      if (this.excludeNpmCwd && p === this.npmPath) {
	        break
	      }

	      const hasPackageJson = await fileExists(p, 'package.json');

	      if (!this.localPrefix && (hasPackageJson || await dirExists(p, 'node_modules'))) {
	        this.localPrefix = p;
	        this.localPackage = hasPackageJson;

	        // if workspaces are disabled, or we're in global mode, return now
	        if (cliWorkspaces === false || isGlobal) {
	          return
	        }

	        // otherwise, continue the loop
	        continue
	      }

	      if (this.localPrefix && hasPackageJson) {
	        const pkgJson = requireLib$3();
	        // if we already set localPrefix but this dir has a package.json
	        // then we need to see if `p` is a workspace root by reading its package.json
	        // however, if reading it fails then we should just move on
	        const { content: pkg } = await pkgJson.normalize(p).catch(() => ({ content: {} }));
	        if (!pkg?.workspaces) {
	          continue
	        }

	        const mapWorkspaces = requireLib$1();
	        const workspaces = await mapWorkspaces({ cwd: p, pkg });
	        for (const w of workspaces.values()) {
	          if (w === this.localPrefix) {
	            // see if there's a .npmrc file in the workspace, if so log a warning
	            if (await fileExists(this.localPrefix, '.npmrc')) {
	              log.warn('config', `ignoring workspace config at ${this.localPrefix}/.npmrc`);
	            }

	            // set the workspace in the default layer, which allows it to be overridden easily
	            const { data } = this.data.get('default');
	            data.workspace = [this.localPrefix];
	            this.localPrefix = p;
	            this.localPackage = hasPackageJson;
	            log.info('config', `found workspace root at ${this.localPrefix}`);
	            // we found a root, so we return now
	            return
	          }
	        }
	      }
	    }

	    if (!this.localPrefix) {
	      this.localPrefix = this.cwd;
	    }
	  }

	  loadUserConfig () {
	    return this.#loadFile(this.#get('userconfig'), 'user')
	  }

	  loadGlobalConfig () {
	    return this.#loadFile(this.#get('globalconfig'), 'global')
	  }

	  async save (where) {
	    if (!this.loaded) {
	      throw new Error('call config.load() before saving')
	    }
	    if (!confFileTypes.has(where)) {
	      throw new Error('invalid config location param: ' + where)
	    }

	    const conf = this.data.get(where);
	    conf[_loadError] = null;

	    if (where === 'user') {
	      // if email is nerfed, then we want to de-nerf it
	      const nerfed = nerfDart(this.get('registry'));
	      const email = this.get(`${nerfed}:email`, 'user');
	      if (email) {
	        this.delete(`${nerfed}:email`, 'user');
	        this.set('email', email, 'user');
	      }
	    }

	    // We need the actual raw data before we called parseField so that we are
	    // saving the same content back to the file
	    const iniData = ini.stringify(conf.raw).trim() + '\n';
	    if (!iniData.trim()) {
	      // ignore the unlink error (eg, if file doesn't exist)
	      await unlink(conf.source).catch(() => {});
	      return
	    }
	    const dir = dirname(conf.source);
	    await mkdir(dir, { recursive: true });
	    await writeFile(conf.source, iniData, 'utf8');
	    const mode = where === 'user' ? 0o600 : 0o666;
	    await chmod(conf.source, mode);
	  }

	  clearCredentialsByURI (uri, level = 'user') {
	    const nerfed = nerfDart(uri);
	    const def = nerfDart(this.get('registry'));
	    if (def === nerfed) {
	      this.delete(`-authtoken`, level);
	      this.delete(`_authToken`, level);
	      this.delete(`_authtoken`, level);
	      this.delete(`_auth`, level);
	      this.delete(`_password`, level);
	      this.delete(`username`, level);
	      // de-nerf email if it's nerfed to the default registry
	      const email = this.get(`${nerfed}:email`, level);
	      if (email) {
	        this.set('email', email, level);
	      }
	    }
	    this.delete(`${nerfed}:_authToken`, level);
	    this.delete(`${nerfed}:_auth`, level);
	    this.delete(`${nerfed}:_password`, level);
	    this.delete(`${nerfed}:username`, level);
	    this.delete(`${nerfed}:email`, level);
	    this.delete(`${nerfed}:certfile`, level);
	    this.delete(`${nerfed}:keyfile`, level);
	  }

	  setCredentialsByURI (uri, { token, username, password, certfile, keyfile }) {
	    const nerfed = nerfDart(uri);

	    // field that hasn't been used as documented for a LONG time,
	    // and as of npm 7.10.0, isn't used at all.  We just always
	    // send auth if we have it, only to the URIs under the nerf dart.
	    this.delete(`${nerfed}:always-auth`, 'user');

	    this.delete(`${nerfed}:email`, 'user');
	    if (certfile && keyfile) {
	      this.set(`${nerfed}:certfile`, certfile, 'user');
	      this.set(`${nerfed}:keyfile`, keyfile, 'user');
	      // cert/key may be used in conjunction with other credentials, thus no `else`
	    }
	    if (token) {
	      this.set(`${nerfed}:_authToken`, token, 'user');
	      this.delete(`${nerfed}:_password`, 'user');
	      this.delete(`${nerfed}:username`, 'user');
	    } else if (username || password) {
	      if (!username) {
	        throw new Error('must include username')
	      }
	      if (!password) {
	        throw new Error('must include password')
	      }
	      this.delete(`${nerfed}:_authToken`, 'user');
	      this.set(`${nerfed}:username`, username, 'user');
	      // note: not encrypted, no idea why we bothered to do this, but oh well
	      // protects against shoulder-hacks if password is memorable, I guess?
	      const encoded = Buffer.from(password, 'utf8').toString('base64');
	      this.set(`${nerfed}:_password`, encoded, 'user');
	    } else if (!certfile || !keyfile) {
	      throw new Error('No credentials to set.')
	    }
	  }

	  // this has to be a bit more complicated to support legacy data of all forms
	  getCredentialsByURI (uri) {
	    const nerfed = nerfDart(uri);
	    const def = nerfDart(this.get('registry'));
	    const creds = {};

	    // email is handled differently, it used to always be nerfed and now it never should be
	    // if it's set nerfed to the default registry, then we copy it to the unnerfed key
	    // TODO: evaluate removing 'email' from the credentials object returned here
	    const email = this.get(`${nerfed}:email`) || this.get('email');
	    if (email) {
	      if (nerfed === def) {
	        this.set('email', email, 'user');
	      }
	      creds.email = email;
	    }

	    const certfileReg = this.get(`${nerfed}:certfile`);
	    const keyfileReg = this.get(`${nerfed}:keyfile`);
	    if (certfileReg && keyfileReg) {
	      creds.certfile = certfileReg;
	      creds.keyfile = keyfileReg;
	      // cert/key may be used in conjunction with other credentials, thus no `return`
	    }

	    const tokenReg = this.get(`${nerfed}:_authToken`);
	    if (tokenReg) {
	      creds.token = tokenReg;
	      return creds
	    }

	    const userReg = this.get(`${nerfed}:username`);
	    const passReg = this.get(`${nerfed}:_password`);
	    if (userReg && passReg) {
	      creds.username = userReg;
	      creds.password = Buffer.from(passReg, 'base64').toString('utf8');
	      const auth = `${creds.username}:${creds.password}`;
	      creds.auth = Buffer.from(auth, 'utf8').toString('base64');
	      return creds
	    }

	    const authReg = this.get(`${nerfed}:_auth`);
	    if (authReg) {
	      const authDecode = Buffer.from(authReg, 'base64').toString('utf8');
	      const authSplit = authDecode.split(':');
	      creds.username = authSplit.shift();
	      creds.password = authSplit.join(':');
	      creds.auth = authReg;
	      return creds
	    }

	    // at this point, nothing else is usable so just return what we do have
	    return creds
	  }

	  // set up the environment object we have with npm_config_* environs
	  // for all configs that are different from their default values, and
	  // set EDITOR and HOME.
	  setEnvs () {
	    setEnvs(this);
	  }
	}

	const _loadError = Symbol('loadError');
	const _valid = Symbol('valid');

	class ConfigData {
	  #data
	  #source = null
	  #raw = null
	  constructor (parent) {
	    this.#data = Object.create(parent && parent.data);
	    this.#raw = {};
	    this[_valid] = true;
	  }

	  get data () {
	    return this.#data
	  }

	  get valid () {
	    return this[_valid]
	  }

	  set source (s) {
	    if (this.#source) {
	      throw new Error('cannot set ConfigData source more than once')
	    }
	    this.#source = s;
	  }

	  get source () {
	    return this.#source
	  }

	  set loadError (e) {
	    if (this[_loadError] || (Object.keys(this.#raw).length)) {
	      throw new Error('cannot set ConfigData loadError after load')
	    }
	    this[_loadError] = e;
	  }

	  get loadError () {
	    return this[_loadError]
	  }

	  set raw (r) {
	    if (Object.keys(this.#raw).length || this[_loadError]) {
	      throw new Error('cannot set ConfigData raw after load')
	    }
	    this.#raw = r;
	  }

	  get raw () {
	    return this.#raw
	  }
	}

	lib = Config;
	return lib;
}

var libExports = requireLib();
const index = /*@__PURE__*/getDefaultExportFromCjs(libExports);

const index$1 = {
	__proto__: null,
	default: index
};

export { index$1 as i };
